{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "dF0MJHXZVRpt"
   },
   "source": [
    "# Packages and functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d285e96e82c24a8a97836a559ea16922",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading:   0%|          | 0.00/391 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d7b7f757389a402c96235a4c7530a299",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading:   0%|          | 0.00/190 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a93835eba2004f84a33de13b550858da",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading:   0%|          | 0.00/3.95k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "71445bc978a74f92981a30676204b0b9",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading:   0%|          | 0.00/2.00 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "261dfd73dbad4c3197b6ed0ba791cee0",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading:   0%|          | 0.00/625 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "dfbec4d642bf4da297f816f4ef94c37c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading:   0%|          | 0.00/122 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e77a1ea6647641e69e41ed04e5290867",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading:   0%|          | 0.00/438M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7c7710ee1c914fd291a4fe6afe2437ca",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading:   0%|          | 0.00/53.0 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4306677e714743efa4ba703c7b2f71d0",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading:   0%|          | 0.00/112 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b26744432cf040c69e75a3e41bd8b850",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading:   0%|          | 0.00/466k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6aebac68e20e4af5bd68f36af63ec025",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading:   0%|          | 0.00/399 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b13b426c13744c9485d6ea011c5d9d32",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading:   0%|          | 0.00/232k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "fa29d976807e4631ab97ed97fb02aa27",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading:   0%|          | 0.00/229 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "(2, 768)"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sentence_transformers import SentenceTransformer, util\n",
    "model = SentenceTransformer('bert-base-nli-mean-tokens')\n",
    "sentences = [\"I love coding\", \"Python is a powerful language\"]\n",
    "sentence_embeddings = model.encode(sentences)\n",
    "sentence_embeddings.shape\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(768,)"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sentence_embeddings = model.encode('I live coding. Python is my languange')\n",
    "sentence_embeddings.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "l5GfuP1hlTmg",
    "outputId": "b655d8cd-a8e8-4766-8d27-d5fcb463db72"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: unidecode in /Users/ghassenabdedayem/opt/anaconda3/lib/python3.8/site-packages (1.2.0)\r\n"
     ]
    }
   ],
   "source": [
    "!pip install unidecode\n",
    "\n",
    "import numpy as np\n",
    "import random\n",
    "from random import randint\n",
    "from datetime import datetime\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import log_loss, accuracy_score\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from time import time\n",
    "from gensim.models import Word2Vec\n",
    "import networkx as nx\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import torch.nn.functional as F\n",
    "import os\n",
    "from random import choice\n",
    "from scipy.sparse import identity, diags\n",
    "from unidecode import unidecode\n",
    "from urllib.request import urlopen\n",
    "import gzip\n",
    "import pickle\n",
    "from gensim.parsing.preprocessing import remove_stopwords\n",
    "import re\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "lemmatizer = WordNetLemmatizer()\n",
    "from tqdm.notebook import tqdm\n",
    "import requests\n",
    "import io\n",
    "from scipy import sparse\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "\n",
    "\n",
    "device = torch.device(\"cuda\") if torch.cuda.is_available() else torch.device(\"cpu\")\n",
    "#device = torch.device(\"cpu\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "id": "BJSlSwejljfp"
   },
   "outputs": [],
   "source": [
    "def save_subgraph_in_file(nbr_nodes, source_path='../input_data/edgelist.txt', destination_path='../input_data/small_edgelist.txt'):\n",
    "    G = nx.read_edgelist(source_path, delimiter=',', create_using=nx.Graph(), nodetype=int)\n",
    "    G = G.subgraph(range(nbr_nodes))\n",
    "    nx.write_edgelist(G, path=destination_path, delimiter=',')\n",
    "    print(G.number_of_nodes(), 'nodes,', G.number_of_edges(), 'edges Graph extracted from', source_path[source_path.rfind('/')+1:])\n",
    "    G = nx.read_edgelist(destination_path, delimiter=',', create_using=nx.Graph(), nodetype=int)\n",
    "    print(G.number_of_nodes(), 'nodes,', G.number_of_edges(), 'edges Graph saved in', destination_path[destination_path.rfind('/')+1:])\n",
    "    print(max(G.nodes))\n",
    "    return\n",
    "\n",
    "\n",
    "def read_train_val_graph(path='../input_data/edgelist.txt', shuffle=True, val_ratio=0.1):\n",
    "    #gets the data from the file on the distant server\n",
    "    G = nx.read_edgelist(urlopen('https://www.lix.polytechnique.fr/~nikolentzos/files/aai/challenge/edgelist.txt'), delimiter=',', create_using=nx.Graph(), nodetype=int)\n",
    "    nodes = list(G.nodes())\n",
    "    edges = list(G.edges())\n",
    "    n = G.number_of_nodes()\n",
    "    m = G.number_of_edges()\n",
    "    \n",
    "    permutation = np.array(range(n))\n",
    "    mapping_permutation = dict(zip(range(n), range(n)))\n",
    "    if shuffle:\n",
    "        # shuffle the order of the edges without changing the labels\n",
    "        random.shuffle(edges)\n",
    "        G = nx.Graph()\n",
    "        G.add_edges_from(edges)\n",
    "        permutation = np.random.permutation(n)\n",
    "        print(type(permutation))\n",
    "        # create a mapping from old nodes labels to new nodes labels\n",
    "        mapping_permutation = dict(zip(range(n), permutation))\n",
    "\n",
    "        # shuffle G node labels according to the permutation\n",
    "        G = nx.relabel_nodes(G, mapping_permutation)    \n",
    "        \n",
    "        edges = list(G.edges())\n",
    "        nodes = list(G.nodes())\n",
    "\n",
    "\n",
    "    print('Number of nodes:', n, 'number of edges:', m,'in the Complete set')\n",
    "\n",
    "    node_to_idx = dict()\n",
    "    for i, node in enumerate(nodes):\n",
    "        node_to_idx[node] = i\n",
    "\n",
    "    val_edges = list()\n",
    "    G_train = G.copy()\n",
    "\n",
    "    for edge in edges:\n",
    "        if random.random() < val_ratio and edge[0] < n and edge[1] < n:\n",
    "            val_edges.append(edge)\n",
    "            G_train.remove_edge(edge[0], edge[1]) # We remove the val edges from the graph G\n",
    "\n",
    "   \n",
    "    #for edge in val_edges:\n",
    "        \n",
    "\n",
    "    n = G_train.number_of_nodes()\n",
    "    m = G_train.number_of_edges()\n",
    "    train_edges = list(G_train.edges())\n",
    "\n",
    "    print('Number of nodes:', n, 'number of edges:', m, 'in the Training set')\n",
    "    print('len(nodes)', len(nodes))\n",
    "\n",
    "    y_val = [1]*len(val_edges)\n",
    "\n",
    "    n_val_edges = len(val_edges)\n",
    "    \n",
    "    print('Creating random val_edges...')\n",
    "    for i in range(n_val_edges):\n",
    "        n1 = nodes[randint(0, n-1)]\n",
    "        n2 = nodes[randint(0, n-1)]\n",
    "        (n1, n2) = (min(n1, n2), max(n1, n2))\n",
    "        while n2 >= n: #or (n1, n2) in train_edges:\n",
    "            if (n1, n2) in train_edges:\n",
    "                print((n1, n2), 'in train_edges:')\n",
    "            n1 = nodes[randint(0, n-1)]\n",
    "            n2 = nodes[randint(0, n-1)]\n",
    "            (n1, n2) = (min(n1, n2), max(n1, n2))\n",
    "        val_edges.append((n1, n2))\n",
    "\n",
    "    y_val.extend([0]*(n_val_edges))\n",
    "    \n",
    "    ### From Giannis /!\\\n",
    "    val_indices = np.zeros((2,len(val_edges)))\n",
    "    for i,edge in enumerate(val_edges):\n",
    "        val_indices[0,i] = node_to_idx[edge[0]]\n",
    "        val_indices[1,i] = node_to_idx[edge[1]]\n",
    "    \n",
    "    print('Returned G_train, train_edges, val_edges, y_val, nodes and node_to_idx objects')\n",
    "    print('Loaded from', path[path.rfind('/')+1:], 'and with a training validation split ratio =', val_ratio)\n",
    "    \n",
    "    \n",
    "    \n",
    "    return G, G_train, train_edges, val_edges, val_indices, y_val, nodes, node_to_idx, permutation, mapping_permutation\n",
    "\n",
    "def random_walk(G, node, walk_length):\n",
    "    walk = [node]\n",
    "  \n",
    "    for i in range(walk_length-1):\n",
    "        neibor_nodes = list(G.neighbors(walk[-1]))\n",
    "        if len(neibor_nodes) > 0:\n",
    "            next_node = choice(neibor_nodes)\n",
    "            walk.append(next_node)\n",
    "    walk = [node for node in walk] # in case the nodes are in string format, we don't need to cast into string, but if the nodes are in numeric or integer, we need this line to cast into string\n",
    "    return walk\n",
    "\n",
    "\n",
    "def generate_walks(G, num_walks, walk_length):\n",
    "  # Runs \"num_walks\" random walks from each node, and returns a list of all random walk\n",
    "    t = time()\n",
    "    print('Start generating walks....')\n",
    "    walks = list()  \n",
    "    for i in range(num_walks):\n",
    "        for node in G.nodes():\n",
    "            walk = random_walk(G, node, walk_length)\n",
    "            walks.append(walk)\n",
    "        #print('walks : ', walks)\n",
    "    print('Random walks generated in in {}s!'.format(round(time()-t)))\n",
    "    return walks\n",
    "\n",
    "def apply_word2vec_on_features(features, nodes, vector_size=128, window=5, min_count=0, sg=1, workers=8):\n",
    "    t = time()\n",
    "    print('Start applying Word2Vec...')\n",
    "    wv_model = Word2Vec(vector_size=vector_size, window=window, min_count=min_count, sg=sg, workers=workers)\n",
    "    wv_model.build_vocab(features)\n",
    "    wv_model.train(features, total_examples=wv_model.corpus_count, epochs=5) \n",
    "    print('Word2vec model trained on features in {} min!'.format(round((time()-t)/60)))\n",
    "    features_np = []\n",
    "    for node in nodes:\n",
    "        features_np.append(wv_model.wv[node])\n",
    "\n",
    "    features_np = np.array(features_np)\n",
    "    print(features_np.shape, 'features numpy array created in {} min!'.format(round((time()-t)/60)))\n",
    "    return features_np\n",
    "\n",
    "\n",
    "import numpy as np\n",
    "import scipy.sparse as sp\n",
    "\n",
    "def normalize_adjacency(A):\n",
    "    n = A.shape[0]\n",
    "    A = A + identity(n)\n",
    "    degs = A.dot(np.ones(n))\n",
    "    inv_degs = np.power(degs, -1)\n",
    "    D_inv = diags(inv_degs)\n",
    "    A_hat = D_inv.dot(A)\n",
    "    return A_hat\n",
    "\n",
    "\n",
    "# a proposed adj normalization, but we will keep the original one in the function after\n",
    "def normalize_adj(adj):\n",
    "    \"\"\"Normalize adjacency matrix.\"\"\"\n",
    "    adj = sp.coo_matrix(adj)\n",
    "    rowsum = np.array(adj.sum(1))\n",
    "    d_inv_sqrt = np.power(rowsum, -0.5).flatten()\n",
    "    d_inv_sqrt[np.isinf(d_inv_sqrt)] = 0.\n",
    "    d_mat_inv_sqrt = sp.diags(d_inv_sqrt)\n",
    "    return adj.dot(d_mat_inv_sqrt).transpose().dot(d_mat_inv_sqrt).tocoo()\n",
    "\n",
    "\n",
    "\n",
    "def create_and_normalize_adjacency(G):\n",
    "    adj = nx.adjacency_matrix(G) # Obtains the adjacency matrix of the training graph\n",
    "    #adj = normalize_adjacency(adj)\n",
    "    adj = normalize_adj(adj)\n",
    "    print('Created a normalized adjancency matrix of shape', adj.shape)\n",
    "    indices = np.array(adj.nonzero()) # Gets the positions of non zeros of adj into indices\n",
    "    print('Created indices', indices.shape, 'with the positions of non zeros in adj matrix')\n",
    "    return adj, indices\n",
    "\n",
    "def sparse_mx_to_torch_sparse_tensor(sparse_mx):\n",
    "    sparse_mx = sparse_mx.tocoo().astype(np.float32)\n",
    "    indices = torch.from_numpy(np.vstack((sparse_mx.row, sparse_mx.col)).astype(np.int64))\n",
    "    values = torch.from_numpy(sparse_mx.data)\n",
    "    shape = torch.Size(sparse_mx.shape)\n",
    "    return torch.sparse.FloatTensor(indices, values, shape)\n",
    "\n",
    "\n",
    "def text_to_list(text):\n",
    "    text = unidecode(text)\n",
    "    text = re.sub(r\"[^a-zA-Z\\s.,]\", \"\", text)\n",
    "    return text.split(',')\n",
    "\n",
    "def intersection(lst1, lst2): # a function that returns the number of common items of two lists and 1 or 0 if there are common. This function will be used in add_authors_to_pairs to add this features to the pairs.\n",
    "    lst3 = [value for value in lst1 if value in lst2]\n",
    "    is_common = 1 if len(lst3)>0 else 0\n",
    "    return len(lst3)+1, is_common+1\n",
    "\n",
    "\n",
    "def add_authors_to_pairs (pairs, authors):\n",
    "    authors = pd.DataFrame(authors)\n",
    "    try: \n",
    "        pairs = pairs.detach().cpu().numpy()\n",
    "    except:\n",
    "        pass\n",
    "        \n",
    "\n",
    "    pairs_df = pd.DataFrame(np.transpose(pairs)).rename(columns={0: \"paper_1\", 1: \"paper_2\"})\n",
    "    pairs_df = pairs_df.merge(authors, left_on='paper_1', right_on='paper_permut', how='left').rename(columns={'authors': \"authors_1\"})\n",
    "    pairs_df = pairs_df.merge(authors, left_on='paper_2', right_on='paper_permut', how='left').rename(columns={'authors': \"authors_2\"})\n",
    "    pairs_df.drop(['paper_id_x', 'paper_id_y'], axis=1, inplace=True)\n",
    "\n",
    "    pairs_df['nb_common_author'] = pairs_df.apply(lambda row: intersection(row['authors_1'], row['authors_2'])[0], axis=1)\n",
    "    pairs_df['is_common_author'] = pairs_df.apply(lambda row: intersection(row['authors_1'], row['authors_2'])[1], axis=1)\n",
    "\n",
    "    pairs_tensor = torch.LongTensor(np.transpose(pairs_df[[\"paper_1\", \"paper_2\", 'is_common_author', 'nb_common_author']].values.tolist())).to(device)\n",
    "    \n",
    "    return pairs_tensor\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "id": "HLahMzTSg4Xz"
   },
   "outputs": [],
   "source": [
    "def read_and_clean_abstracts (nodes, sample_length=-1, abstracts_path = 'https://www.lix.polytechnique.fr/~nikolentzos/files/aai/challenge/abstracts.txt'):\n",
    "    t = time()\n",
    "    abstracts = dict()\n",
    "    abstracts_list = list()\n",
    "    f = urlopen(abstracts_path)\n",
    "    \n",
    "    for i, line in tqdm(enumerate(f)):\n",
    "        if i == sample_length:\n",
    "            break\n",
    "        if i in nodes:\n",
    "            node, abstract = str(line).lower().split('|--|')\n",
    "            abstract = remove_stopwords(abstract)\n",
    "            #abstract = re.sub(r\"[,.;@#?!&$()-]\", \" \", abstract)\n",
    "            abstract = re.sub(r\"[^a-zA-Z0-9\\s]\", \"\", abstract)\n",
    "            #abstract = re.sub(r\"\\\\\", \" \", abstract)\n",
    "            abstract = remove_stopwords(abstract)\n",
    "\n",
    "            for word in abstract.split()[:-1]:\n",
    "                #abstract = abstract.replace(word, stemmer.stem(word))\n",
    "                abstract = abstract.replace(word, lemmatizer.lemmatize(lemmatizer.lemmatize(lemmatizer.lemmatize(lemmatizer.lemmatize(lemmatizer.lemmatize(lemmatizer.lemmatize(word), pos='s'), pos='a'), pos='n'), pos='v'), pos='r'))\n",
    "            \n",
    "            node = re.sub(\"[^0-9]\", \"\", node)\n",
    "            if i != int(node):\n",
    "                print('i and node not the same', i, node)\n",
    "            abstracts[int(node)] = abstract\n",
    "            abstracts_list.append(abstract)\n",
    "        \n",
    "    print('Text loaded and cleaned in {:.0f} min'.format((time()-t)/60))\n",
    "    return abstracts\n",
    "\n",
    "def doc_counter (documents, word): #a function that return the number of documents containing a word\n",
    "    counter = 0\n",
    "    for i in documents:\n",
    "        if word in documents[i]:\n",
    "            counter += 1\n",
    "    return counter\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "id": "8HP9n7D5g4Xz"
   },
   "outputs": [],
   "source": [
    "class Vocabulary:\n",
    "\n",
    "    def __init__(self, name):\n",
    "        self.name = name\n",
    "        self.word2index = {}\n",
    "        self.word2count = {}\n",
    "        self.index2word = {}\n",
    "        self.word_occurrence = {}\n",
    "        self.word2node = {}\n",
    "        self.words_list = []\n",
    "        self.sentences_list = []\n",
    "        self.sentences_list_words = []\n",
    "        self.num_words = 0\n",
    "        self.num_sentences = 0\n",
    "        self.longest_sentence = 0\n",
    "\n",
    "    def add_word(self, word, node):\n",
    "        if word not in self.word2index:\n",
    "            # First entry of word into vocabulary\n",
    "            self.words_list.append(word)\n",
    "            self.word2index[word] = self.num_words\n",
    "            self.word2count[word] = 1\n",
    "            self.index2word[self.num_words] = word\n",
    "            self.num_words += 1\n",
    "            self.word_occurrence[word] = 1\n",
    "            self.word2node[word] = [node]\n",
    "        else:\n",
    "            # Word exists; increase word count\n",
    "            self.word2count[word] += 1\n",
    "            self.word_occurrence[word] += 1\n",
    "            if node not in self.word2node[word]:\n",
    "                self.word2node[word].append(node)\n",
    "            # self.num_words += 1\n",
    "            \n",
    "    def add_sentence(self, sentence, node):\n",
    "        sentence_len = 0\n",
    "        for word in sentence.split()[:-1]:\n",
    "            sentence_len += 1\n",
    "            self.add_word(word, node)\n",
    "        if sentence_len > self.longest_sentence:\n",
    "            # This is the longest sentence\n",
    "            self.longest_sentence = sentence_len\n",
    "        # Count the number of sentences\n",
    "        self.num_sentences += 1\n",
    "        self.sentences_list.append(sentence)\n",
    "        self.sentences_list_words.append(sentence.split()[:-1])\n",
    "\n",
    "    def to_word(self, index):\n",
    "        return self.index2word[index]\n",
    "\n",
    "    def to_index(self, word):\n",
    "        return self.word2index[word]\n",
    "\n",
    "    def words(self):\n",
    "        return self.words_list\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {
    "id": "frfxHnMT0zNn"
   },
   "outputs": [],
   "source": [
    "def prepare_data_to_train (features, authors, adj, auth_matrix, indices, val_indices, y_val):\n",
    "    \n",
    "    print('Preparing the data for training...')\n",
    "    \n",
    "    t = time()\n",
    "    \n",
    "    y_val = torch.LongTensor(y_val).to(device)\n",
    "\n",
    "    # Create class labels\n",
    "    y = np.zeros(2*indices.shape[1])\n",
    "    y[:indices.shape[1]] = 1 # Concatenated ones for edges indices and later in the model we add zeros for random indices.\n",
    "    y = torch.LongTensor(y).to(device)\n",
    "    \n",
    "    features = torch.FloatTensor(features).to(device)\n",
    "    \n",
    "    indices = torch.LongTensor(indices).to(device)\n",
    "    adj = sparse_mx_to_torch_sparse_tensor(adj).to(device)\n",
    "    auth_matrix = sparse_mx_to_torch_sparse_tensor(auth_matrix).to(device)\n",
    "    #tfidf_matrix = sparse_mx_to_torch_sparse_tensor(tfidf_matrix).to(device)\n",
    "    \n",
    "    # the function add_authors_to_pairs converts into torch tensors and sends to Device    \n",
    "    val_indices = add_authors_to_pairs(val_indices, authors) #we add the authors to val_pairs\n",
    "    indices = add_authors_to_pairs(indices, authors) #we add the authors to indices    \n",
    "    #rand_indices = np.random.randint(0, features.shape[0], (indices.shape[0],indices.shape[1]))# We take random indices each time we run an epoch\n",
    "    #rand_indices = add_authors_to_pairs(rand_indices, authors)\n",
    "\n",
    "    #pairs = torch.cat((indices, rand_indices), dim=1) # Concatenate the edges indices and random indices.\n",
    "    #indices = torch.LongTensor(indices).to(device)\n",
    "    del(authors, indices, rand_indices)\n",
    "    \n",
    "    print('Data converted into torch tensors and authors added to indices in {:.0f} min'.format((time()-t)/60))\n",
    "\n",
    "    return features, adj, auth_matrix, indices, y, val_indices, y_val "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "id": "VBxraTeM0zNn"
   },
   "outputs": [],
   "source": [
    "def map_features_with_permutation(features, permutation):\n",
    "    new_features = np.zeros((len(features), len(features[0])))\n",
    "    for i in range(len(features)):\n",
    "        new_features[i] = features[permutation[i]]\n",
    "    return new_features"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Ubeigqung4X0"
   },
   "source": [
    "# Load graph and authors data from sources"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "Oe6DhotaSuqg",
    "outputId": "9b3c3b2d-8645-455a-88dc-1f8005764a26"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of nodes: 138499 number of edges: 1091955 in the Complete set\n",
      "Number of nodes: 138499 number of edges: 982621 in the Training set\n",
      "len(nodes) 138499\n",
      "Creating random val_edges...\n",
      "Returned G_train, train_edges, val_edges, y_val, nodes and node_to_idx objects\n",
      "Loaded from edgelist.txt and with a training validation split ratio = 0.1\n",
      "graph loaded and seperated, val indices generated and node to index mapping returned in 10 s\n"
     ]
    }
   ],
   "source": [
    "t = time()\n",
    "shuffle = False\n",
    "G, G_train, train_edges, val_edges, val_indices, y_val, nodes, node_to_idx, permutation, mapping_permutation = read_train_val_graph(val_ratio=0.1, shuffle=shuffle)\n",
    "\n",
    "print('graph loaded and seperated, val indices generated and node to index mapping returned in {:.0f} s'.format(time()-t))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "EyBibxd6zQhV",
    "outputId": "2dc19344-a28c-4f59-a835-7846b8c109e6"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/pd/glcnl2497w5b6xn3p94tnwlr0000gn/T/ipykernel_5628/1362963898.py:163: FutureWarning: adjacency_matrix will return a scipy.sparse array instead of a matrix in Networkx 3.0.\n",
      "  adj = nx.adjacency_matrix(G) # Obtains the adjacency matrix of the training graph\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Created a normalized adjancency matrix of shape (138499, 138499)\n",
      "Created indices (2, 1965394) with the positions of non zeros in adj matrix\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/pd/glcnl2497w5b6xn3p94tnwlr0000gn/T/ipykernel_5628/1362963898.py:155: RuntimeWarning: divide by zero encountered in power\n",
      "  d_inv_sqrt = np.power(rowsum, -0.5).flatten()\n"
     ]
    }
   ],
   "source": [
    "adj, indices = create_and_normalize_adjacency(G_train)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 206
    },
    "id": "dWAzHqmxmYff",
    "outputId": "030ce381-c869-4555-e0d5-364e8c57dff6",
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>paper_id</th>\n",
       "      <th>authors</th>\n",
       "      <th>paper_permut</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>[James H. Niblock, JianXun Peng, Karen R. McMe...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>[JianXun Peng, Kang Li, DeShuang Huang]</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>[J. Heikkila]</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>[L. Teslic, B. Hartmann, O. Nelles, I. Skrjanc]</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>[Long Zhang, Kang Li, ErWei Bai, George W. Irwin]</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   paper_id                                            authors  paper_permut\n",
       "0         0  [James H. Niblock, JianXun Peng, Karen R. McMe...             0\n",
       "1         1            [JianXun Peng, Kang Li, DeShuang Huang]             1\n",
       "2         2                                      [J. Heikkila]             2\n",
       "3         3    [L. Teslic, B. Hartmann, O. Nelles, I. Skrjanc]             3\n",
       "4         4  [Long Zhang, Kang Li, ErWei Bai, George W. Irwin]             4"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "authors = pd.read_csv(urlopen('https://www.lix.polytechnique.fr/~nikolentzos/files/aai/challenge/authors.txt'), sep = '|', header=None)\n",
    "authors = authors.rename(columns={0: \"paper_id\", 2: \"authors\"})\n",
    "authors['authors'] = authors['authors'].apply(text_to_list)\n",
    "authors = authors[[\"paper_id\", \"authors\"]]\n",
    "authors = authors[authors['paper_id'] <= max(G.nodes())]\n",
    "authors['paper_permut'] = permutation[authors['paper_id']]\n",
    "authors.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 130,
     "referenced_widgets": [
      "b6221c60dfdb4309b6d69db47f5621f1",
      "b768368f52cb4f3d9539caf48fc459c1",
      "1888371c988242c48ba436784b533166",
      "f9282ecb07174c38be1a3dc45ea4a5c2",
      "5faac6ba5e604a3198ad9a5c49f1e2a7",
      "0b776c922cd9412a8dfd8d49ae48bf43",
      "15f1079aff04427d9eab2d7c97fb014e",
      "3f0f112951ca4057960fe2bc33b10acd",
      "029723804c3b420bacce0e1ddd6bc87a",
      "059d6431e6f14c66b9fc272836660c56",
      "ef74a17c91af4def9f5082d345ba5b33",
      "aa38ef49eae14de1800c0d7fb216754b",
      "121f5c36582c4275807e15cb4ba84f30",
      "2c2b5fbf8e41412c949964f2b6cef0d7",
      "7c4a409918d24f71a2b24ea4bf9b1049",
      "8b37044a7d4a4da1adfd9f40b9e27303",
      "dea8d64c83754027b88f54ebc4ffd50c",
      "f428b21f4ed24ac49092742038b20606",
      "6da88af0c4414d758f684ff1258953bd",
      "74cbbff36ac0492b937ad026df2803b1",
      "35ed948eaffd448eb483d863af5b492c",
      "2b681147457b4f859a7d9274012a004a",
      "9b86291845ec4f5b83c8764ed836289e",
      "2cb1d8e27a5346388abcebec1a1ece58",
      "acaa2745e8fc468fadcd0fcc0ff9d324",
      "e7460e2510704b458993133be5fc07bf",
      "c5812332ac6849d1b6e0b28f40d98f5f",
      "d524bbfc74a346f6954f15dad0eeedf1",
      "980cc9d1a24d459f901915403956e030",
      "7bd39cd6acfb4f21ace5dd23f1a82360",
      "6b26bf5844884b34b5cc3c2b8765f6d5",
      "18700b2d971f42d5973f0573dbe397c3",
      "88102ef32915417da9df4562ec493adb"
     ]
    },
    "id": "YQw6HQUT9c_t",
    "outputId": "870561ed-320a-420e-cfda-12833c817a7e"
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "69dcafcfe4c54eae8484015f808b12ea",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/138499 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "93da840b3fda40c08cc2492e1bf5fe0f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0e66987ce1b345bca239db880e0fda1f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(138499, 147481)\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from scipy.sparse import csr_matrix\n",
    "\n",
    "\n",
    "# get the unique list of authors\n",
    "authors_lst_ppr = list(set([a for authors_list in tqdm(authors['authors']) for a in authors_list]))\n",
    "\n",
    "# create a mapping of author to index\n",
    "author_to_index = {author: i for i, author in tqdm(enumerate(authors_lst_ppr))}\n",
    "\n",
    "# create an empty sparse matrix\n",
    "nrows = len(authors)\n",
    "ncols = len(authors_lst_ppr)\n",
    "data = np.ones(nrows)\n",
    "row_ind = np.arange(nrows)\n",
    "col_ind = np.zeros(nrows)\n",
    "\n",
    "# fill in the sparse matrix with 1 where authors appear\n",
    "for i, authors_list in tqdm(enumerate(authors['authors'])):\n",
    "    for author in authors_list:\n",
    "        col_ind[i] = author_to_index[author]\n",
    "        row_ind[i] = i\n",
    "        data[i] = 1\n",
    "auth_matrix = csr_matrix((data, (row_ind, col_ind)), shape=(nrows, ncols))\n",
    "\n",
    "# print the resulting sparse matrix\n",
    "print(auth_matrix.shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['',\n",
       " ' A',\n",
       " ' Belitski',\n",
       " ' Budzianowski',\n",
       " ' S',\n",
       " ' Sra',\n",
       " 'A A Lazar',\n",
       " 'A A Nanavati',\n",
       " 'A A Nielsen',\n",
       " 'A Agah',\n",
       " 'A Alessandri',\n",
       " 'A Altinok',\n",
       " 'A Amer',\n",
       " 'A Averbuch',\n",
       " 'A Aydin Alatan',\n",
       " 'A B Ingole',\n",
       " 'A Banerjee',\n",
       " 'A Barmpoutis',\n",
       " 'A Biem',\n",
       " 'A Bilgin',\n",
       " 'A Bouguettaya',\n",
       " 'A Bouridane',\n",
       " 'A C Bovik',\n",
       " 'A C S Chung',\n",
       " 'A Ciancio',\n",
       " 'A Cichocki',\n",
       " 'A Cleanthous',\n",
       " 'A Criminisi',\n",
       " 'A Datta',\n",
       " 'A Del Bimbo',\n",
       " 'A Doshi',\n",
       " 'A Doulamis',\n",
       " 'A Dufour',\n",
       " 'A Elmoataz',\n",
       " 'A F Atiya',\n",
       " 'A F Frangi',\n",
       " 'A Floratou',\n",
       " 'A Foi',\n",
       " 'A G Bors',\n",
       " 'A G Loukianov',\n",
       " 'A Gal',\n",
       " 'A Giannoula',\n",
       " 'A Gijsenij',\n",
       " 'A Gilbert',\n",
       " 'A Graser',\n",
       " 'A Gretton',\n",
       " 'A Guzzo',\n",
       " 'A H Eid',\n",
       " 'A H Mir',\n",
       " 'A H. Karimi',\n",
       " 'A Irle',\n",
       " 'A J Serrano',\n",
       " 'A J Smola',\n",
       " 'A K Jain',\n",
       " 'A K Pal',\n",
       " 'A K Qin',\n",
       " 'A K RoyChowdhury',\n",
       " 'A Karpenko',\n",
       " 'A Kashyap',\n",
       " 'A Kembhavi',\n",
       " 'A Khosravi',\n",
       " 'A Kumar',\n",
       " 'A Kumaran',\n",
       " 'A Lisowska',\n",
       " 'A M Lopez',\n",
       " 'A M Martinez',\n",
       " 'A M Yip',\n",
       " 'A Mitiche',\n",
       " 'A MohammadDjafari',\n",
       " 'A N Rajagopalan',\n",
       " 'A Oikonomopoulos',\n",
       " 'A Ortega',\n",
       " 'A P Sheppard',\n",
       " 'A P Shivaprasad',\n",
       " 'A Perina',\n",
       " 'A Pesarin',\n",
       " 'A Picariello',\n",
       " 'A Pukrittayakamee',\n",
       " 'A R Balamurali',\n",
       " 'A R FigueirasVidal',\n",
       " 'A Rahman',\n",
       " 'A Ranganathan',\n",
       " 'A Ravichandran',\n",
       " 'A Robin',\n",
       " 'A RoblesKelly',\n",
       " 'A Rocha',\n",
       " 'A Rodan',\n",
       " 'A Russell',\n",
       " 'A Sellent',\n",
       " 'A Srivastava',\n",
       " 'A T Naman',\n",
       " 'A Tannenbaum',\n",
       " 'A Tavano',\n",
       " 'A Tome',\n",
       " 'A Troncoso',\n",
       " 'A Uhl',\n",
       " 'A V Bhavsar',\n",
       " 'A V Subramanyam',\n",
       " 'A Veeraraghavan',\n",
       " 'A Vinciarelli',\n",
       " 'A Vlachou',\n",
       " 'A W M Smeulders',\n",
       " 'A Y Alanis',\n",
       " 'A YS Chia',\n",
       " 'A Yezzi',\n",
       " 'A Zaharescu',\n",
       " 'A Zien',\n",
       " 'A Zimek',\n",
       " 'A Zisserman',\n",
       " 'A. A. Alatan',\n",
       " 'A. A. Argyros',\n",
       " 'A. A. Bell',\n",
       " 'A. A. Brink',\n",
       " 'A. A. Farag',\n",
       " 'A. A. Hamed',\n",
       " 'A. A. Kassim',\n",
       " 'A. A. Khokhar',\n",
       " 'A. A. Manjili',\n",
       " 'A. A. Moaty',\n",
       " 'A. A. Moghadam',\n",
       " 'A. A. Mohammed',\n",
       " 'A. A. Salah',\n",
       " 'A. A. W. Smith',\n",
       " 'A. A. Zaidan',\n",
       " 'A. Aaron',\n",
       " 'A. Abbas',\n",
       " 'A. Abbasi',\n",
       " 'A. AbdelTawab',\n",
       " 'A. Abdelrahim',\n",
       " 'A. Abergel',\n",
       " 'A. Abhyankar',\n",
       " 'A. Aboulnaga',\n",
       " 'A. Abraham',\n",
       " 'A. Abramo',\n",
       " 'A. Abrams',\n",
       " 'A. Abubakar',\n",
       " 'A. Abubaker',\n",
       " 'A. Achim',\n",
       " 'A. AcostaJimenez',\n",
       " 'A. Adam',\n",
       " 'A. Adam Ding',\n",
       " 'A. Adamo',\n",
       " 'A. Adan',\n",
       " 'A. Adya',\n",
       " 'A. Afanasyeva',\n",
       " 'A. Agarwal',\n",
       " 'A. Agarwala',\n",
       " 'A. Aggoun',\n",
       " 'A. Aghagolzadeh',\n",
       " 'A. Agrawal',\n",
       " 'A. Agudo',\n",
       " 'A. Ahmadi',\n",
       " 'A. Ahmed',\n",
       " 'A. Aiken',\n",
       " 'A. Ailamaki',\n",
       " 'A. AissaElBey',\n",
       " 'A. Aissaoui',\n",
       " 'A. Akbarzadeh',\n",
       " 'A. Akimov',\n",
       " 'A. Aksay',\n",
       " 'A. Aksel',\n",
       " 'A. AkselrodBallin',\n",
       " 'A. Al',\n",
       " 'A. AlHamadi',\n",
       " 'A. AlKabbany',\n",
       " 'A. AlKouz',\n",
       " 'A. AlMamun',\n",
       " 'A. Alahi',\n",
       " 'A. Alansary',\n",
       " 'A. Alatan',\n",
       " 'A. Albiol',\n",
       " 'A. Albore',\n",
       " 'A. AlbouyKissi',\n",
       " 'A. Aldama',\n",
       " 'A. Aldea',\n",
       " 'A. Aldroubi',\n",
       " 'A. Alecu',\n",
       " 'A. Alessandri',\n",
       " 'A. Alexander',\n",
       " 'A. Alexandridis',\n",
       " 'A. Ali',\n",
       " 'A. Alla',\n",
       " 'A. Allauzen',\n",
       " 'A. Almansa',\n",
       " 'A. Almog',\n",
       " 'A. AlonsoBetanzos',\n",
       " 'A. Alqahtani',\n",
       " 'A. Altinok',\n",
       " 'A. Alttnok',\n",
       " 'A. Aly Halim',\n",
       " 'A. Alzati',\n",
       " 'A. Alzghoul',\n",
       " 'A. Amara',\n",
       " 'A. Amato',\n",
       " 'A. Ambash',\n",
       " 'A. Amelio',\n",
       " 'A. Amer',\n",
       " 'A. Aminlou',\n",
       " 'A. Amintabar',\n",
       " 'A. Amir',\n",
       " 'A. Amira',\n",
       " 'A. Amirbekyan',\n",
       " 'A. An',\n",
       " 'A. Anand',\n",
       " 'A. Andreopoulos',\n",
       " 'A. Aner',\n",
       " 'A. AnerWolf',\n",
       " 'A. Angelopoulou',\n",
       " 'A. Angelova',\n",
       " 'A. Anjulan',\n",
       " 'A. Ansar',\n",
       " 'A. Appice',\n",
       " 'A. Apte',\n",
       " 'A. Aragones',\n",
       " 'A. Arasu',\n",
       " 'A. Araujo',\n",
       " 'A. ArauzoAzofra',\n",
       " 'A. Aravkin',\n",
       " 'A. Ardeshir Goshtasby',\n",
       " 'A. Ardovini',\n",
       " 'A. Argentini',\n",
       " 'A. Arguelles',\n",
       " 'A. Argyros',\n",
       " 'A. Arleo',\n",
       " 'A. Armato',\n",
       " 'A. Arnold',\n",
       " 'A. Arnt',\n",
       " 'A. Arora',\n",
       " 'A. Artale',\n",
       " 'A. ArtesRodriguez',\n",
       " 'A. Artusi',\n",
       " 'A. Arunkumar',\n",
       " 'A. Arvanitakis',\n",
       " 'A. Assadi',\n",
       " 'A. Assoum',\n",
       " 'A. Astorino',\n",
       " 'A. Atiya',\n",
       " 'A. Auclair',\n",
       " 'A. Aussem',\n",
       " 'A. Averbuch',\n",
       " 'A. Awan',\n",
       " 'A. Axenopoulos',\n",
       " 'A. Ayache',\n",
       " 'A. Ayad',\n",
       " 'A. Aydemir',\n",
       " 'A. Aydin Alatan',\n",
       " 'A. Ayvaci',\n",
       " 'A. Aziz',\n",
       " 'A. Azran',\n",
       " 'A. B. Cambra',\n",
       " 'A. B. Chan',\n",
       " 'A. B. Hamza',\n",
       " 'A. B. J. Teoh',\n",
       " 'A. B. Moreno',\n",
       " 'A. B. Tsybakov',\n",
       " 'A. BabHadiashar',\n",
       " 'A. Babaeian',\n",
       " 'A. Babloyantz',\n",
       " 'A. Back',\n",
       " 'A. Backhouse',\n",
       " 'A. Badia',\n",
       " 'A. Baeza',\n",
       " 'A. Bagchi',\n",
       " 'A. Bagheri',\n",
       " 'A. Bagherjeiran',\n",
       " 'A. Bahamonde',\n",
       " 'A. Baillard',\n",
       " 'A. Bajaj',\n",
       " 'A. Bal',\n",
       " 'A. Balan',\n",
       " 'A. Balasubramanian',\n",
       " 'A. Balasuriya',\n",
       " 'A. Balavoine',\n",
       " 'A. Balmin',\n",
       " 'A. Bandera',\n",
       " 'A. Banerjee',\n",
       " 'A. Bannat',\n",
       " 'A. Banno',\n",
       " 'A. BarHillel',\n",
       " 'A. BarOr',\n",
       " 'A. Baraldi',\n",
       " 'A. Barbu',\n",
       " 'A. Bardera',\n",
       " 'A. Bargiela',\n",
       " 'A. Baric',\n",
       " 'A. Barkana',\n",
       " 'A. Barla',\n",
       " 'A. Barmpoutis',\n",
       " 'A. Barreiro',\n",
       " 'A. Bartesaghi',\n",
       " 'A. Bartoli',\n",
       " 'A. Basarab',\n",
       " 'A. Basharat',\n",
       " 'A. Baskurt',\n",
       " 'A. Bassi',\n",
       " 'A. Basso',\n",
       " 'A. Bastys',\n",
       " 'A. Basu',\n",
       " 'A. Baumberg',\n",
       " 'A. Bayestehtashlc',\n",
       " 'A. Beck',\n",
       " 'A. Becker',\n",
       " 'A. Beghdadi',\n",
       " 'A. Behal',\n",
       " 'A. Behrens',\n",
       " 'A. Bekkali',\n",
       " 'A. Belahmidi',\n",
       " 'A. Belatreche',\n",
       " 'A. Belhedi',\n",
       " 'A. Bellmann',\n",
       " 'A. Belloum',\n",
       " 'A. Belouchrani',\n",
       " 'A. Belz',\n",
       " 'A. Ben Hamidd',\n",
       " 'A. Ben Hamza',\n",
       " 'A. BenazzaBenyahia',\n",
       " 'A. Bendale',\n",
       " 'A. Benedetti',\n",
       " 'A. Benoit',\n",
       " 'A. Bensimon',\n",
       " 'A. Benslimane',\n",
       " 'A. Bensrhair',\n",
       " 'A. Benzinou',\n",
       " 'A. Beoldo',\n",
       " 'A. Berengolts',\n",
       " 'A. Berg',\n",
       " 'A. Berge',\n",
       " 'A. Beric',\n",
       " 'A. Bermak',\n",
       " 'A. Bernardino',\n",
       " 'A. Bernstein',\n",
       " 'A. Berthoz',\n",
       " 'A. Besga',\n",
       " 'A. Bestavros',\n",
       " 'A. Beutel',\n",
       " 'A. Bevilacqua',\n",
       " 'A. Beyeler',\n",
       " 'A. Beygelzimer',\n",
       " 'A. Bezerianos',\n",
       " 'A. Bhalerao',\n",
       " 'A. Bharath',\n",
       " 'A. Bharati',\n",
       " 'A. Bhattacharya',\n",
       " 'A. Bhatti',\n",
       " 'A. Bhaya',\n",
       " 'A. Bhuiyan',\n",
       " 'A. Bhusnurmath',\n",
       " 'A. Bianchetti',\n",
       " 'A. Bianchi',\n",
       " 'A. Biem',\n",
       " 'A. Bikakis',\n",
       " 'A. Bilgin',\n",
       " 'A. Biliris',\n",
       " 'A. Bilke',\n",
       " 'A. Billard',\n",
       " 'A. Birk',\n",
       " 'A. Bishnu',\n",
       " 'A. Bissacco',\n",
       " 'A. Bistoquet',\n",
       " 'A. Biswas',\n",
       " 'A. Blake',\n",
       " 'A. Blanco',\n",
       " 'A. Blansche',\n",
       " 'A. Blumenstock',\n",
       " 'A. Boag',\n",
       " 'A. Bobick',\n",
       " 'A. Bocking',\n",
       " 'A. Bofill',\n",
       " 'A. BofilliPetit',\n",
       " 'A. Bol',\n",
       " 'A. Bolovinou',\n",
       " 'A. Bolshoy',\n",
       " 'A. Bondu',\n",
       " 'A. Boni',\n",
       " 'A. Bonifati',\n",
       " 'A. Bonnin',\n",
       " 'A. Borgida',\n",
       " 'A. Borji',\n",
       " 'A. Borkar',\n",
       " 'A. Bortoletti',\n",
       " 'A. Bosch',\n",
       " 'A. Boschetti',\n",
       " 'A. Bottino',\n",
       " 'A. Bottrighi',\n",
       " 'A. Boudghene Stambouli',\n",
       " 'A. Bouguettaya',\n",
       " 'A. Bouhouch',\n",
       " 'A. Boulanger',\n",
       " 'A. Boulkroune',\n",
       " 'A. Bourge',\n",
       " 'A. Bouridane',\n",
       " 'A. Bourquard',\n",
       " 'A. Boutet',\n",
       " 'A. Bouzerdoum',\n",
       " 'A. Bouzeriba',\n",
       " 'A. Bouziane',\n",
       " 'A. Bowen',\n",
       " 'A. Bradley',\n",
       " 'A. Brahim',\n",
       " 'A. Branca',\n",
       " 'A. Brandt',\n",
       " 'A. Branzan Albu',\n",
       " 'A. Braverman',\n",
       " 'A. Bravo',\n",
       " 'A. Bray',\n",
       " 'A. Brechmann',\n",
       " 'A. Briassouli',\n",
       " 'A. Broadhurst',\n",
       " 'A. Brockwell',\n",
       " 'A. Brodsky',\n",
       " 'A. Broggi',\n",
       " 'A. Brook',\n",
       " 'A. Browet',\n",
       " 'A. Browne',\n",
       " 'A. Bruckstein',\n",
       " 'A. Bruhn',\n",
       " 'A. Bruns',\n",
       " 'A. Buades',\n",
       " 'A. Buchanan',\n",
       " 'A. Bugatti',\n",
       " 'A. Bugeau',\n",
       " 'A. Buisson',\n",
       " 'A. Bulut',\n",
       " 'A. Bur',\n",
       " 'A. Burian',\n",
       " 'A. Busch',\n",
       " 'A. Busti',\n",
       " 'A. C. A. del Valle',\n",
       " 'A. C. Berg',\n",
       " 'A. C. Bovik',\n",
       " 'A. C. Carvalho',\n",
       " 'A. C. Civelek',\n",
       " 'A. C. Gallagher',\n",
       " 'A. C. Gilbert',\n",
       " 'A. C. Kak',\n",
       " 'A. C. Kot',\n",
       " 'A. C. Loui',\n",
       " 'A. C. MartinezEstudillo',\n",
       " 'A. C. Murillo',\n",
       " 'A. C. Rogers',\n",
       " 'A. C. S. Chung',\n",
       " 'A. C. Sankaranarayanan',\n",
       " 'A. C. Serra',\n",
       " 'A. C. Tsoi',\n",
       " 'A. Cakmak',\n",
       " 'A. Calise',\n",
       " 'A. Call',\n",
       " 'A. Calway',\n",
       " 'A. Camara',\n",
       " 'A. Campi',\n",
       " 'A. Can',\n",
       " 'A. Canclini',\n",
       " 'A. Capela',\n",
       " 'A. Caplier',\n",
       " 'A. Carbone',\n",
       " 'A. Carboni',\n",
       " 'A. Carkacioglu',\n",
       " 'A. Carleton',\n",
       " 'A. Carlson',\n",
       " 'A. CarmonaPoyato',\n",
       " 'A. Cary',\n",
       " 'A. Cassandra',\n",
       " 'A. Castano',\n",
       " 'A. Catali',\n",
       " 'A. Cavallaro',\n",
       " 'A. Cengiz Oztireli',\n",
       " 'A. Censi',\n",
       " 'A. Cesta',\n",
       " 'A. Chaabouni',\n",
       " 'A. Chaker',\n",
       " 'A. Chakrabarti',\n",
       " 'A. Chakraborty',\n",
       " 'A. Chalamalla',\n",
       " 'A. Chalechale',\n",
       " 'A. Chalmers',\n",
       " 'A. Chambolle',\n",
       " 'A. Chandel',\n",
       " 'A. Chandrasekar',\n",
       " 'A. Chandrasekhar',\n",
       " 'A. Chang',\n",
       " 'A. Charchanti',\n",
       " 'A. Chatterjee',\n",
       " 'A. Chattopadhyay',\n",
       " 'A. Chaudhary',\n",
       " 'A. Chaudhry',\n",
       " 'A. Chebira',\n",
       " 'A. Chebotko',\n",
       " 'A. Chella',\n",
       " 'A. Cherian',\n",
       " 'A. Chessel',\n",
       " 'A. Chia',\n",
       " 'A. Chianese',\n",
       " 'A. Chimienti',\n",
       " 'A. Chiuso',\n",
       " 'A. Choksuriwong',\n",
       " 'A. Chouchane',\n",
       " 'A. Chowdhury',\n",
       " 'A. Chung',\n",
       " 'A. Churkin',\n",
       " 'A. Chutatape',\n",
       " 'A. Ciampi',\n",
       " 'A. Ciaramella',\n",
       " 'A. Cichocki',\n",
       " 'A. Cid',\n",
       " 'A. Cimatti',\n",
       " 'A. Cinar',\n",
       " 'A. Cioppa',\n",
       " 'A. Civilis',\n",
       " 'A. Civit',\n",
       " 'A. CivitBalcells',\n",
       " 'A. CivitBallcels',\n",
       " 'A. Clare',\n",
       " 'A. Cleeremans',\n",
       " 'A. Coath',\n",
       " 'A. Cochet',\n",
       " 'A. Coddington',\n",
       " 'A. Coden',\n",
       " 'A. Coelho',\n",
       " 'A. Cohen',\n",
       " 'A. Colantonio',\n",
       " 'A. Collet',\n",
       " 'A. Colmenarez',\n",
       " 'A. Colombari',\n",
       " 'A. Colomer',\n",
       " 'A. Colosimo',\n",
       " 'A. Coman',\n",
       " 'A. Combaz',\n",
       " 'A. Combernoux',\n",
       " 'A. Conci',\n",
       " 'A. Conrad Bovik',\n",
       " 'A. Corazza',\n",
       " 'A. Corduneanu',\n",
       " 'A. Cosar',\n",
       " 'A. Costanzo',\n",
       " 'A. Coste',\n",
       " 'A. Courville',\n",
       " 'A. Crawford',\n",
       " 'A. Crespo',\n",
       " 'A. Criminisi',\n",
       " 'A. Crouzil',\n",
       " 'A. Cruz',\n",
       " 'A. Cuhadar',\n",
       " 'A. Cuzol',\n",
       " 'A. D. Bagdanov',\n",
       " 'A. D. Rast',\n",
       " 'A. D. Sappa',\n",
       " 'A. D. Whitehead',\n",
       " 'A. DAngelo',\n",
       " 'A. Dalalyan',\n",
       " 'A. Daneshgar',\n",
       " 'A. Dang Thanh Trung',\n",
       " 'A. Danielyan',\n",
       " 'A. Danilin',\n",
       " 'A. Danov',\n",
       " 'A. Dante',\n",
       " 'A. Daouzli',\n",
       " 'A. Darabiha',\n",
       " 'A. Dardzinska',\n",
       " 'A. Darzi',\n",
       " 'A. Das',\n",
       " 'A. Das Sarma',\n",
       " 'A. Datta',\n",
       " 'A. Davella',\n",
       " 'A. David Edwards',\n",
       " 'A. David Marshall',\n",
       " 'A. David Redish',\n",
       " 'A. Davidson',\n",
       " 'A. Davison',\n",
       " 'A. Dawoud',\n",
       " 'A. De AsiS',\n",
       " 'A. De Rosa',\n",
       " 'A. De Santis',\n",
       " 'A. De Stefano',\n",
       " 'A. Declercq',\n",
       " 'A. Del Bimbo',\n",
       " 'A. Del Bue',\n",
       " 'A. Del Mastio',\n",
       " 'A. DelPozo',\n",
       " 'A. Delalleau',\n",
       " 'A. Deliege',\n",
       " 'A. Deligiannakis',\n",
       " 'A. Delis',\n",
       " 'A. DellAcqua',\n",
       " 'A. Della Cioppa',\n",
       " 'A. Delong',\n",
       " 'A. Delopoulos',\n",
       " 'A. Demiriz',\n",
       " 'A. Dentinger',\n",
       " 'A. Denton',\n",
       " 'A. Descampe',\n",
       " 'A. Descour',\n",
       " 'A. Deshpande',\n",
       " 'A. Desolneux',\n",
       " 'A. Destexhe',\n",
       " 'A. Destrero',\n",
       " 'A. Deutsch',\n",
       " 'A. Dev',\n",
       " 'A. Dey',\n",
       " 'A. Di Blas',\n",
       " 'A. Di Lillo',\n",
       " 'A. Diaz de Ilarraza',\n",
       " 'A. Dick',\n",
       " 'A. Dignos',\n",
       " 'A. Dima',\n",
       " 'A. Dimitrios',\n",
       " 'A. Dimou',\n",
       " 'A. Diosi',\n",
       " 'A. Dipanda',\n",
       " 'A. Diplaros',\n",
       " 'A. Distante',\n",
       " 'A. Divakaran',\n",
       " 'A. Doan',\n",
       " 'A. Doncescu',\n",
       " 'A. Donnelly',\n",
       " 'A. Dooms',\n",
       " 'A. Dorado',\n",
       " 'A. Dore',\n",
       " 'A. Doshi',\n",
       " 'A. Doufexi',\n",
       " 'A. Doulamis',\n",
       " 'A. Dourado',\n",
       " 'A. Doustmohammadi',\n",
       " 'A. Dovier',\n",
       " 'A. Dricot',\n",
       " 'A. Dries',\n",
       " 'A. Drobchenko',\n",
       " 'A. Drosopoulos',\n",
       " 'A. Drosou',\n",
       " 'A. Druet',\n",
       " 'A. Drzezga',\n",
       " 'A. Duci',\n",
       " 'A. Dufaux',\n",
       " 'A. Dufour',\n",
       " 'A. Duggins',\n",
       " 'A. Dumitras',\n",
       " 'A. Dupasquier',\n",
       " 'A. Dupret',\n",
       " 'A. Duquette',\n",
       " 'A. DuretLutz',\n",
       " 'A. Dziech',\n",
       " 'A. E. Abbadi',\n",
       " 'A. E. AbdelHakim',\n",
       " 'A. E. C. Pece',\n",
       " 'A. E. Cetin',\n",
       " 'A. E. Delgado',\n",
       " 'A. E. Eiben',\n",
       " 'A. E. Esteban',\n",
       " 'A. E. Hassanien',\n",
       " 'A. E. Kostopoulos',\n",
       " 'A. EbrahimiMoghadam',\n",
       " 'A. Ecker',\n",
       " 'A. Eden',\n",
       " 'A. Efrat',\n",
       " 'A. Egozi',\n",
       " 'A. Eid',\n",
       " 'A. Ekin',\n",
       " 'A. Eklund',\n",
       " 'A. El Abbadi',\n",
       " 'A. El Essaili',\n",
       " 'A. El Gamal',\n",
       " 'A. El Hamidi',\n",
       " 'A. El Tanboly',\n",
       " 'A. ElBaz',\n",
       " 'A. ElDessouki',\n",
       " 'A. ElHelw',\n",
       " 'A. ElSaddik',\n",
       " 'A. ElSallam',\n",
       " 'A. Elad',\n",
       " 'A. Eleftheriadis',\n",
       " 'A. Eleuteri',\n",
       " 'A. Elgammal',\n",
       " 'A. Elghazal',\n",
       " 'A. Elhayek',\n",
       " 'A. Ellmauthaler',\n",
       " 'A. Elmagarmid',\n",
       " 'A. Elmaghraby',\n",
       " 'A. Elmoataz',\n",
       " 'A. Elnakib',\n",
       " 'A. Enis Cetin',\n",
       " 'A. Entezari',\n",
       " 'A. Ercil',\n",
       " 'A. Erdem',\n",
       " 'A. Erdmann',\n",
       " 'A. Erfanian',\n",
       " 'A. Eriksson',\n",
       " 'A. Erol',\n",
       " 'A. Ertuzun',\n",
       " 'A. Esposito',\n",
       " 'A. Ess',\n",
       " 'A. Even',\n",
       " 'A. Eweiwi',\n",
       " 'A. Ezeiza',\n",
       " 'A. F. Atiya',\n",
       " 'A. F. Clark',\n",
       " 'A. F. Laine',\n",
       " 'A. F. Pacheco',\n",
       " 'A. Fadeev',\n",
       " 'A. Faina',\n",
       " 'A. Fan',\n",
       " 'A. Faradjian',\n",
       " 'A. Farag',\n",
       " 'A. Farhadi',\n",
       " 'A. Farinelli',\n",
       " 'A. Farman',\n",
       " 'A. Faro',\n",
       " 'A. Fascioli',\n",
       " 'A. Fast',\n",
       " 'A. Fathi',\n",
       " 'A. Fazel Famili',\n",
       " 'A. Fazly',\n",
       " 'A. Feelders',\n",
       " 'A. Feher',\n",
       " 'A. Feinberg',\n",
       " 'A. Fekete',\n",
       " 'A. Feragen',\n",
       " 'A. Ferencz',\n",
       " 'A. Fern',\n",
       " 'A. Fernandez',\n",
       " 'A. FernndezHiguera',\n",
       " 'A. Ferrari',\n",
       " 'A. Ferrein',\n",
       " 'A. Ferro',\n",
       " 'A. Filippidis',\n",
       " 'A. Firjani',\n",
       " 'A. Fischer',\n",
       " 'A. Fitzgibbon',\n",
       " 'A. Fitzhugh',\n",
       " 'A. Foi',\n",
       " 'A. Fornells',\n",
       " 'A. Foss',\n",
       " 'A. Fossati',\n",
       " 'A. Fotinos',\n",
       " 'A. Foulonneau',\n",
       " 'A. Fox',\n",
       " 'A. Frajka',\n",
       " 'A. Franchois',\n",
       " 'A. Freitas',\n",
       " 'A. Freno',\n",
       " 'A. FriasVelazquez',\n",
       " 'A. Friedman',\n",
       " 'A. Frieze',\n",
       " 'A. FriisChristensen',\n",
       " 'A. Fu',\n",
       " 'A. Fuduli',\n",
       " 'A. Fujino',\n",
       " 'A. Fukunaga',\n",
       " 'A. Furnari',\n",
       " 'A. Fusiello',\n",
       " 'A. FusterGuillo',\n",
       " 'A. Fuxman',\n",
       " 'A. G. Amitha Perera',\n",
       " 'A. G. Bors',\n",
       " 'A. G. Chung',\n",
       " 'A. G. Constantinides',\n",
       " 'A. G. Hauptmann',\n",
       " 'A. G. Loukianov',\n",
       " 'A. G. Parlos',\n",
       " 'A. G. Yarovoy',\n",
       " 'A. Gabay',\n",
       " 'A. Gabriel',\n",
       " 'A. Gahlmann',\n",
       " 'A. Gaidon',\n",
       " 'A. Gal',\n",
       " 'A. Galata',\n",
       " 'A. Galiullin',\n",
       " 'A. Gallagher',\n",
       " 'A. Galland',\n",
       " 'A. Galton',\n",
       " 'A. Ganesh',\n",
       " 'A. Gangopadhyay',\n",
       " 'A. Gao',\n",
       " 'A. Garcea',\n",
       " 'A. GarciaAlberola',\n",
       " 'A. GarciaCerezo',\n",
       " 'A. GarciaGarcia',\n",
       " 'A. Garg',\n",
       " 'A. Garrido',\n",
       " 'A. Gartner',\n",
       " 'A. Garulli',\n",
       " 'A. Gavioli',\n",
       " 'A. Gavrilescu',\n",
       " 'A. Gelas',\n",
       " 'A. Gelb',\n",
       " 'A. Gelzinis',\n",
       " 'A. Genovesio',\n",
       " 'A. Gentile',\n",
       " 'A. Georgakis',\n",
       " 'A. Georgieva',\n",
       " 'A. Germain',\n",
       " 'A. Ghadesi',\n",
       " 'A. Ghafoor',\n",
       " 'A. Ghani',\n",
       " 'A. Ghio',\n",
       " 'A. Ghodsi',\n",
       " 'A. Gholipour',\n",
       " 'A. Ghose',\n",
       " 'A. Ghosh',\n",
       " 'A. Ghoting',\n",
       " 'A. Giachetti',\n",
       " 'A. Giani',\n",
       " 'A. Giannoula',\n",
       " 'A. Giaquinto',\n",
       " 'A. Gijsenij',\n",
       " 'A. Gillette',\n",
       " 'A. Gionis',\n",
       " 'A. Giordana',\n",
       " 'A. Giron',\n",
       " 'A. Giusti',\n",
       " 'A. GkoulalasDivanis',\n",
       " 'A. Glantz',\n",
       " 'A. Glaser',\n",
       " 'A. Gnana Saravanan',\n",
       " 'A. Goel',\n",
       " 'A. Gogna',\n",
       " 'A. Goh',\n",
       " 'A. Gohr',\n",
       " 'A. Gomez',\n",
       " 'A. Gonczarek',\n",
       " 'A. GonzalezMarcos',\n",
       " 'A. GonzalezPinto',\n",
       " 'A. Goode',\n",
       " 'A. Gooya',\n",
       " 'A. Gopalan',\n",
       " 'A. Goshtasby',\n",
       " 'A. Goswami',\n",
       " 'A. Gotchev',\n",
       " 'A. Gouaillard',\n",
       " 'A. Gounaris',\n",
       " 'A. Gouze',\n",
       " 'A. Grama',\n",
       " 'A. Granados',\n",
       " 'A. Grand',\n",
       " 'A. Graves',\n",
       " 'A. Gribok',\n",
       " 'A. Griesser',\n",
       " 'A. Gritai',\n",
       " 'A. Gross',\n",
       " 'A. Gruber',\n",
       " 'A. Gryglewski',\n",
       " 'A. Gschwindt',\n",
       " 'A. Gu',\n",
       " 'A. GuerinDugue',\n",
       " 'A. GuerreroCurieses',\n",
       " 'A. Guillaud',\n",
       " 'A. Guillen',\n",
       " 'A. Gulbeden',\n",
       " 'A. Gunay',\n",
       " 'A. Gunduz',\n",
       " 'A. Gupta',\n",
       " 'A. Gural Vural',\n",
       " 'A. Gurel',\n",
       " 'A. Gusev',\n",
       " 'A. Gutierrez',\n",
       " 'A. GutierrezGalvez',\n",
       " 'A. Gutman',\n",
       " 'A. Guzzo',\n",
       " 'A. H. F. Laender',\n",
       " 'A. H. Jafari',\n",
       " 'A. H. Lee',\n",
       " 'A. H. Mahmoud',\n",
       " 'A. H. Rouhi',\n",
       " 'A. Habed',\n",
       " 'A. Hadayer',\n",
       " 'A. Hadid',\n",
       " 'A. Hafez',\n",
       " 'A. Hagelauer',\n",
       " 'A. Haja',\n",
       " 'A. Hajdu',\n",
       " 'A. Hajibagheri',\n",
       " 'A. Hakeem',\n",
       " 'A. Halevy',\n",
       " 'A. Halimi',\n",
       " 'A. Hallapuro',\n",
       " 'A. Halverson',\n",
       " 'A. HamiltonWright',\n",
       " 'A. Hammonds',\n",
       " 'A. Hampapur',\n",
       " 'A. Hamza',\n",
       " 'A. Hamzeh',\n",
       " 'A. Hanbury',\n",
       " 'A. Hanjalic',\n",
       " 'A. Hanson',\n",
       " 'A. Hanssen',\n",
       " 'A. Hapfelmeier',\n",
       " 'A. Harbitz',\n",
       " 'A. Haro',\n",
       " 'A. Harrer',\n",
       " 'A. Harthattu',\n",
       " 'A. Harwood',\n",
       " 'A. Hashmi',\n",
       " 'A. Hatevy',\n",
       " 'A. Hayashi',\n",
       " 'A. Hedayat',\n",
       " 'A. Heffel',\n",
       " 'A. Heinzl',\n",
       " 'A. Heittmann',\n",
       " 'A. Helzer',\n",
       " 'A. Henrich',\n",
       " 'A. Herbulot',\n",
       " 'A. Hernandez',\n",
       " 'A. Hero',\n",
       " 'A. Herrera',\n",
       " 'A. Hertzmann',\n",
       " 'A. Hervas',\n",
       " 'A. Hervieu',\n",
       " 'A. Hesson',\n",
       " 'A. Heydari',\n",
       " 'A. Heyden',\n",
       " 'A. Hill',\n",
       " 'A. Hilsmann',\n",
       " 'A. Hilton',\n",
       " 'A. Hinneburg',\n",
       " 'A. Hirabayashi',\n",
       " 'A. Hirose',\n",
       " 'A. Histace',\n",
       " 'A. Hoberman',\n",
       " 'A. Hogue',\n",
       " 'A. Holub',\n",
       " 'A. Honkela',\n",
       " 'A. Hoogs',\n",
       " 'A. Hoover',\n",
       " 'A. Hope',\n",
       " 'A. Hoppe',\n",
       " 'A. Hore',\n",
       " 'A. Hornung',\n",
       " 'A. Hosni',\n",
       " 'A. Hotho',\n",
       " 'A. Hourunranta',\n",
       " 'A. Huang',\n",
       " 'A. Huck',\n",
       " 'A. Huertas',\n",
       " 'A. HuertasRosero',\n",
       " 'A. Hughes',\n",
       " 'A. Hulgeri',\n",
       " 'A. Humayun',\n",
       " 'A. Humm',\n",
       " 'A. Hunter',\n",
       " 'A. Hyvarinen',\n",
       " 'A. I. Haizhou',\n",
       " 'A. I. Marques',\n",
       " 'A. I. Saleh',\n",
       " 'A. I. Shihab',\n",
       " 'A. Iazzetta',\n",
       " 'A. Ibrahim',\n",
       " 'A. Iglesias',\n",
       " 'A. Ihler',\n",
       " 'A. Ilchmann',\n",
       " 'A. Ilie',\n",
       " 'A. Ilin',\n",
       " 'A. Imiya',\n",
       " 'A. Imran Naseem',\n",
       " 'A. Inan',\n",
       " 'A. Inokuchi',\n",
       " 'A. Ion',\n",
       " 'A. Iosifidis',\n",
       " 'A. Irschara',\n",
       " 'A. Isar',\n",
       " 'A. Ittycheriah',\n",
       " 'A. Ivannikov',\n",
       " 'A. Ivanovic',\n",
       " 'A. Iwata',\n",
       " 'A. Iyengar',\n",
       " 'A. J. Alvero',\n",
       " 'A. J. Bagnall',\n",
       " 'A. J. Cowell',\n",
       " 'A. J. DiazHonrubia',\n",
       " 'A. J. Feelders',\n",
       " 'A. J. Garrido',\n",
       " 'A. J. Gibberd',\n",
       " 'A. J. H. Peddemors',\n",
       " 'A. J. Joshi',\n",
       " 'A. J. Lee',\n",
       " 'A. J. M. Traina',\n",
       " 'A. J. Ma',\n",
       " 'A. J. McCann',\n",
       " 'A. J. Oliner',\n",
       " 'A. J. Piergiovanni',\n",
       " 'A. J. Plaza',\n",
       " 'A. J. RodriguezSanchez',\n",
       " 'A. J. SerranoLopez',\n",
       " 'A. J. Weijters',\n",
       " 'A. Jagannathan',\n",
       " 'A. Jagmohan',\n",
       " 'A. Jagota',\n",
       " 'A. Jaimes',\n",
       " 'A. Jain',\n",
       " 'A. Jaiswal',\n",
       " 'A. Jakary',\n",
       " 'A. Jalobeanu',\n",
       " 'A. James',\n",
       " 'A. Janse van Rensburg',\n",
       " 'A. Jepson',\n",
       " 'A. Jerbi',\n",
       " 'A. Jeromin',\n",
       " 'A. Jezierska',\n",
       " 'A. Jhingran',\n",
       " 'A. Jimenez',\n",
       " 'A. JimenezFernandez',\n",
       " 'A. JoannicChardin',\n",
       " 'A. Joch',\n",
       " ...]"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "(authors_lst_ppr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "ahaTr3Q0C5Vb",
    "outputId": "243d3042-30c6-4530-da6a-e769a8448eb5"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0, 79653]\n"
     ]
    }
   ],
   "source": [
    "# get the indices of non-zero elements\n",
    "row_idx, col_idx = auth_matrix.nonzero()\n",
    "\n",
    "# display the first non-zero element\n",
    "print([row_idx[0], col_idx[0]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2bf08099133f4bae848e417a24445f0b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/138499 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Text cleaned and vocab built in 44 min\n"
     ]
    }
   ],
   "source": [
    "t = time()\n",
    "n = -1 #length of the sample to develop and test the pipeline (-1 or negative values to take all the dataset)\n",
    "\n",
    "#takes 4 minutes to process all the abstracts\n",
    "abstracts = read_and_clean_abstracts(nodes, sample_length=n)  #149s #194s\n",
    "abstracts_dict_list_words = {i: abstracts[i].split()[:-1] for i in nodes}\n",
    "abstracts_list_sentences = [list(item)[1][:-3] for item in abstracts.items()]\n",
    "\n",
    "#we create a vacabulary of words and sentences (abstracts)\n",
    "#we take only a sample of 3 abstracts (i=2) to explore the approach\n",
    "\n",
    "voc = Vocabulary('abstracts') \n",
    "for i in tqdm(nodes):\n",
    "    voc.add_sentence(abstracts[i], i)\n",
    "\n",
    "print('Text cleaned and vocab built in {:.0f} min'.format((time()-t)/60))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "o5mW4OXyLIGQ",
    "outputId": "8edaed15-29fa-4e50-d83e-017e47c7bfef"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(138499, 768)"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sentence_embeddings = model.encode(voc.sentences_list)\n",
    "sentence_embeddings.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(138499, 768)"
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sentence_embeddings.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('sentence_embeddings_BERT.plk', 'wb') as f:\n",
    "    pickle.dump(sentence_embeddings, f)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "2czqslmiVfcQ"
   },
   "source": [
    "# Read processed data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "bf-_fYkF5xiO",
    "outputId": "3197fbbb-73a7-4b2e-c97f-4e9408afb7cf"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "wv walks loaded from GCP in 0 sec\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(138499, 64)"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "t = time()\n",
    "from io import BytesIO\n",
    "\n",
    "walks_url = 'https://storage.googleapis.com/link_prediction_processed_data/walks_wv.npy'\n",
    "with urlopen(walks_url) as url:\n",
    "    data = url.read()\n",
    "\n",
    "# Create a seekable file-like object from the data\n",
    "fileobj = BytesIO(data)\n",
    "\n",
    "# Load the data from the file object\n",
    "walks_wv = np.load(fileobj)\n",
    "print('wv walks loaded from GCP in {:.0f} sec'.format(time()-t))\n",
    "walks_wv.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "id": "MGlREMRlrZKa"
   },
   "outputs": [],
   "source": [
    "# # Load max embeddings wv_192\n",
    "\n",
    "# url='https://storage.googleapis.com/link_prediction_processed_data/max_abstract_embedding.pkl'\n",
    "\n",
    "# response = requests.get(url)\n",
    "# data = response.content\n",
    "# max_abstract_embedding = pickle.loads(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "id": "IrvRUVduhoAI"
   },
   "outputs": [],
   "source": [
    "# # Load the BART embedding torch tensor\n",
    "\n",
    "# url = \"https://storage.googleapis.com/link_prediction_processed_data/bart_embeddings.pt\"\n",
    "# response = requests.get(url)\n",
    "\n",
    "# with open(\"bart_embeddings.pt\", \"wb\") as f:\n",
    "#     f.write(response.content)\n",
    "\n",
    "# abstracts_bart_embeddings = torch.load('bart_embeddings.pt')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "LlQCihvfmBQP",
    "outputId": "133327d1-e540-4cd7-df63-e2ae446a0e75"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(138499, 300)"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Load the wv300 mean embedding\n",
    "url = 'https://storage.googleapis.com/link_prediction_processed_data/embedded_abstracts_local_wv300.npy'\n",
    "\n",
    "response = requests.get(url)\n",
    "\n",
    "with open('embedded_abstracts_local_wv300.npy', 'wb') as f:\n",
    "    f.write(response.content)\n",
    "\n",
    "# Load the numpy array from the saved file\n",
    "local_wv300_abstracts = np.load('embedded_abstracts_local_wv300.npy')\n",
    "\n",
    "local_wv300_abstracts.shape\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "id": "F4jEFSE6in_w"
   },
   "outputs": [],
   "source": [
    "# # Load the goog300 mean embedding\n",
    "# url = 'https://storage.googleapis.com/link_prediction_processed_data/embedded_abstracts_goog300.npy'\n",
    "\n",
    "# response = requests.get(url)\n",
    "\n",
    "# with open('embedded_abstracts_goog300.npy', 'wb') as f:\n",
    "#     f.write(response.content)\n",
    "\n",
    "# # Load the numpy array from the saved file\n",
    "# goog300_abstracts = np.load('embedded_abstracts_goog300.npy')\n",
    "\n",
    "# goog300_abstracts.shape\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "id": "3_xIGkD_wuUn"
   },
   "outputs": [],
   "source": [
    "# # Load TF-IDF matrix\n",
    "\n",
    "# url = \"https://storage.googleapis.com/link_prediction_processed_data/tfidf_matrix.npz\"\n",
    "\n",
    "# response = requests.get(url)\n",
    "\n",
    "# with open(\"tfidf_matrix.npz\", \"wb\") as f:\n",
    "#     f.write(response.content)\n",
    "\n",
    "# tfidf_matrix = sparse.load_npz(\"tfidf_matrix.npz\")\n",
    "\n",
    "# tfidf_matrix.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "id": "mJjyDTiVPblx"
   },
   "outputs": [],
   "source": [
    "# # Load words 192 embedding\n",
    "# import gzip\n",
    "# import pickle\n",
    "\n",
    "# with gzip.open('embedded_abstracts_dict_192array.pkl.gz', 'rb') as f:\n",
    "#     words_embedding_192 = pickle.load(f)\n",
    "\n",
    "# len(words_embedding_192)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "id": "RuZSYpPv0zNr"
   },
   "outputs": [],
   "source": [
    "# len(words_embedding_192)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "id": "20sWKHiSsgKV"
   },
   "outputs": [],
   "source": [
    "# from tqdm.notebook import tqdm\n",
    "# import numpy as np\n",
    "\n",
    "# words_embedding_192_trunc128 = dict ()\n",
    "# for i in tqdm(range(len(words_embedding_192))):\n",
    "#     if len(words_embedding_192[i])>0:\n",
    "#         arr = np.zeros((128, 192))\n",
    "#         vec = words_embedding_192[i][:128, :]\n",
    "#         arr[:vec.shape[0],:] = vec\n",
    "#         words_embedding_192_trunc128[i] = torch.tensor(arr).to(device)\n",
    "#     else:\n",
    "#         words_embedding_192_trunc128[i] = []\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "id": "fkzNXQF1taxU"
   },
   "outputs": [],
   "source": [
    "# tensor_list = []\n",
    "# i = 0\n",
    "# for i in tqdm(range(len(words_embedding_192_trunc128))):\n",
    "#     if len(words_embedding_192_trunc128[i])>0:\n",
    "#         tensor_list.append(words_embedding_192_trunc128[i])\n",
    "#     else:\n",
    "#         tensor_list.append(torch.zeros((128, 192)))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "id": "pM27YApj0zNs"
   },
   "outputs": [],
   "source": [
    "# del(words_embedding_192_trunc128)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "id": "tAo6RBG-xy47"
   },
   "outputs": [],
   "source": [
    "# import gzip\n",
    "\n",
    "# filename = 'words_embedding_192_trunc128.pkl.gz'\n",
    "\n",
    "# # open the file in binary mode and write the dictionary to it, compressing the data with gzip\n",
    "# with gzip.open(filename, 'wb') as f:\n",
    "#     pickle.dump(words_embedding_192_trunc128, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "id": "BNgqJRoY0zNt"
   },
   "outputs": [],
   "source": [
    "# tensor_list_float = []\n",
    "# for i, tensor in tqdm(enumerate(tensor_list)):\n",
    "#     tensor_list_float.append(tensor_list[i].float())\n",
    "# del(tensor_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "id": "ebgY7dPF0zNt"
   },
   "outputs": [],
   "source": [
    "# t = time ()\n",
    "# url = 'https://storage.googleapis.com/link_prediction_processed_data/words_embedding_192_trunc128.pkl.gz'\n",
    "\n",
    "\n",
    "# # download the file from the URL\n",
    "# response = requests.get(url)\n",
    "\n",
    "# # save the file to disk\n",
    "# with open(filename, 'wb') as f:\n",
    "#     f.write(response.content)\n",
    "\n",
    "# # load the data from the file\n",
    "# with gzip.open(filename, 'rb') as f:\n",
    "#     words_embedding_192_trunc128 = pickle.load(f)\n",
    "\n",
    "# print('padded truncated embeddings loaded in {:.0f} sec'.format(time()-t))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "id": "nNfoJp-U0zNt"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "zxvIuCP_bFrN"
   },
   "source": [
    "# Models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "id": "ROBXxQaZnfQ3"
   },
   "outputs": [],
   "source": [
    "class GNN(nn.Module):\n",
    "    def __init__(self, n_text, n_auth, n_feat, n_hidden, n_class, sub_class, dropout):\n",
    "        super(GNN, self).__init__()\n",
    "        self.auth_emb = nn.Linear(n_auth, n_hidden)\n",
    "        #self.abstract_emb = nn.Linear(n_text, n_hidden)\n",
    "        self.fc1 = nn.Linear(n_feat+n_hidden, n_hidden)        \n",
    "        self.fc2 = nn.Linear(n_hidden, n_hidden)\n",
    "        self.fc3 = nn.Linear(2*n_hidden, n_hidden)\n",
    "        self.fc4 = nn.Linear(n_hidden, sub_class)\n",
    "        self.fc5 = nn.Linear(sub_class, n_class)        \n",
    "        self.dropout = nn.Dropout(dropout)\n",
    "        self.relu = nn.ReLU()\n",
    "        self.sigmoid = nn.Sigmoid()\n",
    "        \n",
    "        \n",
    "\n",
    "    def forward(self, x_in, abstract, auth, adj, pairs):\n",
    "\n",
    "#         y = self.abstract_emb(abstract)\n",
    "#         y = self.relu(y)\n",
    "#         y = self.dropout(y)\n",
    "#         del(abstract)\n",
    "\n",
    "        y = self.auth_emb(auth)\n",
    "        y = self.relu(y)\n",
    "        y = self.dropout(y)\n",
    "        del(auth)\n",
    "\n",
    "        x_in = torch.cat((x_in, y), dim=1)\n",
    "        \n",
    "        h1 = self.fc1(x_in)\n",
    "        z1 = self.relu(torch.spmm(adj, h1))\n",
    "        z1 = self.dropout(z1)\n",
    "        del(x_in, h1)\n",
    "\n",
    "        h2 = self.fc2(z1)\n",
    "        z2 = self.relu(torch.spmm(adj, h2))\n",
    "        z2 = self.dropout(z2)\n",
    "        del(h2, z1, adj)\n",
    "        \n",
    "        #x = torch.cat((z2[pairs[0]] , y[pairs[0]], z2[pairs[1]] , y[pairs[1]]), dim=1)\n",
    "        x = torch.cat((z2[pairs[0]] , z2[pairs[1]]), dim=1)\n",
    "        del(z2)\n",
    "\n",
    "        x = self.relu(self.fc3(x))\n",
    "        x = self.dropout(x)\n",
    "\n",
    "        #x = torch.cat((x, pairs[2][:, None], pairs[3][:, None]), dim=1)        \n",
    "        del(pairs)\n",
    "        \n",
    "        x = self.relu(self.fc4(x))\n",
    "        x = self.dropout(x)\n",
    "        \n",
    "        x = self.fc5(x)\n",
    "        return F.log_softmax(x, dim=1)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ognzQbsFDb13"
   },
   "source": [
    "# Training functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "id": "0azz_rVlDyn9"
   },
   "outputs": [],
   "source": [
    "class EarlyStopping:\n",
    "    def __init__(self, model, patience, delta, path='checkpoint.pt'):\n",
    "        self.patience = patience\n",
    "        self.delta = delta\n",
    "        self.counter = 0\n",
    "        self.best_score = None\n",
    "        self.early_stop = False\n",
    "        self.model = model\n",
    "        self.val_loss_min = np.Inf\n",
    "        \n",
    "    def __call__(self, val_loss, path='checkpoint.pt'):\n",
    "        score = val_loss\n",
    "\n",
    "        if self.best_score is None:\n",
    "            self.best_score = score\n",
    "            self.save_checkpoint(path)\n",
    "        elif score > self.best_score + 0:\n",
    "            self.counter += 1\n",
    "            #print(self.counter)\n",
    "            if self.counter >= self.patience:\n",
    "                self.early_stop = True\n",
    "        else:\n",
    "            self.best_score = score\n",
    "            self.save_checkpoint(path)\n",
    "            self.counter = 0\n",
    "\n",
    "    def save_checkpoint(self, path):\n",
    "        torch.save(self.model.state_dict(), path)\n",
    "\n",
    "    def load_checkpoint(self, path):\n",
    "        self.model.load_state_dict(torch.load(path))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [],
   "source": [
    "tensor1 = (pairs_torch[0:2].permute(1, 0)[:int(len(pairs_torch[0])/2)])\n",
    "tensor2 = pairs_torch[0:2].permute(1, 0)[int(len(pairs_torch[0])/2):]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tensor1[:, None]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "common_indices = torch.nonzero(torch.all(torch.eq(tensor1[:, None], tensor2[None, :]), dim=-1))\n",
    "\n",
    "# Print the common indices\n",
    "print(common_indices)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[True, True],\n",
       "        [True, True],\n",
       "        [True, True],\n",
       "        ...,\n",
       "        [True, True],\n",
       "        [True, True],\n",
       "        [True, True]])"
      ]
     },
     "execution_count": 94,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.isin((pairs_torch[0:2].permute(1, 0)[:int(len(pairs_torch[0])/2)]), (pairs_torch[0:2].permute(1, 0)[int(len(pairs_torch[0])/2):]))\n",
    "           "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "False\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "\n",
    "# Example tensors\n",
    "tensor1 = torch.tensor([[1, 2], [3, 4], [5, 6]])\n",
    "tensor2 = torch.tensor([[3, 4], [7, 8], [9, 10]])\n",
    "\n",
    "# Reshape tensors to (1, -1) to get pairs of elements\n",
    "pairs1 = tensor1.reshape(1, -1)\n",
    "pairs2 = tensor2.reshape(1, -1)\n",
    "\n",
    "# Check if there are any common pairs of elements\n",
    "common_pairs = torch.eq(pairs1, pairs2).any()\n",
    "\n",
    "# Print the result\n",
    "print(common_pairs.item())  # True if there are common pairs, False otherwise\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[False, False],\n",
       "        [ True,  True],\n",
       "        [False, False]])"
      ]
     },
     "execution_count": 95,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.isin(tensor1, tensor2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "id": "bnRNz5z4nh6x"
   },
   "outputs": [],
   "source": [
    "def train_model(model, learning_rate, abstract, auth, features, adj, pairs, y, val_indices, y_val, epochs, run_number, window = 10):\n",
    "    # Train model\n",
    "    start_time = time()\n",
    "    \n",
    "    print('Initializing the optimizer with learning rate:', learning_rate)\n",
    "    optimizer = optim.Adam(model.parameters(), lr=learning_rate) #optimizer with halving learning rate in training\n",
    "    try: os.mkdir('./outputs')\n",
    "    except: pass\n",
    "\n",
    "    today = datetime.today().strftime('%Y-%m-%d-%H:%M')\n",
    "    list_loss_val = []\n",
    "    list_loss_train = []\n",
    "    list_epochs = []\n",
    "    \n",
    "    halving_lr = 0 # counter of the number of halving lr\n",
    "    patience = 16\n",
    "    early_stopping = EarlyStopping(model, patience=patience, delta=0.1, path='checkpoint.pt')\n",
    "    print('Start training...')\n",
    "    for epoch in range(epochs):\n",
    "        t = time()\n",
    "        optimizer.zero_grad()\n",
    "        \n",
    "        rand_indices = torch.randint(0, features.shape[0], size=(indices.shape[0],indices.shape[1])).to(device)\n",
    "        \n",
    "        pairs = torch.cat((indices, rand_indices), dim=1)\n",
    "        \n",
    "        model.train()\n",
    "\n",
    "        output = model(features, abstract, auth, adj, pairs).to(device) # we run the model that gives the output.\n",
    "        loss_train = F.nll_loss(output, y) # we are using nll_loss as loss to optimize, we store it in loss_train. We compare to y which is stable and contains the tag ones and zeros.\n",
    "        acc_train = accuracy_score(torch.argmax(output, dim=1).detach().cpu().numpy(), y.cpu().numpy())# just to show it in the out put message of the training\n",
    "        loss_train.backward() # The back propagation ? --> Computes the gradient of current tensor w.r.t. graph leaves\n",
    "        optimizer.step() # Performs a single optimization step (parameter update).\n",
    "        \n",
    "        model.eval()\n",
    "        output = model(features, abstract, auth, adj, val_indices).to(device)\n",
    "        #y_val = torch.LongTensor(y_val).to(device)\n",
    "        loss_val = F.nll_loss(output, y_val)\n",
    "        list_loss_val.append(loss_val.item())\n",
    "        list_loss_train.append(loss_train.item())\n",
    "        list_epochs.append(epoch)\n",
    "        acc_val = accuracy_score(torch.argmax(output, dim=1).detach().cpu().numpy(), y_val.cpu().numpy())\n",
    "        \n",
    "\n",
    "\n",
    "        if epoch % 5 == 0:\n",
    "            print('Epoch: {:03d}'.format(epoch+1),\n",
    "                  'loss_train: {:.4f}'.format(loss_train.item()),\n",
    "                  'loss_val: {:.4f}'.format(loss_val.item()),\n",
    "                  'acc_train: {:.4f}'.format(acc_train.item()),\n",
    "                  'acc_val: {:.4f}'.format(acc_val.item()),\n",
    "                  'time: {} s'.format(int(round(time()) - round(t))),\n",
    "                 'total_time: {} min'.format(round((time() - start_time)/60)))\n",
    "            \n",
    "            if epoch % 50 == 0:\n",
    "                model_path = \"outputs/{}-model-{}epochs-{}.pt\".format(today, epoch, run_number)\n",
    "                torch.save(model.state_dict(), model_path)\n",
    "            \n",
    "\n",
    "        \n",
    "        early_stopping(loss_val)\n",
    "\n",
    "        if early_stopping.early_stop:\n",
    "            halving_lr += 1\n",
    "            if halving_lr > 4:\n",
    "                break\n",
    "            learning_rate = learning_rate/10\n",
    "            optimizer = optim.Adam(model.parameters(), lr=learning_rate)\n",
    "            early_stopping = EarlyStopping(model, patience=patience, delta=0.01, path='checkpoint.pt')\n",
    "            print('Deviding the learning rate by 10. New learning rate: {}'.format(learning_rate))\n",
    "\n",
    "\n",
    "\n",
    "    print(\"Optimization Finished in {} min!\".format(round((time() - start_time)/60)))\n",
    "    return model, list_loss_val, list_loss_train, list_epochs\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "kJqiI7fxbVhl"
   },
   "source": [
    "# Train the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "PZqvqcdPg4X6",
    "outputId": "8e844bbe-4744-4a1d-d25c-8788bd906535"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Preparing the data for training...\n",
      "Data converted into torch tensors and authors added to indices in 2 min\n"
     ]
    }
   ],
   "source": [
    "features_torch, adj_torch, auth_torch, pairs_torch, y_torch, val_indices_torch, y_val_torch = prepare_data_to_train(walks_wv, authors, adj, auth_matrix, indices, val_indices, y_val)\n",
    "#max_abstract_embedding_torch = torch.FloatTensor(max_abstract_embedding_array).to(device)\n",
    "#abstracts_bart_embeddings = abstracts_bart_embeddings.to(device)\n",
    "#goog300_abstracts_torch = torch.FloatTensor(goog300_abstracts).to(device)\n",
    "#local_wv300_abstracts_torch = torch.FloatTensor(local_wv300_abstracts).to(device)\n",
    "#tfidf_matrix_torch = sparse_mx_to_torch_sparse_tensor(tfidf_matrix).to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "id": "47r-jwjb4jl4"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([138499, 147481])"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "auth_torch.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "id": "7i8UpGHuNhQp"
   },
   "outputs": [],
   "source": [
    "n_hidden = 64\n",
    "dropout_rate = 0.2\n",
    "sub_class = 32\n",
    "n_class = 2\n",
    "#text_embedding = local_wv300_abstracts_torch\n",
    "n_text = 0 #text_embedding.shape[1]\n",
    "n_auth = auth_torch.shape[1] \n",
    "n_features = features_torch.shape[1]\n",
    "\n",
    "\n",
    "# Creates the model\n",
    "model = GNN(n_text, n_auth, n_features, n_hidden, n_class, sub_class, dropout_rate).to(device)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "id": "p5llTPM64kQj"
   },
   "outputs": [],
   "source": [
    "torch.cuda.empty_cache()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "tiyrR1an0zNx",
    "outputId": "f0043171-1805-4b3e-f281-1014860a1187"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Initializing the optimizer with learning rate: 0.01\n",
      "Start training...\n",
      "Epoch: 001 loss_train: 0.6990 loss_val: 0.6850 acc_train: 0.5000 acc_val: 0.5876 time: 14 s total_time: 0 min\n",
      "Epoch: 006 loss_train: 0.6640 loss_val: 0.6609 acc_train: 0.6430 acc_val: 0.6405 time: 8 s total_time: 1 min\n",
      "Epoch: 011 loss_train: 0.6114 loss_val: 0.6019 acc_train: 0.6529 acc_val: 0.6189 time: 6 s total_time: 2 min\n",
      "Epoch: 016 loss_train: 0.5630 loss_val: 0.5472 acc_train: 0.7150 acc_val: 0.7162 time: 8 s total_time: 2 min\n",
      "Epoch: 021 loss_train: 0.5075 loss_val: 0.4870 acc_train: 0.7612 acc_val: 0.7702 time: 8 s total_time: 3 min\n",
      "Epoch: 026 loss_train: 0.4657 loss_val: 0.4474 acc_train: 0.7865 acc_val: 0.7979 time: 8 s total_time: 4 min\n",
      "Epoch: 031 loss_train: 0.4292 loss_val: 0.4191 acc_train: 0.8029 acc_val: 0.8109 time: 8 s total_time: 4 min\n",
      "Epoch: 036 loss_train: 0.3993 loss_val: 0.3954 acc_train: 0.8203 acc_val: 0.8225 time: 7 s total_time: 5 min\n",
      "Epoch: 041 loss_train: 0.3703 loss_val: 0.3733 acc_train: 0.8358 acc_val: 0.8401 time: 8 s total_time: 6 min\n",
      "Epoch: 046 loss_train: 0.3517 loss_val: 0.3686 acc_train: 0.8461 acc_val: 0.8428 time: 9 s total_time: 6 min\n",
      "Epoch: 051 loss_train: 0.3366 loss_val: 0.3620 acc_train: 0.8537 acc_val: 0.8488 time: 9 s total_time: 7 min\n",
      "Epoch: 056 loss_train: 0.3265 loss_val: 0.3551 acc_train: 0.8588 acc_val: 0.8501 time: 8 s total_time: 8 min\n",
      "Epoch: 061 loss_train: 0.3184 loss_val: 0.3511 acc_train: 0.8637 acc_val: 0.8550 time: 9 s total_time: 8 min\n",
      "Epoch: 066 loss_train: 0.3113 loss_val: 0.3449 acc_train: 0.8673 acc_val: 0.8581 time: 10 s total_time: 9 min\n",
      "Epoch: 071 loss_train: 0.3042 loss_val: 0.3410 acc_train: 0.8710 acc_val: 0.8616 time: 7 s total_time: 10 min\n",
      "Epoch: 076 loss_train: 0.2975 loss_val: 0.3360 acc_train: 0.8741 acc_val: 0.8638 time: 8 s total_time: 11 min\n",
      "Epoch: 081 loss_train: 0.2930 loss_val: 0.3301 acc_train: 0.8772 acc_val: 0.8652 time: 8 s total_time: 11 min\n",
      "Epoch: 086 loss_train: 0.2873 loss_val: 0.3261 acc_train: 0.8800 acc_val: 0.8664 time: 8 s total_time: 12 min\n",
      "Epoch: 091 loss_train: 0.2819 loss_val: 0.3205 acc_train: 0.8824 acc_val: 0.8693 time: 8 s total_time: 12 min\n",
      "Epoch: 096 loss_train: 0.2751 loss_val: 0.3137 acc_train: 0.8851 acc_val: 0.8744 time: 8 s total_time: 13 min\n",
      "Epoch: 101 loss_train: 0.2682 loss_val: 0.3107 acc_train: 0.8885 acc_val: 0.8765 time: 7 s total_time: 14 min\n",
      "Epoch: 106 loss_train: 0.2623 loss_val: 0.3088 acc_train: 0.8909 acc_val: 0.8791 time: 8 s total_time: 14 min\n",
      "Epoch: 111 loss_train: 0.2574 loss_val: 0.3024 acc_train: 0.8936 acc_val: 0.8819 time: 7 s total_time: 15 min\n",
      "Epoch: 116 loss_train: 0.2517 loss_val: 0.2969 acc_train: 0.8969 acc_val: 0.8852 time: 8 s total_time: 16 min\n",
      "Epoch: 121 loss_train: 0.2460 loss_val: 0.2952 acc_train: 0.8999 acc_val: 0.8886 time: 8 s total_time: 16 min\n",
      "Epoch: 126 loss_train: 0.2405 loss_val: 0.2891 acc_train: 0.9028 acc_val: 0.8913 time: 8 s total_time: 17 min\n",
      "Epoch: 131 loss_train: 0.2351 loss_val: 0.2857 acc_train: 0.9056 acc_val: 0.8944 time: 8 s total_time: 18 min\n",
      "Epoch: 136 loss_train: 0.2329 loss_val: 0.2892 acc_train: 0.9063 acc_val: 0.8963 time: 8 s total_time: 18 min\n",
      "Epoch: 141 loss_train: 0.2254 loss_val: 0.2804 acc_train: 0.9105 acc_val: 0.8993 time: 9 s total_time: 19 min\n",
      "Epoch: 146 loss_train: 0.2203 loss_val: 0.2755 acc_train: 0.9132 acc_val: 0.9013 time: 9 s total_time: 20 min\n",
      "Epoch: 151 loss_train: 0.2147 loss_val: 0.2721 acc_train: 0.9158 acc_val: 0.9027 time: 8 s total_time: 20 min\n",
      "Epoch: 156 loss_train: 0.2110 loss_val: 0.2705 acc_train: 0.9177 acc_val: 0.9040 time: 8 s total_time: 21 min\n",
      "Epoch: 161 loss_train: 0.2086 loss_val: 0.2756 acc_train: 0.9184 acc_val: 0.9048 time: 9 s total_time: 22 min\n",
      "Epoch: 166 loss_train: 0.2060 loss_val: 0.2735 acc_train: 0.9197 acc_val: 0.9060 time: 7 s total_time: 23 min\n",
      "Epoch: 171 loss_train: 0.2030 loss_val: 0.2725 acc_train: 0.9212 acc_val: 0.9075 time: 8 s total_time: 23 min\n",
      "Epoch: 176 loss_train: 0.1994 loss_val: 0.2713 acc_train: 0.9229 acc_val: 0.9086 time: 9 s total_time: 24 min\n",
      "Epoch: 181 loss_train: 0.1961 loss_val: 0.2696 acc_train: 0.9244 acc_val: 0.9099 time: 9 s total_time: 25 min\n",
      "Epoch: 186 loss_train: 0.1938 loss_val: 0.2648 acc_train: 0.9256 acc_val: 0.9112 time: 9 s total_time: 25 min\n",
      "Epoch: 191 loss_train: 0.1913 loss_val: 0.2624 acc_train: 0.9266 acc_val: 0.9120 time: 8 s total_time: 26 min\n",
      "Epoch: 196 loss_train: 0.1890 loss_val: 0.2623 acc_train: 0.9277 acc_val: 0.9124 time: 8 s total_time: 27 min\n",
      "Deviding the learning rate by 10. New learning rate: 0.001\n",
      "Epoch: 201 loss_train: 0.1871 loss_val: 0.2763 acc_train: 0.9285 acc_val: 0.9105 time: 8 s total_time: 27 min\n",
      "Epoch: 206 loss_train: 0.1882 loss_val: 0.2616 acc_train: 0.9281 acc_val: 0.9132 time: 9 s total_time: 28 min\n",
      "Epoch: 211 loss_train: 0.1874 loss_val: 0.2630 acc_train: 0.9285 acc_val: 0.9131 time: 8 s total_time: 29 min\n",
      "Epoch: 216 loss_train: 0.1867 loss_val: 0.2625 acc_train: 0.9287 acc_val: 0.9132 time: 7 s total_time: 29 min\n",
      "Deviding the learning rate by 10. New learning rate: 0.0001\n",
      "Epoch: 221 loss_train: 0.1860 loss_val: 0.2640 acc_train: 0.9290 acc_val: 0.9132 time: 7 s total_time: 30 min\n",
      "Epoch: 226 loss_train: 0.1860 loss_val: 0.2620 acc_train: 0.9289 acc_val: 0.9134 time: 8 s total_time: 31 min\n",
      "Epoch: 231 loss_train: 0.1859 loss_val: 0.2635 acc_train: 0.9291 acc_val: 0.9133 time: 9 s total_time: 31 min\n",
      "Epoch: 236 loss_train: 0.1860 loss_val: 0.2627 acc_train: 0.9290 acc_val: 0.9134 time: 10 s total_time: 32 min\n",
      "Epoch: 241 loss_train: 0.1855 loss_val: 0.2625 acc_train: 0.9293 acc_val: 0.9135 time: 9 s total_time: 33 min\n",
      "Deviding the learning rate by 10. New learning rate: 1e-05\n",
      "Epoch: 246 loss_train: 0.1861 loss_val: 0.2629 acc_train: 0.9291 acc_val: 0.9134 time: 9 s total_time: 34 min\n",
      "Epoch: 251 loss_train: 0.1860 loss_val: 0.2630 acc_train: 0.9289 acc_val: 0.9134 time: 8 s total_time: 34 min\n",
      "Epoch: 256 loss_train: 0.1857 loss_val: 0.2630 acc_train: 0.9291 acc_val: 0.9134 time: 9 s total_time: 35 min\n",
      "Deviding the learning rate by 10. New learning rate: 1.0000000000000002e-06\n",
      "Epoch: 261 loss_train: 0.1857 loss_val: 0.2629 acc_train: 0.9291 acc_val: 0.9134 time: 8 s total_time: 36 min\n",
      "Epoch: 266 loss_train: 0.1857 loss_val: 0.2629 acc_train: 0.9290 acc_val: 0.9134 time: 8 s total_time: 36 min\n",
      "Epoch: 271 loss_train: 0.1855 loss_val: 0.2629 acc_train: 0.9292 acc_val: 0.9134 time: 8 s total_time: 37 min\n",
      "Epoch: 276 loss_train: 0.1856 loss_val: 0.2629 acc_train: 0.9291 acc_val: 0.9134 time: 10 s total_time: 38 min\n",
      "Epoch: 281 loss_train: 0.1859 loss_val: 0.2629 acc_train: 0.9289 acc_val: 0.9134 time: 9 s total_time: 39 min\n",
      "Epoch: 286 loss_train: 0.1853 loss_val: 0.2629 acc_train: 0.9293 acc_val: 0.9134 time: 10 s total_time: 39 min\n",
      "Epoch: 291 loss_train: 0.1859 loss_val: 0.2629 acc_train: 0.9289 acc_val: 0.9134 time: 9 s total_time: 40 min\n",
      "Epoch: 296 loss_train: 0.1858 loss_val: 0.2629 acc_train: 0.9291 acc_val: 0.9134 time: 8 s total_time: 41 min\n",
      "Epoch: 301 loss_train: 0.1860 loss_val: 0.2629 acc_train: 0.9290 acc_val: 0.9134 time: 9 s total_time: 41 min\n",
      "Epoch: 306 loss_train: 0.1858 loss_val: 0.2629 acc_train: 0.9291 acc_val: 0.9134 time: 8 s total_time: 42 min\n",
      "Epoch: 311 loss_train: 0.1859 loss_val: 0.2629 acc_train: 0.9291 acc_val: 0.9134 time: 7 s total_time: 43 min\n",
      "Optimization Finished in 43 min!\n"
     ]
    }
   ],
   "source": [
    "torch.cuda.empty_cache()\n",
    "\n",
    "\n",
    "epochs = 400\n",
    "run_number = randint(0, 1000)\n",
    "learning_rate = 0.01\n",
    "\n",
    "\n",
    "trained_model, list_loss_val, list_loss_train, list_epochs = train_model(model, learning_rate, text_embedding, \n",
    "                            auth_torch, features_torch, adj_torch, pairs_torch, \n",
    "                            y_torch, val_indices_torch, y_val_torch, epochs, run_number)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "idFEWIJO4k5L"
   },
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "\n",
    "\n",
    "y1 = pd.Series(list_loss_val[:400])\n",
    "y2 = pd.Series(list_loss_train[:400])\n",
    "x = pd.Series(list_epochs[:400])\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "plt.plot(x, y1, label='Validation Loss')\n",
    "plt.plot(x, y2, label='Training Loss')\n",
    "\n",
    "plt.title('Loss over Epochs, G not shuffled')\n",
    "plt.xlabel('Epoch')\n",
    "plt.ylabel('Loss')\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "oErtNBi1Ra66"
   },
   "outputs": [],
   "source": [
    "pairs_torch.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "0KKqG0rk1HM4"
   },
   "outputs": [],
   "source": [
    "break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "bDss4SBl0zNx"
   },
   "outputs": [],
   "source": [
    "torch.cuda.empty_cache()\n",
    "\n",
    "\n",
    "epochs = 602\n",
    "run_number = randint(0, 1000)\n",
    "learning_rate = 0.01\n",
    "\n",
    "\n",
    "trained_model = train_model(model, learning_rate, text_embedding, \n",
    "                            features_torch, adj_torch, pairs_torch, \n",
    "                            y_torch, val_indices_torch, y_val_torch, epochs, run_number)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "BSvrKVnoLGfn"
   },
   "outputs": [],
   "source": [
    "# before shuffling\n",
    "torch.cuda.empty_cache()\n",
    "\n",
    "\n",
    "epochs = 602\n",
    "run_number = randint(0, 1000)\n",
    "learning_rate = 0.01\n",
    "\n",
    "\n",
    "trained_model = train_model(model, learning_rate, text_embedding, \n",
    "                            features_torch, adj_torch, pairs_torch, \n",
    "                            y_torch, val_indices_torch, y_val_torch, epochs, run_number)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "JoZHWc0G0zNy"
   },
   "outputs": [],
   "source": [
    "np.shape(pairs_torch), y_torch.shape, val_indices_torch.shape, y_val_torch.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "uihFEZKFsjwH"
   },
   "outputs": [],
   "source": [
    "torch.cuda.empty_cache()\n",
    "\n",
    "\n",
    "epochs = 602\n",
    "run_number = randint(0, 1000)\n",
    "learning_rate = 0.01\n",
    "\n",
    "\n",
    "trained_model = train_model(model, learning_rate, text_embedding, \n",
    "                            features_torch, adj_torch, pairs_torch, \n",
    "                            y_torch, val_indices_torch, y_val_torch, epochs, run_number)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "2lJ2Kxomh20h"
   },
   "outputs": [],
   "source": [
    "break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "1PAjwmZMg4X6"
   },
   "outputs": [],
   "source": [
    "# with dense2 1024 of BART\n",
    "torch.cuda.empty_cache()\n",
    "\n",
    "\n",
    "epochs = 200\n",
    "run_number = randint(0, 1000)\n",
    "learning_rate = 0.005\n",
    "\n",
    "\n",
    "trained_model = train_model(model, learning_rate, abstracts_bart_embeddings, features_torch, adj_torch, pairs_torch, y_torch, val_indices_torch, y_val_torch, epochs, run_number)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "dZPrUfJnFnzB"
   },
   "outputs": [],
   "source": [
    "break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "KDQ_DCCJavQZ"
   },
   "outputs": [],
   "source": [
    "# Without dense 1000\n",
    "torch.cuda.empty_cache()\n",
    "\n",
    "\n",
    "epochs = 200\n",
    "run_number = randint(0, 1000)\n",
    "\n",
    "\n",
    "trained_model = train_model(model, 0.01, tfidf_matrix_torch, features_torch, adj_torch, pairs_torch, y_torch, val_indices_torch, y_val_torch, epochs, run_number)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "e_XPsPMFbZji"
   },
   "source": [
    "# Generate test file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "cmFO4qI7_245"
   },
   "outputs": [],
   "source": [
    "from datetime import datetime\n",
    "import re\n",
    "\n",
    "test_path = 'https://www.lix.polytechnique.fr/~nikolentzos/files/aai/challenge/test.txt'\n",
    "node_pairs = list()\n",
    "f = urlopen(test_path)\n",
    "\n",
    "for line in f:\n",
    "    t = str(line).split(',')\n",
    "    t[0] = int(re.sub(\"[^0-9]\", \"\", t[0]))\n",
    "    t[1] = int(re.sub(\"[^0-9]\", \"\", t[1]))\n",
    "    node_pairs.append((node_to_idx[int(t[0])], node_to_idx[int(t[1])]))\n",
    "\n",
    "node_pairs = np.transpose(node_pairs)\n",
    "node_pairs = add_authors_to_pairs(node_pairs, authors)\n",
    "#node_pairs = torch.LongTensor(node_pairs).to(device)\n",
    "\n",
    "adj_torch = sparse_mx_to_torch_sparse_tensor(adj).to(device)\n",
    "features_torch = torch.FloatTensor(walks_wv).to(device)\n",
    "\n",
    "test_output = model(features_torch, text_embedding, adj_torch, node_pairs)\n",
    "y_pred = torch.exp(test_output)\n",
    "y_pred = y_pred.detach().cpu().numpy()\n",
    "\n",
    "y_pred_true = list()\n",
    "for element in y_pred:\n",
    "    y_pred_true.append(element[1])\n",
    "\n",
    "today = datetime.today().strftime('%Y-%m-%d')\n",
    "random_nb = randint(0, 1000)\n",
    "model_nb = 4\n",
    "\n",
    "pd.DataFrame(y_pred_true, columns=['predicted']).to_csv(\n",
    "\"{}-submission-{}-{}.csv\".format(today, model_nb, random_nb), header=True, index=True, index_label='id'\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "pD505btvfDG0"
   },
   "outputs": [],
   "source": [
    "features.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Bfa1O6lLg4X2"
   },
   "source": [
    "# BART"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "Md1ARLd-g4X3"
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "from transformers import BartTokenizer, BartModel\n",
    "\n",
    "# Load the BART model and tokenizer\n",
    "model = BartModel.from_pretrained('facebook/bart-large')\n",
    "tokenizer = BartTokenizer.from_pretrained('facebook/bart-large')\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "Ov9PcB9wg4X3"
   },
   "outputs": [],
   "source": [
    "abstracts_bart_embeddings = []\n",
    "\n",
    "# Define a function to generate embeddings for text\n",
    "def get_bart_embeddings(text, model):\n",
    "    # Tokenize the input text\n",
    "    encoded_input = tokenizer(text, padding=True, truncation=True, return_tensors='pt')\n",
    "\n",
    "    # Generate embeddings using the BART model\n",
    "    with torch.no_grad():\n",
    "        model_output = model(**encoded_input)\n",
    "        embeddings = model_output.last_hidden_state.mean(dim=1).squeeze()\n",
    "\n",
    "    return embeddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "D_FBpRYsg4X3"
   },
   "outputs": [],
   "source": [
    "for i in tqdm(range(len(abstracts_bart_embeddings), len(voc.sentences_list))):\n",
    "    abstract = voc.sentences_list[i]\n",
    "    abstracts_bart_embeddings.append(get_bart_embeddings(abstract, model))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "j8RxfG2Eg4X3"
   },
   "outputs": [],
   "source": [
    "saved_abstracts_bart_embeddings = abstracts_bart_embeddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "Mi0TkxyFg4X3"
   },
   "outputs": [],
   "source": [
    "len(saved_abstracts_bart_embeddings), len(abstracts_bart_embeddings), len(voc.sentences_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "411JkYvrg4X4"
   },
   "outputs": [],
   "source": [
    "abstracts_bart_embeddings = torch.stack(abstracts_bart_embeddings)\n",
    "abstracts_bart_embeddings.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "iLzw5akgg4X4"
   },
   "outputs": [],
   "source": [
    "abstracts_bart_embeddings.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "hTZC7PDEg4X4"
   },
   "outputs": [],
   "source": [
    "torch.save(abstracts_bart_embeddings, 'bart_embeddings.pt')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "B6oNCPyubfSd"
   },
   "source": [
    "#Draft"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "h2UWL4y-K1jd"
   },
   "outputs": [],
   "source": [
    "# Testing\n",
    "model.eval()\n",
    "node_pairs = np.array(np.transpose(node_pairs))\n",
    "node_pairs = torch.LongTensor(node_pairs).to(device)\n",
    "\n",
    "test_output = model(features, adj, node_pairs)\n",
    "y_pred = torch.exp(test_output)\n",
    "y_pred = y_pred.detach().cpu().numpy()\n",
    "\n",
    "y_pred_true = list()\n",
    "for element in y_pred:\n",
    "    y_pred_true.append(element[1])\n",
    "    \n",
    "\n",
    "    \n",
    "today = datetime.today().strftime('%Y-%m-%d')\n",
    "random_nb = randint(0, 1000)\n",
    "\n",
    "pd.DataFrame(y_pred_true, columns={'predicted'}).to_csv(\n",
    "\"{}-submission-{}-{}.csv\".format(today, model_nb, random_nb), header=True, index=True, index_label='id'\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "QmUL7tGAR9Yt"
   },
   "outputs": [],
   "source": [
    "#### New script with batches\n",
    "\n",
    "def early_stopping(loss_train, list_loss_train, loss_val, list_loss_val, \n",
    "                   tolerance=0.01, patience=15):\n",
    "    list_loss_val = list(list_loss_val)[-patience:]\n",
    "    list_loss_train = list(list_loss_train)[-patience:]\n",
    "    if (len(list_loss_val) == patience and loss_val > (sum(list_loss_val)/len(list_loss_val)) and loss_train + tolerance < loss_val) or (len(list_loss_train) == patience and loss_train > (sum(list_loss_train)/len(list_loss_train))):\n",
    "        #print('train: {:.5f} val: {:.5f} mean val: {:.5f}'.format(loss_train, loss_val, (sum(list_loss_val)/len(list_loss_val))))\n",
    "        return True\n",
    "    return False\n",
    "    \n",
    "\n",
    "    \n",
    "def train_model(model, learning_rate, features, adj, indices_mc, y, val_indices, \n",
    "                y_val, epochs, batch_size, wv_walk_size, \n",
    "                tolerence = 0.01, patience = 15, run_number=randint(0, 1000)):\n",
    "    # Train model\n",
    "    start_time = time()\n",
    "    print('Initializing the optimizer with learning rate:', learning_rate)\n",
    "    optimizer = optim.Adam(model.parameters(), lr=learning_rate) #optimizer with halving learning rate in training\n",
    "    try: os.mkdir('./outputs')\n",
    "    except: pass\n",
    "    print('Preparing the data for training...')        \n",
    "\n",
    "    today = datetime.today().strftime('%Y-%m-%d-%H:%M')\n",
    "    list_loss_val = []\n",
    "    list_loss_train = []\n",
    "\n",
    "    \n",
    "    halving_lr = 0 # counter of the number of halving lr\n",
    "    print('Start training...')\n",
    "    for epoch in range(epochs):\n",
    "        t = time()\n",
    "\n",
    "        # we create the rand indices corresponding to non edges (their y = 0)\n",
    "        # we could apply a condition on epoch to run rand_indices (for speed purposes)\n",
    "        rand_indices = np.random.randint(0, len(indices_mc), size=(indices_mc.shape[0], indices_mc.shape[1]))\n",
    "        rand_indices = add_authors_to_pairs(rand_indices, authors)\n",
    "        pairs = np.concatenate((indices_mc, rand_indices), axis=1)\n",
    "        pairs = torch.LongTensor(pairs).to(device)\n",
    "\n",
    "        permutation = torch.randperm(pairs.size()[1])\n",
    "        \n",
    "        # batches\n",
    "        for i in range(0, pairs.size()[1], batch_size):\n",
    "            optimizer.zero_grad()\n",
    "\n",
    "            elts_indices = permutation[i:i+batch_size]\n",
    "            batch_pairs = pairs[:, elts_indices]\n",
    "            batch_y = y[elts_indices]\n",
    "\n",
    "        \n",
    "            model.train()\n",
    "\n",
    "            output = model(features, adj, batch_pairs, wv_walk_size).to(device) # we run the model that gives the output.\n",
    "            loss_train = F.nll_loss(output, batch_y) # we are using nll_loss as loss to optimize, we store it in loss_train. We compare to y which is stable and contains the tag ones and zeros.\n",
    "            acc_train = accuracy_score(torch.argmax(output, dim=1).detach().cpu().numpy(), batch_y.cpu().numpy())# just to show it in the out put message of the training\n",
    "            loss_train.backward() # The back propagation ? --> Computes the gradient of current tensor w.r.t. graph leaves\n",
    "            optimizer.step() # Performs a single optimization step (parameter update).\n",
    "        \n",
    "        model.eval()\n",
    "        output = model(features, adj, val_indices, wv_walk_size).to(device)\n",
    "        #y_val = torch.LongTensor(y_val).to(device)\n",
    "        loss_val = F.nll_loss(output, y_val)\n",
    "        list_loss_val.append(loss_val.item())\n",
    "        list_loss_train.append(loss_train.item())\n",
    "        acc_val = accuracy_score(torch.argmax(output, dim=1).detach().cpu().numpy(), y_val.cpu().numpy())\n",
    "        \n",
    "        if epoch % 5 == 0:\n",
    "            print('Epoch: {:03d}'.format(epoch+1),\n",
    "                  'loss_train: {:.4f}'.format(loss_train.item()),\n",
    "                  'loss_val: {:.4f}'.format(loss_val.item()),\n",
    "                  'acc_train: {:.4f}'.format(acc_train.item()),\n",
    "                  'acc_val: {:.4f}'.format(acc_val.item()),\n",
    "                  'time: {} s'.format(int(round(time()) - round(t))),\n",
    "                 'total_time: {} min'.format(round((time() - start_time)/60)))\n",
    "        if epoch % 50 == 0:\n",
    "            model_path = \"outputs/{}-model-{}epochs-{}.pt\".format(today, epoch, run_number)\n",
    "            torch.save(model.state_dict(), model_path)\n",
    "        \n",
    "        if int(loss_val.item()) > 5:\n",
    "            break\n",
    "            \n",
    "        early = early_stopping(loss_train.item(), list_loss_train, loss_val.item(), list_loss_val, patience=15)        \n",
    "        if early:\n",
    "            halving_lr += 1\n",
    "            if halving_lr > 5:\n",
    "                break\n",
    "            list_loss_val=[]\n",
    "            learning_rate = learning_rate/10\n",
    "            optimizer = optim.Adam(model.parameters(), lr=learning_rate)\n",
    "            print('Deviding the learning rate by 2. New learning rate: {:.6f}'.format(learning_rate))\n",
    "\n",
    "\n",
    "\n",
    "    print(\"Optimization Finished in {} min!\".format(round((time() - start_time)/60)))\n",
    "    return model\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "dwNIJmkGn6-G"
   },
   "outputs": [],
   "source": [
    "epochs = 1000\n",
    "\n",
    "trained_model = train_model(model, 0.01, features, authors, adj, indices, y, torch.tensor(val_indices).to(device), torch.tensor(y_val).to(device), epochs)\n"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [
    "dF0MJHXZVRpt",
    "Ubeigqung4X0",
    "zxvIuCP_bFrN",
    "ognzQbsFDb13"
   ],
   "machine_shape": "hm",
   "provenance": []
  },
  "gpuClass": "premium",
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  },
  "widgets": {
   "application/vnd.jupyter.widget-state+json": {
    "029723804c3b420bacce0e1ddd6bc87a": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "ProgressStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "ProgressStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "bar_color": null,
      "description_width": ""
     }
    },
    "059d6431e6f14c66b9fc272836660c56": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "0b776c922cd9412a8dfd8d49ae48bf43": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "121f5c36582c4275807e15cb4ba84f30": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_dea8d64c83754027b88f54ebc4ffd50c",
      "placeholder": "",
      "style": "IPY_MODEL_f428b21f4ed24ac49092742038b20606",
      "value": ""
     }
    },
    "15f1079aff04427d9eab2d7c97fb014e": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "18700b2d971f42d5973f0573dbe397c3": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "1888371c988242c48ba436784b533166": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "FloatProgressModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "FloatProgressModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "ProgressView",
      "bar_style": "success",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_3f0f112951ca4057960fe2bc33b10acd",
      "max": 138499,
      "min": 0,
      "orientation": "horizontal",
      "style": "IPY_MODEL_029723804c3b420bacce0e1ddd6bc87a",
      "value": 138499
     }
    },
    "2b681147457b4f859a7d9274012a004a": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "2c2b5fbf8e41412c949964f2b6cef0d7": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "FloatProgressModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "FloatProgressModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "ProgressView",
      "bar_style": "success",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_6da88af0c4414d758f684ff1258953bd",
      "max": 1,
      "min": 0,
      "orientation": "horizontal",
      "style": "IPY_MODEL_74cbbff36ac0492b937ad026df2803b1",
      "value": 1
     }
    },
    "2cb1d8e27a5346388abcebec1a1ece58": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_d524bbfc74a346f6954f15dad0eeedf1",
      "placeholder": "",
      "style": "IPY_MODEL_980cc9d1a24d459f901915403956e030",
      "value": ""
     }
    },
    "35ed948eaffd448eb483d863af5b492c": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "3f0f112951ca4057960fe2bc33b10acd": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "5faac6ba5e604a3198ad9a5c49f1e2a7": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "6b26bf5844884b34b5cc3c2b8765f6d5": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "ProgressStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "ProgressStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "bar_color": null,
      "description_width": ""
     }
    },
    "6da88af0c4414d758f684ff1258953bd": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": "20px"
     }
    },
    "74cbbff36ac0492b937ad026df2803b1": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "ProgressStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "ProgressStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "bar_color": null,
      "description_width": ""
     }
    },
    "7bd39cd6acfb4f21ace5dd23f1a82360": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": "20px"
     }
    },
    "7c4a409918d24f71a2b24ea4bf9b1049": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_35ed948eaffd448eb483d863af5b492c",
      "placeholder": "",
      "style": "IPY_MODEL_2b681147457b4f859a7d9274012a004a",
      "value": " 147950/? [00:00&lt;00:00, 1337911.69it/s]"
     }
    },
    "88102ef32915417da9df4562ec493adb": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "8b37044a7d4a4da1adfd9f40b9e27303": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "980cc9d1a24d459f901915403956e030": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "9b86291845ec4f5b83c8764ed836289e": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HBoxModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HBoxModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HBoxView",
      "box_style": "",
      "children": [
       "IPY_MODEL_2cb1d8e27a5346388abcebec1a1ece58",
       "IPY_MODEL_acaa2745e8fc468fadcd0fcc0ff9d324",
       "IPY_MODEL_e7460e2510704b458993133be5fc07bf"
      ],
      "layout": "IPY_MODEL_c5812332ac6849d1b6e0b28f40d98f5f"
     }
    },
    "aa38ef49eae14de1800c0d7fb216754b": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HBoxModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HBoxModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HBoxView",
      "box_style": "",
      "children": [
       "IPY_MODEL_121f5c36582c4275807e15cb4ba84f30",
       "IPY_MODEL_2c2b5fbf8e41412c949964f2b6cef0d7",
       "IPY_MODEL_7c4a409918d24f71a2b24ea4bf9b1049"
      ],
      "layout": "IPY_MODEL_8b37044a7d4a4da1adfd9f40b9e27303"
     }
    },
    "acaa2745e8fc468fadcd0fcc0ff9d324": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "FloatProgressModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "FloatProgressModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "ProgressView",
      "bar_style": "success",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_7bd39cd6acfb4f21ace5dd23f1a82360",
      "max": 1,
      "min": 0,
      "orientation": "horizontal",
      "style": "IPY_MODEL_6b26bf5844884b34b5cc3c2b8765f6d5",
      "value": 1
     }
    },
    "b6221c60dfdb4309b6d69db47f5621f1": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HBoxModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HBoxModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HBoxView",
      "box_style": "",
      "children": [
       "IPY_MODEL_b768368f52cb4f3d9539caf48fc459c1",
       "IPY_MODEL_1888371c988242c48ba436784b533166",
       "IPY_MODEL_f9282ecb07174c38be1a3dc45ea4a5c2"
      ],
      "layout": "IPY_MODEL_5faac6ba5e604a3198ad9a5c49f1e2a7"
     }
    },
    "b768368f52cb4f3d9539caf48fc459c1": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_0b776c922cd9412a8dfd8d49ae48bf43",
      "placeholder": "",
      "style": "IPY_MODEL_15f1079aff04427d9eab2d7c97fb014e",
      "value": "100%"
     }
    },
    "c5812332ac6849d1b6e0b28f40d98f5f": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "d524bbfc74a346f6954f15dad0eeedf1": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "dea8d64c83754027b88f54ebc4ffd50c": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "e7460e2510704b458993133be5fc07bf": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_18700b2d971f42d5973f0573dbe397c3",
      "placeholder": "",
      "style": "IPY_MODEL_88102ef32915417da9df4562ec493adb",
      "value": " 138499/? [00:00&lt;00:00, 289440.89it/s]"
     }
    },
    "ef74a17c91af4def9f5082d345ba5b33": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "f428b21f4ed24ac49092742038b20606": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "f9282ecb07174c38be1a3dc45ea4a5c2": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_059d6431e6f14c66b9fc272836660c56",
      "placeholder": "",
      "style": "IPY_MODEL_ef74a17c91af4def9f5082d345ba5b33",
      "value": " 138499/138499 [00:00&lt;00:00, 1644505.90it/s]"
     }
    }
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
