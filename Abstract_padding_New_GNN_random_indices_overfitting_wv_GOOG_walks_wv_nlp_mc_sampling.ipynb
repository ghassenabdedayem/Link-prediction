{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "XbW5vRi3mWS0"
   },
   "source": [
    "# Packages and functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "l5GfuP1hlTmg",
    "outputId": "44b88e28-f774-4e8d-8ea4-7f881cb7c62c"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "zsh:1: command not found: pip\r\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package wordnet to\n",
      "[nltk_data]     /Users/ghassenabdedayem/nltk_data...\n",
      "[nltk_data]   Package wordnet is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "from random import random\n",
    "from random import randint\n",
    "from datetime import datetime\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import log_loss, accuracy_score\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from time import time\n",
    "from gensim.models import Word2Vec\n",
    "import networkx as nx\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import torch.nn.functional as F\n",
    "import os\n",
    "from scipy.sparse import identity, diags\n",
    "from urllib.request import urlopen\n",
    "import torch.nn.functional as F\n",
    "from sklearn.metrics import log_loss, accuracy_score\n",
    "import re\n",
    "from gensim.parsing.preprocessing import remove_stopwords\n",
    "from random import choice\n",
    "\n",
    "\n",
    "\n",
    "!pip install unidecode\n",
    "\n",
    "from unidecode import unidecode\n",
    "\n",
    "#from nltk.stem import WordNetLemmatizer\n",
    "#lemmatizer = WordNetLemmatizer()\n",
    "\n",
    "from nltk.stem.snowball import SnowballStemmer\n",
    "stemmer = SnowballStemmer(\"english\")\n",
    "\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "import nltk\n",
    "nltk.download('wordnet')\n",
    "lemmatizer = WordNetLemmatizer()\n",
    "\n",
    "device = torch.device(\"cuda\") if torch.cuda.is_available() else torch.device(\"cpu\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "id": "rgUHHNwD2fzO"
   },
   "outputs": [],
   "source": [
    "def sparse_mx_to_torch_sparse_tensor(sparse_mx):\n",
    "    sparse_mx = sparse_mx.tocoo().astype(np.float32)\n",
    "    indices = torch.from_numpy(np.vstack((sparse_mx.row, sparse_mx.col)).astype(np.int64))\n",
    "    values = torch.from_numpy(sparse_mx.data)\n",
    "    shape = torch.Size(sparse_mx.shape)\n",
    "    return torch.sparse.FloatTensor(indices, values, shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "id": "BJSlSwejljfp"
   },
   "outputs": [],
   "source": [
    "\n",
    "def text_to_list(text): # a function that split the text of the authors to a list of authors\n",
    "    return unidecode(text).split(',')\n",
    "\n",
    "def intersection(lst1, lst2): # a function that returns the number of common items of two lists and 1 or 0 if there are common. This function will be used in add_authors_to_pairs to add this features to the pairs.\n",
    "    lst3 = [value for value in lst1 if value in lst2]\n",
    "    is_common = 1 if len(lst3)>0 else 0\n",
    "    return len(lst3), is_common\n",
    "\n",
    "\n",
    "def save_subgraph_in_file(nbr_nodes, source_path='../input_data/edgelist.txt', destination_path='../input_data/small_edgelist.txt'):\n",
    "    G = nx.read_edgelist(source_path, delimiter=',', create_using=nx.Graph(), nodetype=int)\n",
    "    G = G.subgraph(range(nbr_nodes))\n",
    "    nx.write_edgelist(G, path=destination_path, delimiter=',')\n",
    "    print(G.number_of_nodes(), 'nodes,', G.number_of_edges(), 'edges Graph extracted from', source_path[source_path.rfind('/')+1:])\n",
    "    G = nx.read_edgelist(destination_path, delimiter=',', create_using=nx.Graph(), nodetype=int)\n",
    "    print(G.number_of_nodes(), 'nodes,', G.number_of_edges(), 'edges Graph saved in', destination_path[destination_path.rfind('/')+1:])\n",
    "    print(max(G.nodes))\n",
    "    return\n",
    "\n",
    "\n",
    "def read_train_val_graph(path='small_edgelist.txt', val_ratio=0.1):\n",
    "    #gets the data from the file on the distant server\n",
    "    G = nx.read_edgelist(urlopen('https://www.lix.polytechnique.fr/~nikolentzos/files/aai/challenge/edgelist.txt'), delimiter=',', create_using=nx.Graph(), nodetype=int)\n",
    "    #G = nx.read_edgelist(path, delimiter=',', create_using=nx.Graph(), nodetype=int)\n",
    "    nodes = list(G.nodes())\n",
    "    n = G.number_of_nodes()\n",
    "    m = G.number_of_edges()\n",
    "    edges = list(G.edges())\n",
    "\n",
    "    print('Number of nodes:', n, 'number of edges:', m,'in the Complete the set')\n",
    "\n",
    "    node_to_idx = dict()\n",
    "    for i, node in enumerate(nodes):\n",
    "        node_to_idx[node] = i\n",
    "\n",
    "    val_edges = list()\n",
    "    G_train = G.copy()\n",
    "\n",
    "    for edge in edges:\n",
    "        if random() < val_ratio and edge[0] < n and edge[1] < n:\n",
    "            val_edges.append(edge)\n",
    "            G_train.remove_edge(edge[0], edge[1]) # We remove the val edges from the graph G\n",
    "\n",
    "   \n",
    "    #for edge in val_edges:\n",
    "        \n",
    "\n",
    "    n = G_train.number_of_nodes()\n",
    "    m = G_train.number_of_edges()\n",
    "    train_edges = list(G_train.edges())\n",
    "\n",
    "    print('Number of nodes:', n, 'number of edges:', m, 'in the Training set')\n",
    "    print('len(nodes)', len(nodes))\n",
    "\n",
    "    y_val = [1]*len(val_edges)\n",
    "\n",
    "    n_val_edges = len(val_edges)\n",
    "    \n",
    "    print('Creating random val_edges...')\n",
    "    for i in range(n_val_edges):\n",
    "        n1 = nodes[randint(0, n-1)]\n",
    "        n2 = nodes[randint(0, n-1)]\n",
    "        (n1, n2) = (min(n1, n2), max(n1, n2))\n",
    "        while n2 >= n: #or (n1, n2) in train_edges:\n",
    "            if (n1, n2) in train_edges:\n",
    "                print((n1, n2), 'in train_edges:')\n",
    "            n1 = nodes[randint(0, n-1)]\n",
    "            n2 = nodes[randint(0, n-1)]\n",
    "            (n1, n2) = (min(n1, n2), max(n1, n2))\n",
    "        val_edges.append((n1, n2))\n",
    "\n",
    "    y_val.extend([0]*(n_val_edges))\n",
    "    \n",
    "    ### From Giannis /!\\\n",
    "    val_indices = np.zeros((2,len(val_edges)))\n",
    "    for i,edge in enumerate(val_edges):\n",
    "        val_indices[0,i] = node_to_idx[edge[0]]\n",
    "        val_indices[1,i] = node_to_idx[edge[1]]\n",
    "    \n",
    "    print('Returned G_train, train_edges, val_edges, y_val, nodes and node_to_idx objects')\n",
    "    print('Loaded from', path[path.rfind('/')+1:], 'and with a training validation split ratio =', val_ratio)\n",
    "    \n",
    "    \n",
    "    \n",
    "    return G, G_train, train_edges, val_edges, val_indices, y_val, nodes, node_to_idx\n",
    "\n",
    "def random_walk(G, node, walk_length):\n",
    "    walk = [node]\n",
    "  \n",
    "    for i in range(walk_length-1):\n",
    "        neibor_nodes = list(G.neighbors(walk[-1]))\n",
    "        if len(neibor_nodes) > 0:\n",
    "            next_node = choice(neibor_nodes)\n",
    "            walk.append(next_node)\n",
    "    walk = [node for node in walk] # in case the nodes are in string format, we don't need to cast into string, but if the nodes are in numeric or integer, we need this line to cast into string\n",
    "    return walk\n",
    "\n",
    "\n",
    "def generate_walks(G, num_walks, walk_length):\n",
    "  # Runs \"num_walks\" random walks from each node, and returns a list of all random walk\n",
    "    t = time()\n",
    "    print('Start generating walks....')\n",
    "    walks = list()  \n",
    "    for i in range(num_walks):\n",
    "        for node in G.nodes():\n",
    "            walk = random_walk(G, node, walk_length)\n",
    "            walks.append(walk)\n",
    "        #print('walks : ', walks)\n",
    "    print('Random walks generated in in {}s!'.format(round(time()-t)))\n",
    "    return walks\n",
    "\n",
    "def apply_word2vec_on_features(features, nodes, vector_size=128, window=5, min_count=0, sg=1, workers=8):\n",
    "    t = time()\n",
    "    print('Start applying Word2Vec...')\n",
    "    wv_model = Word2Vec(vector_size=vector_size, window=window, min_count=min_count, sg=sg, workers=workers)\n",
    "    wv_model.build_vocab(features)\n",
    "    wv_model.train(features, total_examples=wv_model.corpus_count, epochs=5) \n",
    "    print('Word2vec model trained on features in {} min!'.format(round((time()-t)/60)))\n",
    "    features_np = []\n",
    "    for node in nodes:\n",
    "        features_np.append(wv_model.wv[node])\n",
    "\n",
    "    features_np = np.array(features_np)\n",
    "    print(features_np.shape, 'features numpy array created in {} min!'.format(round((time()-t)/60)))\n",
    "    return features_np\n",
    "\n",
    "\n",
    "\n",
    "def normalize_adjacency(A):\n",
    "    n = A.shape[0]\n",
    "    A = A + identity(n)\n",
    "    degs = A.dot(np.ones(n))\n",
    "    inv_degs = np.power(degs, -1)\n",
    "    D_inv = diags(inv_degs)\n",
    "    A_hat = D_inv.dot(A)\n",
    "    return A_hat\n",
    "\n",
    "def create_and_normalize_adjacency(G):\n",
    "    adj = nx.adjacency_matrix(G) # Obtains the adjacency matrix of the training graph\n",
    "    adj = normalize_adjacency(adj)\n",
    "    print('Created a normalized adjancency matrix of shape', adj.shape)\n",
    "    indices = np.array(adj.nonzero()) # Gets the positions of non zeros of adj into indices\n",
    "    print('Created indices', indices.shape, 'with the positions of non zeros in adj matrix')\n",
    "    return adj, indices\n",
    "\n",
    "def sparse_mx_to_torch_sparse_tensor(sparse_mx):\n",
    "    sparse_mx = sparse_mx.tocoo().astype(np.float32)\n",
    "    indices = torch.from_numpy(np.vstack((sparse_mx.row, sparse_mx.col)).astype(np.int64))\n",
    "    values = torch.from_numpy(sparse_mx.data)\n",
    "    shape = torch.Size(sparse_mx.shape)\n",
    "    return torch.sparse.FloatTensor(indices, values, shape)\n",
    " \n",
    "\n",
    "def add_authors_to_pairs (pairs, authors):\n",
    "    #authors = pd.DataFrame(authors)\n",
    "    try: \n",
    "        pairs = pairs.detach().cpu().numpy()\n",
    "    except:\n",
    "        pass\n",
    "\n",
    "    pairs_df = pd.DataFrame(np.transpose(pairs)).rename(columns={0: \"paper_1\", 1: \"paper_2\"})\n",
    "    #pairs = torch.tensor(pairs).to(device)\n",
    "    pairs_df = pairs_df.merge(authors, left_on='paper_1', right_on='paper_id', how='left').rename(columns={'authors': \"authors_1\"})\n",
    "    pairs_df = pairs_df.merge(authors, left_on='paper_2', right_on='paper_id', how='left').rename(columns={'authors': \"authors_2\"})\n",
    "    pairs_df.drop(['paper_id_x', 'paper_id_y'], axis=1, inplace=True)\n",
    "\n",
    "    pairs_df['nb_common_author'] = pairs_df.apply(lambda row: intersection(row['authors_1'], row['authors_2'])[0], axis=1)\n",
    "    pairs_df['is_common_author'] = pairs_df.apply(lambda row: intersection(row['authors_1'], row['authors_2'])[1], axis=1)\n",
    "\n",
    "    #pairs_tensor = torch.LongTensor(np.transpose(pairs_df[[\"paper_1\", \"paper_2\", 'is_common_author', 'nb_common_author']].values.tolist())).to(device)\n",
    "    \n",
    "    return np.transpose(pairs_df[[\"paper_1\", \"paper_2\", 'is_common_author', 'nb_common_author']].values.tolist())\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "id": "5ef7pPp7lBeS"
   },
   "outputs": [],
   "source": [
    "def read_and_clean_abstracts (nodes, sample_length=-1, abstracts_path = 'https://www.lix.polytechnique.fr/~nikolentzos/files/aai/challenge/abstracts.txt'):\n",
    "    t = time()\n",
    "    abstracts = dict()\n",
    "    abstracts_list = list()\n",
    "    f = urlopen(abstracts_path)\n",
    "    \n",
    "    for i, line in enumerate(f):\n",
    "        if i == sample_length:\n",
    "            break\n",
    "        if i in nodes:\n",
    "            node, abstract = str(line).lower().split('|--|')\n",
    "            abstract = remove_stopwords(abstract)\n",
    "            abstract = re.sub(r\"[,.;@#?!&$()-]\", \" \", abstract)\n",
    "\n",
    "            for word in abstract.split()[:-1]:\n",
    "                #abstract = abstract.replace(word, stemmer.stem(word))\n",
    "                abstract = abstract.replace(word, lemmatizer.lemmatize(lemmatizer.lemmatize(lemmatizer.lemmatize(lemmatizer.lemmatize(lemmatizer.lemmatize(lemmatizer.lemmatize(word), pos='s'), pos='a'), pos='n'), pos='v'), pos='r'))\n",
    "            \n",
    "            node = re.sub(\"[^0-9]\", \"\", node)\n",
    "            if i != int(node):\n",
    "                print('i and node not the same', i, node)\n",
    "            abstracts[int(node)] = abstract\n",
    "            abstracts_list.append(abstract)\n",
    "        \n",
    "    print('Text loaded and cleaned in {:.0f} sec'.format(time()-t))\n",
    "    return abstracts\n",
    "\n",
    "def doc_counter (documents, word): #a function that return the number of documents containing a word\n",
    "    counter = 0\n",
    "    for i in documents:\n",
    "        if word in documents[i]:\n",
    "            counter += 1\n",
    "    return counter\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "id": "UAOZ3MLP98UR"
   },
   "outputs": [],
   "source": [
    "class Vocabulary:\n",
    "\n",
    "    def __init__(self, name):\n",
    "        self.name = name\n",
    "        self.word2index = {}\n",
    "        self.word2count = {}\n",
    "        self.index2word = {}\n",
    "        self.word_occurrence = {}\n",
    "        self.words_list = []\n",
    "        self.sentences_list = []\n",
    "        self.sentences_list_words = []\n",
    "        self.num_words = 0\n",
    "        self.num_sentences = 0\n",
    "        self.longest_sentence = 0\n",
    "\n",
    "    def add_word(self, word):\n",
    "        if word not in self.word2index:\n",
    "            # First entry of word into vocabulary\n",
    "            self.words_list.append(word)\n",
    "            self.word2index[word] = self.num_words\n",
    "            self.word2count[word] = 1\n",
    "            self.index2word[self.num_words] = word\n",
    "            self.num_words += 1\n",
    "            self.word_occurrence[word] = 1\n",
    "        else:\n",
    "            # Word exists; increase word count\n",
    "            self.word2count[word] += 1\n",
    "            self.word_occurrence[word] += 1\n",
    "            \n",
    "    def add_sentence(self, sentence):\n",
    "        sentence_len = 0\n",
    "        for word in sentence.split()[:-1]:\n",
    "            sentence_len += 1\n",
    "            self.add_word(word)\n",
    "        if sentence_len > self.longest_sentence:\n",
    "            # This is the longest sentence\n",
    "            self.longest_sentence = sentence_len\n",
    "        # Count the number of sentences\n",
    "        self.num_sentences += 1\n",
    "        self.sentences_list.append(sentence)\n",
    "        self.sentences_list_words.append(sentence.split()[:-1])\n",
    "\n",
    "    def to_word(self, index):\n",
    "        return self.index2word[index]\n",
    "\n",
    "    def to_index(self, word):\n",
    "        return self.word2index[word]\n",
    "\n",
    "    def words(self):\n",
    "        return self.words_list\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {
    "id": "QlXtTyCe4C_J"
   },
   "outputs": [],
   "source": [
    "from tqdm import tqdm\n",
    "from multiprocessing import Pool, cpu_count\n",
    "from functools import partial\n",
    "import numpy as np\n",
    "from time import time\n",
    "\n",
    "def replace_words_with_embeddings(abstract_list_of_words, wv_model):\n",
    "    if len(abstract_list_of_words) == 0:\n",
    "        result_embeddings = []\n",
    "    else:\n",
    "        result_embeddings = wv_model[abstract_list_of_words]\n",
    "    return result_embeddings\n",
    "\n",
    "def words_embeddings_multithread(wv_model, abstracts):\n",
    "    from time import time\n",
    "    t = time()\n",
    "    embedded_abstracts = dict()\n",
    "    \n",
    "    with Pool(processes=cpu_count()) as p:\n",
    "        results = list(tqdm(p.imap(partial(replace_words_with_embeddings, wv_model=wv_model), abstracts), total=len(abstracts)))\n",
    "        \n",
    "    for node, result_embeddings in enumerate(results):\n",
    "        embedded_abstracts[node] = result_embeddings\n",
    "        \n",
    "    print('list of words embeddings generated for each node in {:.0f} min'.format((time()-t)/60))\n",
    "    return embedded_abstracts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tqdm import tqdm\n",
    "from multiprocessing import Pool, cpu_count\n",
    "\n",
    "def replace_missing_words_with_random(abstract_list_of_words, wv_model):\n",
    "    if len(abstract_list_of_words) == 0:\n",
    "        embedded_abstracts[node] = []\n",
    "    else:\n",
    "        missing_word_mask = ~np.isin(abstract_list_of_words, wv_model.index_to_key)\n",
    "        missing_word_indices = np.where(missing_word_mask)[0]\n",
    "        missing_word_embeddings = np.random.rand(len(missing_word_indices), wv_model.vector_size)\n",
    "        abstract_list_of_words_clean = np.compress(~missing_word_mask, abstract_list_of_words)\n",
    "        result_embeddings = np.vstack((wv_model[abstract_list_of_words_clean], missing_word_embeddings))\n",
    "    return result_embeddings\n",
    "\n",
    "def word_embeddings_replace_missing_words_with_random(wv_model, abstracts):\n",
    "    t = time()\n",
    "    embedded_abstracts = dict()\n",
    "    \n",
    "    with Pool(processes=cpu_count()) as p:\n",
    "        results = list(tqdm(p.imap(lambda x: replace_missing_words_with_random(x, wv_model), abstracts), total=len(abstracts)))\n",
    "    \n",
    "    for node, result_embeddings in enumerate(results):\n",
    "        embedded_abstracts[node] = result_embeddings\n",
    "    \n",
    "    print('list of words embeddings generated for each node in {:.0f} min'.format((time()-t)/60))\n",
    "    return embedded_abstracts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tqdm import tqdm\n",
    "from multiprocessing import Pool, cpu_count\n",
    "from functools import partial\n",
    "\n",
    "def replace_missing_words_with_random(abstract_list_of_words, wv_model):\n",
    "    if len(abstract_list_of_words) == 0:\n",
    "        embedded_abstracts[node] = []\n",
    "    else:\n",
    "        missing_word_mask = ~np.isin(abstract_list_of_words, wv_model.index_to_key)\n",
    "        missing_word_indices = np.where(missing_word_mask)[0]\n",
    "        missing_word_embeddings = np.random.rand(len(missing_word_indices), wv_model.vector_size)\n",
    "        abstract_list_of_words_clean = np.compress(~missing_word_mask, abstract_list_of_words)\n",
    "        result_embeddings = np.vstack((wv_model[abstract_list_of_words_clean], missing_word_embeddings))\n",
    "    return result_embeddings\n",
    "\n",
    "def word_embeddings_replace_missing_words_with_random(wv_model, abstracts):\n",
    "    t = time()\n",
    "    embedded_abstracts = dict()\n",
    "    \n",
    "    with Pool(processes=cpu_count()) as p:\n",
    "        results = list(tqdm(p.imap(partial(replace_missing_words_with_random, wv_model=wv_model), abstracts), total=len(abstracts)))\n",
    "        \n",
    "    for node, result_embeddings in enumerate(results):\n",
    "        embedded_abstracts[node] = result_embeddings\n",
    "        \n",
    "    print('list of words embeddings generated for each node in {:.0f} min'.format((time()-t)/60))\n",
    "    return embedded_abstracts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def list_words_to_one_sentence_wv_vector(wv_model, sentences_list_words):\n",
    "    t = time()\n",
    "\n",
    "    embedded_abstracts = dict()\n",
    "    for node, abstract in enumerate(sentences_list_words):\n",
    "        #some abstracts are null\n",
    "        cleaned_abstract=[]\n",
    "        for word in abstract:\n",
    "            try: \n",
    "                wv_model[word] #we try to find the word in the Vocabulary\n",
    "                cleaned_abstract.append(word)\n",
    "            except: pass\n",
    "        if len(cleaned_abstract) > 0:\n",
    "            wv_model[cleaned_abstract]\n",
    "            embedded_abstracts[node] = np.mean(wv_model[cleaned_abstract], axis=0)\n",
    "            for quartile in np.percentile(wv_model[cleaned_abstract], [25, 50, 75], axis=0):\n",
    "                embedded_abstracts[node] = np.concatenate((embedded_abstracts[node], quartile), axis=0)\n",
    "        else: #if the abstract text is null, we fill the embedded text vector by random numbers (it could help to prevent overfittiing)\n",
    "            embedded_abstracts[node] = np.random.uniform(wv_model.vectors.min(), wv_model.vectors.max(), size=embedded_abstracts[0].shape)\n",
    "        if (node % 10000 == 0):\n",
    "            print('Procssed at {:.0f} % in {:.0f} min'.format((node / len(abstracts))*100, (time()-t)/60))\n",
    "    print('nodes embeddings generated based on words embeddings in {:.0f}'.format((time()-t)/60)) #206 sec\n",
    "    return embedded_abstracts, cleaned_abstract"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "def list_words_to_list_embeddings(sentences_list_words, wv_model):\n",
    "    t = time()\n",
    "\n",
    "    embedded_abstracts = dict()\n",
    "    for node, abstract in enumerate(sentences_list_words):\n",
    "        #some abstracts are null\n",
    "        cleaned_abstract=[]\n",
    "        for word in abstract:\n",
    "            try: \n",
    "                wv_model[word] #we try to find the word in the Vocabulary\n",
    "                cleaned_abstract.append(word)\n",
    "            except: pass\n",
    "        if len(cleaned_abstract) > 0:\n",
    "            embedded_abstracts[node] = wv_model[cleaned_abstract]\n",
    "        else: #if the abstract text is null, we fill the embedded text vector by random numbers (it could help to prevent overfittiing)\n",
    "            embedded_abstracts[node] = np.zeros(shape=embedded_abstracts[0].shape)\n",
    "        if (node % 10000 == 0):\n",
    "            print('Procssed at {:.0f} % in {:.0f} min'.format((node / len(abstracts))*100, (time()-t)/60))\n",
    "    print('nodes embeddings generated based on words embeddings in {:.0f} min in embedded_abstracts'.format((time()-t)/60)) #206 sec\n",
    "    return embedded_abstracts, cleaned_abstract"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "id": "iHDwUFfhUmJw"
   },
   "outputs": [],
   "source": [
    "def train_wv_on_vocab (voc, vector_size):\n",
    "    t = time()\n",
    "    wv_model = Word2Vec(vector_size=vector_size, window=5, min_count=1, sg=1, workers=8)\n",
    "    wv_model.build_vocab(voc.sentences_list_words)\n",
    "    wv_model.train(voc.sentences_list_words, total_examples=wv_model.corpus_count, epochs=5) \n",
    "    print('word2vec trained in {:.0f} sec'.format(time()-t)) #219 sec\n",
    "    return wv_model\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "MH6hAskFw5AU"
   },
   "source": [
    "# Features processing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "oHyYv78NlkXU",
    "outputId": "2aad4843-6b00-4a07-e4dc-197e403c9c0a"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of nodes: 138499 number of edges: 1091955 in the Complete the set\n",
      "Number of nodes: 138499 number of edges: 982981 in the Training set\n",
      "len(nodes) 138499\n",
      "Creating random val_edges...\n",
      "Returned G_train, train_edges, val_edges, y_val, nodes and node_to_idx objects\n",
      "Loaded from small_edgelist.txt and with a training validation split ratio = 0.1\n",
      "Start generating walks....\n",
      "Random walks generated in in 58s!\n",
      "Start applying Word2Vec...\n",
      "Word2vec model trained on features in 2 min!\n",
      "(138499, 64) features numpy array created in 2 min!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/pd/glcnl2497w5b6xn3p94tnwlr0000gn/T/ipykernel_86421/975224092.py:139: FutureWarning: adjacency_matrix will return a scipy.sparse array instead of a matrix in Networkx 3.0.\n",
      "  adj = nx.adjacency_matrix(G) # Obtains the adjacency matrix of the training graph\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Created a normalized adjancency matrix of shape (138499, 138499)\n",
      "Created indices (2, 2104461) with the positions of non zeros in adj matrix\n"
     ]
    }
   ],
   "source": [
    "path = 'input_data/small_edgelist.txt' #not used\n",
    "num_walks = 10\n",
    "walk_length=15\n",
    "wv_vector_size = 64\n",
    "\n",
    "G, G_train, train_edges, val_edges, val_indices, y_val, nodes, node_to_idx = read_train_val_graph(path=path, val_ratio=0.1)\n",
    "walks = generate_walks(G=G_train, num_walks=num_walks, walk_length=walk_length)\n",
    "walks_wv = apply_word2vec_on_features(features=walks, nodes=nodes, vector_size=wv_vector_size)\n",
    "adj, indices = create_and_normalize_adjacency(G_train)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 197,
   "metadata": {
    "id": "sbhiufK3kLG7"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Text loaded and cleaned in 499 sec\n",
      "Text cleaned and vocab built in 540 sec\n"
     ]
    }
   ],
   "source": [
    "t = time()\n",
    "n = -1 #length of the sample to develop and test the pipeline (-1 or negative values to take all the dataset)\n",
    "\n",
    "#takes 4 minutes to process all the abstracts\n",
    "abstracts = read_and_clean_abstracts(nodes, sample_length=n)  #149s #194s\n",
    "abstracts_dict_list_words = {i: abstracts[i].split()[:-1] for i in nodes}\n",
    "abstracts_list_sentences = [list(item)[1][:-3] for item in abstracts.items()]\n",
    "\n",
    "#we create a vacabulary of words and sentences (abstracts)\n",
    "#we take only a sample of 3 abstracts (i=2) to explore the approach\n",
    "voc = Vocabulary('abstracts') \n",
    "for i in nodes:\n",
    "    voc.add_sentence(abstracts[i])\n",
    "\n",
    "print('Text cleaned and vocab built in {:.0f} min'.format((time()-t)/60))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 200,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "657"
      ]
     },
     "execution_count": 200,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#apply wv to cleaned abstracts\n",
    "vector_size = 192\n",
    "\n",
    "wv_model = train_wv_on_vocab (voc, vector_size=vector_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 205,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['development',\n",
       " 'automate',\n",
       " 'quality',\n",
       " 'assessment',\n",
       " 'aerodrome',\n",
       " 'grind',\n",
       " 'light',\n",
       " 'agl',\n",
       " 'accordance',\n",
       " 'associate',\n",
       " 'standard',\n",
       " 'recommendation',\n",
       " 'present',\n",
       " 'compose',\n",
       " 'image',\n",
       " 'sensor',\n",
       " 'place',\n",
       " 'inside',\n",
       " 'cockpit',\n",
       " 'aircraft',\n",
       " 'record',\n",
       " 'normal',\n",
       " 'descent',\n",
       " 'model',\n",
       " 'base',\n",
       " 'methodology',\n",
       " 'ascertain',\n",
       " 'optimum',\n",
       " 'match',\n",
       " 'template',\n",
       " 'actual',\n",
       " 'data',\n",
       " 'order',\n",
       " 'calculate',\n",
       " 'position',\n",
       " 'orientation',\n",
       " 'camera',\n",
       " 'instant',\n",
       " 'acquire',\n",
       " 'pixel',\n",
       " 'grey',\n",
       " 'level',\n",
       " 'luminaire',\n",
       " 'estimate',\n",
       " 'value',\n",
       " 'luminous',\n",
       " 'intensity',\n",
       " 'give',\n",
       " 'compare',\n",
       " 'expect',\n",
       " 'brightness',\n",
       " 'ensure',\n",
       " 'operate',\n",
       " 'require',\n",
       " 'such',\n",
       " 'metric',\n",
       " 'pattern',\n",
       " 'determine',\n",
       " 'experiment',\n",
       " 'real',\n",
       " 'demonstrate',\n",
       " 'application',\n",
       " 'effectiveness',\n",
       " 'system',\n",
       " 'paper',\n",
       " 'propose',\n",
       " 'novel',\n",
       " 'hybrid',\n",
       " 'forward',\n",
       " 'algorithm',\n",
       " 'hfa',\n",
       " 'construction',\n",
       " 'radial',\n",
       " 'basis',\n",
       " 'function',\n",
       " 'rbf',\n",
       " 'neural',\n",
       " 'network',\n",
       " 'tunable',\n",
       " 'node',\n",
       " 'main',\n",
       " 'objective',\n",
       " 'efficiently',\n",
       " 'effectively',\n",
       " 'produce',\n",
       " 'parsimonious',\n",
       " 'generalize',\n",
       " 'well',\n",
       " 'study',\n",
       " 'achieve',\n",
       " 'simultaneous',\n",
       " 'structure',\n",
       " 'determination',\n",
       " 'parameter',\n",
       " 'optimization',\n",
       " 'continuous',\n",
       " 'space',\n",
       " 'mix',\n",
       " 'integer',\n",
       " 'hard',\n",
       " 'problem',\n",
       " 'tackle',\n",
       " 'integrate',\n",
       " 'analytic',\n",
       " 'framework',\n",
       " 'lead',\n",
       " 'significantly',\n",
       " 'improve',\n",
       " 'performance',\n",
       " 'reduce',\n",
       " 'memory',\n",
       " 'usage',\n",
       " 'computational',\n",
       " 'complexity',\n",
       " 'analysis',\n",
       " 'confirm',\n",
       " 'efficiency',\n",
       " 'simulation',\n",
       " 'result',\n",
       " 'modern',\n",
       " 'ccd',\n",
       " 'usually',\n",
       " 'capable',\n",
       " 'spatial',\n",
       " 'accuracy',\n",
       " 'great',\n",
       " '1/50',\n",
       " 'size',\n",
       " 'however',\n",
       " 'easily',\n",
       " 'attain',\n",
       " 'error',\n",
       " 'source',\n",
       " 'affect',\n",
       " 'formation',\n",
       " 'process',\n",
       " 'current',\n",
       " 'calibration',\n",
       " 'meethod',\n",
       " 'typically',\n",
       " 'assume',\n",
       " 'observation',\n",
       " 'unbiased',\n",
       " 'zero',\n",
       " 'mean',\n",
       " 'independent',\n",
       " 'identically',\n",
       " 'distribute',\n",
       " 'random',\n",
       " 'noise',\n",
       " 'observe',\n",
       " 'coordinate',\n",
       " 'completely',\n",
       " 'explain',\n",
       " 'map',\n",
       " '3d',\n",
       " 'general',\n",
       " 'condition',\n",
       " 'meet',\n",
       " 'cause',\n",
       " 'accurate',\n",
       " 'procedure',\n",
       " 'precise',\n",
       " 'vision',\n",
       " 'describe',\n",
       " 'introduce',\n",
       " 'bias',\n",
       " 'correction',\n",
       " 'circular',\n",
       " 'control',\n",
       " 'point',\n",
       " 'nonrecursive',\n",
       " 'reverse',\n",
       " 'distortion',\n",
       " 'theoretical',\n",
       " 'discuss',\n",
       " 'test',\n",
       " 'synthetic',\n",
       " 'indicate',\n",
       " 'improvement',\n",
       " 'limit',\n",
       " 'suppression',\n",
       " 'external',\n",
       " 'prerequisite',\n",
       " 'successful',\n",
       " 'deal',\n",
       " 'fuzzy',\n",
       " 'nonlinear',\n",
       " 'identification',\n",
       " 'local',\n",
       " 'lmn',\n",
       " 'new',\n",
       " 'iterative',\n",
       " 'approach',\n",
       " 'supervise',\n",
       " 'unsupervise',\n",
       " 'learn',\n",
       " 'combine',\n",
       " 'optimize',\n",
       " 'purpose',\n",
       " 'fit',\n",
       " 'cluster',\n",
       " 'center',\n",
       " 'nonlinearity',\n",
       " 'gustafsson',\n",
       " 'kessel',\n",
       " 'gk',\n",
       " 'i',\n",
       " 'e',\n",
       " 'apply',\n",
       " 'combination',\n",
       " 'incremental',\n",
       " 'method',\n",
       " 'define',\n",
       " 'number',\n",
       " 'initial',\n",
       " 'location',\n",
       " 'correspond',\n",
       " 'region',\n",
       " 'linear',\n",
       " 'validity',\n",
       " 'covariance',\n",
       " 'matrix',\n",
       " 'highly',\n",
       " 'adaptable',\n",
       " 'sparse',\n",
       " 'construct',\n",
       " 'finally',\n",
       " 'drug',\n",
       " 'absorption',\n",
       " 'spectral',\n",
       " 'namely',\n",
       " 'lolimot',\n",
       " 'hilomot',\n",
       " 'comparison',\n",
       " 'experimental',\n",
       " 'show',\n",
       " 'usefulness',\n",
       " 'unify',\n",
       " 'include',\n",
       " 'regression',\n",
       " 'classification',\n",
       " 'probability',\n",
       " 'density',\n",
       " 'estimation',\n",
       " 'orthogonal',\n",
       " 'least',\n",
       " 'square',\n",
       " 'leave',\n",
       " 'one',\n",
       " 'out',\n",
       " 'criterion',\n",
       " 'formulate',\n",
       " 'kernel',\n",
       " 'generalise',\n",
       " 'example',\n",
       " 'illustrate',\n",
       " 'generic',\n",
       " 'excellent',\n",
       " 'generalisation',\n",
       " 'capability',\n",
       " 'investigate',\n",
       " 'selection',\n",
       " 'multi',\n",
       " 'output',\n",
       " 'fast',\n",
       " 'recursive',\n",
       " 'mfra',\n",
       " 'reveal',\n",
       " 'significance',\n",
       " 'candidate',\n",
       " 'reduction',\n",
       " 'trace',\n",
       " 'weight',\n",
       " 'simultaneously',\n",
       " 'substitution',\n",
       " 'contribution',\n",
       " 'perform',\n",
       " 'context',\n",
       " 'extreme',\n",
       " 'machine',\n",
       " 'elm',\n",
       " 'huang',\n",
       " 'et',\n",
       " 'al',\n",
       " 'develop',\n",
       " 'single',\n",
       " 'hide',\n",
       " 'layer',\n",
       " 'feedforward',\n",
       " 'slfns',\n",
       " 'wide',\n",
       " 'variety',\n",
       " 'prove',\n",
       " 'effective',\n",
       " 'especially',\n",
       " 'solve',\n",
       " 'approximation',\n",
       " 'predetermine',\n",
       " 'preliminary',\n",
       " 'tedious',\n",
       " 'solution',\n",
       " 'systematic',\n",
       " 'two',\n",
       " 'stage',\n",
       " 'name',\n",
       " 't',\n",
       " 'handle',\n",
       " 'select',\n",
       " 'randomly',\n",
       " 'generate',\n",
       " 'step',\n",
       " 'add',\n",
       " 'stop',\n",
       " 'minimum',\n",
       " 'review',\n",
       " 'second',\n",
       " 'insignificance',\n",
       " 'remove',\n",
       " 'drastically',\n",
       " 'verify',\n",
       " 'empirical',\n",
       " 'rbfnns',\n",
       " 'widely',\n",
       " 'challenge',\n",
       " 'rbfnn',\n",
       " 'width',\n",
       " 'concurrent',\n",
       " 'subspace',\n",
       " 'cswo',\n",
       " 'decomposition',\n",
       " 'coordination',\n",
       " 'strategy',\n",
       " 'decompose',\n",
       " 'large',\n",
       " 'scale',\n",
       " 'sso',\n",
       " 'variable',\n",
       " 'small',\n",
       " 'train',\n",
       " 'validation',\n",
       " 'set',\n",
       " 'greatly',\n",
       " 'simplify',\n",
       " 'ssos',\n",
       " 'concurrently',\n",
       " 'time',\n",
       " 'top',\n",
       " 'converge',\n",
       " 'consistent',\n",
       " 'equivalent',\n",
       " 'original',\n",
       " 'mathematical',\n",
       " 'practical',\n",
       " 'engineer',\n",
       " 'robustness',\n",
       " 'traditional',\n",
       " 'class',\n",
       " 'adjustable',\n",
       " 'speed',\n",
       " 'convergence',\n",
       " 'levenberg',\n",
       " 'marquardt',\n",
       " 'lm',\n",
       " 'dimension',\n",
       " 'jacobian',\n",
       " 'unlike',\n",
       " 'conventional',\n",
       " 'convert',\n",
       " 'dependent',\n",
       " 'need',\n",
       " 'explicit',\n",
       " 'computation',\n",
       " 'consequently',\n",
       " 'nn',\n",
       " 'use',\n",
       " 'popular',\n",
       " 'cost',\n",
       " 'efficacy',\n",
       " 'different',\n",
       " 'know',\n",
       " 'statistic',\n",
       " 'regressors',\n",
       " 'rank',\n",
       " 'wilcoxon',\n",
       " 'robust',\n",
       " 'or',\n",
       " 'insensitive',\n",
       " 'to',\n",
       " 'outlier',\n",
       " 'motivate',\n",
       " 'area',\n",
       " 'specifically',\n",
       " 'wnn',\n",
       " 'wgrbfn',\n",
       " 'wfnn',\n",
       " 'regressor',\n",
       " 'kwr',\n",
       " 'provide',\n",
       " 'alternative',\n",
       " 'face',\n",
       " 'simple',\n",
       " 'update',\n",
       " 'rule',\n",
       " 'gradient',\n",
       " 'derive',\n",
       " 'numerical',\n",
       " 'good',\n",
       " 'firmly',\n",
       " 'believe',\n",
       " 'promise',\n",
       " 'abstract',\n",
       " 'gsln',\n",
       " 'architecture',\n",
       " 'implement',\n",
       " 'sum',\n",
       " 'arbitrary',\n",
       " 'input',\n",
       " 'potentially',\n",
       " 'flexible',\n",
       " 'efficient',\n",
       " 'approximate',\n",
       " 'drawback',\n",
       " 'gslns',\n",
       " 'satisfactory',\n",
       " 'search',\n",
       " 'ifos',\n",
       " 'couple',\n",
       " 'description',\n",
       " 'length',\n",
       " 'mdl',\n",
       " 'automatic',\n",
       " 'dub',\n",
       " 'ifos\\\\xe2\\\\x80\\\\x93mdl',\n",
       " 'growth',\n",
       " 'prune',\n",
       " 'blind',\n",
       " 'equalization',\n",
       " 'exploit',\n",
       " 'short',\n",
       " 'term',\n",
       " 'predictability',\n",
       " 'net',\n",
       " 'predict',\n",
       " 'inverse',\n",
       " 'filter',\n",
       " 'prediction',\n",
       " 'minimize',\n",
       " 'coefficient',\n",
       " 'identical',\n",
       " 'unknown',\n",
       " 'enhance',\n",
       " 'noisy',\n",
       " 'environment',\n",
       " 'il',\n",
       " 'concept',\n",
       " 'distance',\n",
       " 'additive',\n",
       " 'measurement',\n",
       " 'rate',\n",
       " 'analyze',\n",
       " 'asymptotic',\n",
       " 'mse',\n",
       " 'predictive',\n",
       " 'theoretically',\n",
       " 'monte',\n",
       " 'carlo',\n",
       " 'technique',\n",
       " 'applications:',\n",
       " 'life',\n",
       " 'radar',\n",
       " 'sea',\n",
       " 'clutter',\n",
       " 'collect',\n",
       " 'east',\n",
       " 'coast',\n",
       " 'canada',\n",
       " 'deconvolution',\n",
       " 'speech',\n",
       " 'signal',\n",
       " 'case',\n",
       " 'channel',\n",
       " 'effect',\n",
       " 'strong',\n",
       " 'consider',\n",
       " 'snpom',\n",
       " 'adapt',\n",
       " 'style',\n",
       " 'autoregressive',\n",
       " 'exogenous',\n",
       " 'off',\n",
       " 'line',\n",
       " 'depend',\n",
       " 'partly',\n",
       " 'singular',\n",
       " 'accelerate',\n",
       " 'type',\n",
       " 'tune',\n",
       " 'genetic',\n",
       " 'ga',\n",
       " 'benchmark',\n",
       " 'switch',\n",
       " 'link',\n",
       " 'this',\n",
       " 'relationship',\n",
       " 'choose',\n",
       " 'manually',\n",
       " 'increase',\n",
       " 'fitness',\n",
       " 'enough',\n",
       " 'sunspot',\n",
       " 'forecast',\n",
       " 'associative',\n",
       " 'merit',\n",
       " 'work',\n",
       " 'sequential',\n",
       " 'refer',\n",
       " 'grow',\n",
       " 'ggap',\n",
       " 'neuron',\n",
       " 'u',\n",
       " 'realize',\n",
       " 'near',\n",
       " 'intentionally',\n",
       " 'measure',\n",
       " 'average',\n",
       " 'information',\n",
       " 'content',\n",
       " 'sample',\n",
       " 'rigorous',\n",
       " 'statistical',\n",
       " 'view',\n",
       " 'bench',\n",
       " 'mark',\n",
       " 'outperform',\n",
       " 'generalization',\n",
       " 'regardless',\n",
       " 'backstepping',\n",
       " 'affine',\n",
       " 'strict',\n",
       " 'feedback',\n",
       " 'form',\n",
       " 'nonlinearities',\n",
       " 'special',\n",
       " 'design',\n",
       " 'scheme',\n",
       " 'controller',\n",
       " 'singularity',\n",
       " 'avoid',\n",
       " 'perfectly',\n",
       " 'furthermore',\n",
       " 'close',\n",
       " 'loop',\n",
       " 'guarantee',\n",
       " 'semiglobally',\n",
       " 'uniformly',\n",
       " 'ultimately',\n",
       " 'bound',\n",
       " 'neighborhood',\n",
       " 'desire',\n",
       " 'trajectory',\n",
       " 'shape',\n",
       " 'suitably',\n",
       " 'obtain',\n",
       " 'difference',\n",
       " 'briefly',\n",
       " 'placement',\n",
       " 'say',\n",
       " 'significant',\n",
       " 'superior',\n",
       " 'locate',\n",
       " 'sigmoid',\n",
       " 'offset',\n",
       " 'regular',\n",
       " 'way',\n",
       " 'overcome',\n",
       " 'fine',\n",
       " 'evaluate',\n",
       " 'move',\n",
       " 'decrease',\n",
       " 'then',\n",
       " 'change',\n",
       " 'bind',\n",
       " 'hessian',\n",
       " 'fix',\n",
       " 'moreover',\n",
       " 'begin',\n",
       " 'possible',\n",
       " 'that',\n",
       " 'specify',\n",
       " 'deliver',\n",
       " 'support',\n",
       " 'vector',\n",
       " 'svms',\n",
       " 'subnetwork',\n",
       " 'object',\n",
       " 'respect',\n",
       " 'distinction',\n",
       " 'feature',\n",
       " 'o',\n",
       " 'nlogn',\n",
       " 'n',\n",
       " 'important',\n",
       " 'advantage',\n",
       " 'svm',\n",
       " 'generally',\n",
       " 'take',\n",
       " 'far',\n",
       " 'classifier',\n",
       " 'contemporary',\n",
       " 'particular',\n",
       " 'continuously',\n",
       " 'database',\n",
       " 'desirable',\n",
       " 'carry',\n",
       " 'run',\n",
       " 'word',\n",
       " 'resort',\n",
       " 'mechanism',\n",
       " 'against',\n",
       " 'all',\n",
       " 'dataset',\n",
       " 'interest',\n",
       " 'recent',\n",
       " 'able',\n",
       " 'high',\n",
       " 'exist',\n",
       " 'instance',\n",
       " 'issue',\n",
       " 'address',\n",
       " 'regard',\n",
       " 'remain',\n",
       " 'na/spl',\n",
       " 'inodot//spl',\n",
       " 'uml/ve',\n",
       " 'identify',\n",
       " 'software',\n",
       " 'distribution',\n",
       " 'boundary',\n",
       " 'crucial',\n",
       " 'inner',\n",
       " 'part',\n",
       " 'multiobjective',\n",
       " 'evolutionary',\n",
       " 'target',\n",
       " 'pair',\n",
       " 'allow',\n",
       " 'heuristic',\n",
       " 'hand',\n",
       " 'operator',\n",
       " 'transformations:',\n",
       " 'svd',\n",
       " 'ols',\n",
       " 'mutation',\n",
       " 'global',\n",
       " 'modification',\n",
       " 'rbfs',\n",
       " 'the',\n",
       " 'individual',\n",
       " 'population',\n",
       " 'yield',\n",
       " 'adjust',\n",
       " 'recognition',\n",
       " 'discrete',\n",
       " 'cosine',\n",
       " 'transform',\n",
       " 'dct',\n",
       " 'fisheru0027s',\n",
       " 'discriminant',\n",
       " 'fld',\n",
       " 'first',\n",
       " 'dimensionality',\n",
       " 'illumination',\n",
       " 'variation',\n",
       " 'alleviate',\n",
       " 'discard',\n",
       " 'low',\n",
       " 'frequency',\n",
       " 'next',\n",
       " 'truncate',\n",
       " 'make',\n",
       " 'subsequent',\n",
       " 'discriminate',\n",
       " 'invariant',\n",
       " 'facial',\n",
       " 'maintain',\n",
       " 'consequence',\n",
       " 'fulfil',\n",
       " 'facilitate',\n",
       " 'gaussian',\n",
       " 'commonly',\n",
       " 'fully',\n",
       " 'unsupervised',\n",
       " 'manner',\n",
       " 'supervision',\n",
       " 'concatenate',\n",
       " 'input\\\\xe2\\\\x80\\\\x93output',\n",
       " 'separately',\n",
       " 'specific',\n",
       " 'idea',\n",
       " 'previous',\n",
       " 'benefit',\n",
       " 'accomplish',\n",
       " 'conduct',\n",
       " '25',\n",
       " 'overall',\n",
       " 'gain',\n",
       " 'relatively',\n",
       " 'dynamic',\n",
       " 'multidimensional',\n",
       " 'particle',\n",
       " 'swarm',\n",
       " 'centroid',\n",
       " 'svr',\n",
       " 'vapnik\\\\xe2\\\\x80\\\\x99s',\n",
       " 'variant',\n",
       " '\\\\\\\\ell',\n",
       " '_{1}',\n",
       " 'norm',\n",
       " 'useful',\n",
       " 'redundant',\n",
       " 'cod',\n",
       " 'sc',\n",
       " 'available',\n",
       " 'brief',\n",
       " 'connection',\n",
       " 'typical',\n",
       " 'newton',\n",
       " 'program',\n",
       " 'pursuit',\n",
       " 'magnitude',\n",
       " 'checkerboard',\n",
       " 'detection',\n",
       " 'detect',\n",
       " 'pose',\n",
       " 'distort',\n",
       " 'lens',\n",
       " 'resolution',\n",
       " 'surface',\n",
       " 'subpixel',\n",
       " 'refinement',\n",
       " 'tailor',\n",
       " 'x',\n",
       " 'junction',\n",
       " 'detector',\n",
       " 'setup',\n",
       " 'capture',\n",
       " 'applicability',\n",
       " 'quantitative',\n",
       " 'opencv\\\\xe2\\\\x80\\\\x99s',\n",
       " '80%',\n",
       " 'corner',\n",
       " 'accurately',\n",
       " 'perspective',\n",
       " 'baseline',\n",
       " 'stereo',\n",
       " 'shadow',\n",
       " 'stationary',\n",
       " 'scene',\n",
       " 'photograph',\n",
       " 'sufficient',\n",
       " 'calibrate',\n",
       " 'where',\n",
       " 'geo',\n",
       " 'longitude',\n",
       " 'ambiguity',\n",
       " 'date',\n",
       " 'acquisition',\n",
       " 'gps',\n",
       " 'instrument',\n",
       " '\"geo',\n",
       " 'temporal',\n",
       " 'localization\"',\n",
       " 'additional',\n",
       " 'knowledge',\n",
       " 'picture',\n",
       " 'recover',\n",
       " 'directly',\n",
       " 'localization',\n",
       " 'localisation',\n",
       " 'subregion',\n",
       " 'individually',\n",
       " 'identifiable',\n",
       " 'cross',\n",
       " 'ratio',\n",
       " 'aim',\n",
       " 'minimise',\n",
       " 'misidentify',\n",
       " 'key',\n",
       " 'ability',\n",
       " 'constraint',\n",
       " 'element',\n",
       " 'constitute',\n",
       " 'flexibility',\n",
       " 'precision',\n",
       " 'consumer',\n",
       " 'grade',\n",
       " 'depth',\n",
       " 'jointly',\n",
       " 'color',\n",
       " 'joint',\n",
       " 'undesired',\n",
       " 'interaction',\n",
       " 'intrinsic',\n",
       " 'merely',\n",
       " 'rig',\n",
       " 'checker',\n",
       " 'board',\n",
       " 'replace',\n",
       " 'cuboid',\n",
       " 'height',\n",
       " 'angle',\n",
       " 'neighbor',\n",
       " 'robustly',\n",
       " 'experimentally',\n",
       " 'cubic',\n",
       " 'empirically',\n",
       " 'state',\n",
       " 'of',\n",
       " 'art',\n",
       " 'commodity',\n",
       " 'applicable',\n",
       " 'scenario',\n",
       " 'etc',\n",
       " 'gait',\n",
       " 'piecewise',\n",
       " 'body',\n",
       " 'extract',\n",
       " 'video',\n",
       " 'sequence',\n",
       " 'rectify',\n",
       " 'appear',\n",
       " 'fronto',\n",
       " 'parallel',\n",
       " 'characteristic',\n",
       " 'compute',\n",
       " 'half',\n",
       " 'cycle',\n",
       " 'walk',\n",
       " 'direction',\n",
       " 'decouple',\n",
       " 'distract',\n",
       " 'factor',\n",
       " 'contrast',\n",
       " 'suit',\n",
       " 'clinical',\n",
       " 'surveillance',\n",
       " 'simulate',\n",
       " 'indoor',\n",
       " 'validate',\n",
       " 'chessboard',\n",
       " 'fundamental',\n",
       " 'textural',\n",
       " 'geometrical',\n",
       " 'consideration',\n",
       " 'employ',\n",
       " 'eliminate',\n",
       " 'fake',\n",
       " 'user',\n",
       " 'total',\n",
       " 'adaptively',\n",
       " 'public',\n",
       " 'opencv',\n",
       " 'geometric',\n",
       " 'thermal',\n",
       " 'infrared',\n",
       " 'ir',\n",
       " 'vital',\n",
       " 'importance',\n",
       " 'consist',\n",
       " 'localize',\n",
       " 'subsequently',\n",
       " 'physical',\n",
       " 'limitation',\n",
       " 'difficulty',\n",
       " 'unsatisfying',\n",
       " 'miniature',\n",
       " 'bulb',\n",
       " 'radiation',\n",
       " 'ellipse',\n",
       " 'mass',\n",
       " 'ellipsoidal',\n",
       " 'start',\n",
       " 'refine',\n",
       " 'iteratively',\n",
       " 'alternate',\n",
       " 'undistorted',\n",
       " 'grid',\n",
       " 'chain',\n",
       " 'visible',\n",
       " 'suitable',\n",
       " 'multiple',\n",
       " 'involve',\n",
       " 'field',\n",
       " 'analytical',\n",
       " 'researcher',\n",
       " 'digital',\n",
       " 'shelf',\n",
       " 'favor',\n",
       " 'rely',\n",
       " 'specialize',\n",
       " 'optical',\n",
       " 'equipment',\n",
       " 'hardware',\n",
       " 'priori',\n",
       " '3',\n",
       " 'd',\n",
       " 'planar',\n",
       " '2',\n",
       " 'offer',\n",
       " 'range',\n",
       " 'reconstruct',\n",
       " 'counterpart',\n",
       " '\\\\xe2\\\\x80\\\\x9cdistortion',\n",
       " 'free\\\\xe2\\\\x80\\\\x9d',\n",
       " 'incorporation',\n",
       " 'exact',\n",
       " 'addition',\n",
       " 'express',\n",
       " 'unit',\n",
       " 'quaternion',\n",
       " 'minimally',\n",
       " 'equation',\n",
       " 'free',\n",
       " 'extensive',\n",
       " 'benchmarking',\n",
       " 'optic',\n",
       " 'comprehensive',\n",
       " 'tangential',\n",
       " 'circle',\n",
       " 'ring',\n",
       " 'utilize',\n",
       " 'initialization',\n",
       " 'undistortion',\n",
       " 'unprojection',\n",
       " 'canonical',\n",
       " 'plane',\n",
       " 'recompute',\n",
       " 'undistorting',\n",
       " 'unprojecting',\n",
       " 'reprojection',\n",
       " '50%',\n",
       " 'toolbox',\n",
       " 'recovery',\n",
       " 'visual',\n",
       " 'hull',\n",
       " 'reconstruction',\n",
       " 'epipolar',\n",
       " 'geometry',\n",
       " 'pixelsu0027',\n",
       " 'ray',\n",
       " 'common',\n",
       " 'enable',\n",
       " 'travel',\n",
       " 'non',\n",
       " 'central',\n",
       " 'catadioptric',\n",
       " 'auto',\n",
       " 'polarization',\n",
       " 'specular',\n",
       " 'catacaustics',\n",
       " 'geometrically',\n",
       " 'catacaustic',\n",
       " 'locus',\n",
       " 'viewpoint',\n",
       " 'caustic',\n",
       " 'unique',\n",
       " 'help',\n",
       " 'widen',\n",
       " 'characterize',\n",
       " 'occlusion',\n",
       " 'complex',\n",
       " 'reflection',\n",
       " 'property',\n",
       " 'raise',\n",
       " 'huge',\n",
       " 'attempt',\n",
       " 'mainly',\n",
       " 'rough',\n",
       " 'correct',\n",
       " 'patch',\n",
       " 'disparity',\n",
       " 'projection',\n",
       " 'call',\n",
       " 'from',\n",
       " 'contour',\n",
       " 'discrepancy',\n",
       " 'segment',\n",
       " 'segmentation',\n",
       " 'highlightsmultiple',\n",
       " 'display',\n",
       " 'unconsistencies',\n",
       " 'focus',\n",
       " 'dimensional',\n",
       " '1d',\n",
       " 'objects:',\n",
       " 'a',\n",
       " 'motion',\n",
       " 'b',\n",
       " 'firstly',\n",
       " ...]"
      ]
     },
     "execution_count": 205,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "voc."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 191,
   "metadata": {
    "id": "DesyOWhh86uv"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "word2vec trained in 0 sec\n"
     ]
    }
   ],
   "source": [
    "#apply wv to abstracts\n",
    "vector_size = 192\n",
    "\n",
    "wv_model = train_wv_on_vocab (voc, vector_size=vector_size)\n",
    "#embedded_abstracts = list_words_to_one_sentence_wv_vector(voc.sentences_list_words, wv_model)\n",
    "#embedded_abstracts = np.array(list(embedded_abstracts.values()))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 202,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyError",
     "evalue": "\"Key 'the' not present\"",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[202], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[43mwv_model\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mwv\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mthe\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m]\u001b[49m\n",
      "File \u001b[0;32m~/opt/anaconda3/lib/python3.8/site-packages/gensim/models/keyedvectors.py:395\u001b[0m, in \u001b[0;36mKeyedVectors.__getitem__\u001b[0;34m(self, key_or_keys)\u001b[0m\n\u001b[1;32m    381\u001b[0m \u001b[38;5;124;03m\"\"\"Get vector representation of `key_or_keys`.\u001b[39;00m\n\u001b[1;32m    382\u001b[0m \n\u001b[1;32m    383\u001b[0m \u001b[38;5;124;03mParameters\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    392\u001b[0m \n\u001b[1;32m    393\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m    394\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(key_or_keys, _KEY_TYPES):\n\u001b[0;32m--> 395\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget_vector\u001b[49m\u001b[43m(\u001b[49m\u001b[43mkey_or_keys\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    397\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m vstack([\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mget_vector(key) \u001b[38;5;28;01mfor\u001b[39;00m key \u001b[38;5;129;01min\u001b[39;00m key_or_keys])\n",
      "File \u001b[0;32m~/opt/anaconda3/lib/python3.8/site-packages/gensim/models/keyedvectors.py:438\u001b[0m, in \u001b[0;36mKeyedVectors.get_vector\u001b[0;34m(self, key, norm)\u001b[0m\n\u001b[1;32m    414\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mget_vector\u001b[39m(\u001b[38;5;28mself\u001b[39m, key, norm\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m):\n\u001b[1;32m    415\u001b[0m     \u001b[38;5;124;03m\"\"\"Get the key's vector, as a 1D numpy array.\u001b[39;00m\n\u001b[1;32m    416\u001b[0m \n\u001b[1;32m    417\u001b[0m \u001b[38;5;124;03m    Parameters\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    436\u001b[0m \n\u001b[1;32m    437\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[0;32m--> 438\u001b[0m     index \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget_index\u001b[49m\u001b[43m(\u001b[49m\u001b[43mkey\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    439\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m norm:\n\u001b[1;32m    440\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mfill_norms()\n",
      "File \u001b[0;32m~/opt/anaconda3/lib/python3.8/site-packages/gensim/models/keyedvectors.py:412\u001b[0m, in \u001b[0;36mKeyedVectors.get_index\u001b[0;34m(self, key, default)\u001b[0m\n\u001b[1;32m    410\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m default\n\u001b[1;32m    411\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m--> 412\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mKeyError\u001b[39;00m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mKey \u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mkey\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m not present\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "\u001b[0;31mKeyError\u001b[0m: \"Key 'the' not present\""
     ]
    }
   ],
   "source": [
    "wv_model.wv['the']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "id": "iA80kLyFBO8l"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "downloading word2vec google news 300...\n",
      "Model downloaded in 1 min\n"
     ]
    }
   ],
   "source": [
    "##### NEW with GOOG vocab --> to test\n",
    "import gensim.downloader as api\n",
    "print('downloading word2vec google news 300...')\n",
    "t = time()\n",
    "wv_model = api.load('word2vec-google-news-300')\n",
    "print('Model downloaded in {} min'.format(round((time()-t)/60)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "id": "EFN6fF-Nstmm"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "embedded abstracts npy saved in file\n"
     ]
    }
   ],
   "source": [
    "np.save('embedded_goog_abstracts_quartiles_array.npy', embedded_abstracts)\n",
    "print('embedded abstracts npy saved in file')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "word2vec model with a vec size = 100 created\n"
     ]
    }
   ],
   "source": [
    "wv_model_local = Word2Vec(sentences=voc.sentences_list_words, vector_size=100, window=5, min_count=1, workers=8)\n",
    "print('word2vec model with a vec size = 100 created')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 208,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "23814"
      ]
     },
     "execution_count": 208,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "voc.word2count['the']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 209,
   "metadata": {},
   "outputs": [
    {
     "ename": "ImportError",
     "evalue": "cannot import name 'words_embeddings_multithread_3' from 'my_functions' (/Users/ghassenabdedayem/Documents/Data/Polytechnique/5- Data Challenge/data_challenge_2022/my_functions.py)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mImportError\u001b[0m                               Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[209], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mmy_functions\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m words_embeddings_multithread_3\n\u001b[1;32m      2\u001b[0m list_embeddings \u001b[38;5;241m=\u001b[39m words_embeddings_multithread(wv_model_local\u001b[38;5;241m.\u001b[39mwv, voc\u001b[38;5;241m.\u001b[39msentences_list_words)\n",
      "\u001b[0;31mImportError\u001b[0m: cannot import name 'words_embeddings_multithread_3' from 'my_functions' (/Users/ghassenabdedayem/Documents/Data/Polytechnique/5- Data Challenge/data_challenge_2022/my_functions.py)"
     ]
    }
   ],
   "source": [
    "from my_functions import words_embeddings_multithread_3\n",
    "list_embeddings = words_embeddings_multithread(wv_model_local.wv, voc.sentences_list_words)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(103, 300)"
      ]
     },
     "execution_count": 103,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "list_embeddings[2].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "abstracts words embeddings npy saved in file\n"
     ]
    }
   ],
   "source": [
    "np.save('embedded_goog_abstracts_array.npy', list_embeddings)\n",
    "print('abstracts words embeddings npy saved in file')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 2.16064453e-02,  2.17285156e-02,  5.02929688e-02,  3.37890625e-01,\n",
       "        3.58886719e-02, -3.56445312e-02,  1.25976562e-01, -1.51367188e-01,\n",
       "        3.07617188e-02,  1.20239258e-02, -1.68945312e-01, -2.83203125e-01,\n",
       "       -1.60156250e-01, -2.46093750e-01, -2.50000000e-01,  2.94921875e-01,\n",
       "        1.31835938e-01, -1.39160156e-02,  1.67968750e-01, -2.92968750e-01,\n",
       "       -1.50756836e-02,  9.66796875e-02,  2.53906250e-01, -3.17382812e-02,\n",
       "        1.26953125e-01,  6.93359375e-02, -6.68945312e-02,  1.06933594e-01,\n",
       "       -9.42382812e-02, -5.46875000e-02,  3.29589844e-02,  2.17773438e-01,\n",
       "       -1.04980469e-01,  1.62109375e-01,  3.22265625e-02,  6.83593750e-02,\n",
       "        2.44140625e-01,  1.61132812e-01,  2.04101562e-01,  3.37890625e-01,\n",
       "        7.71484375e-02, -2.04101562e-01,  4.76562500e-01,  4.54711914e-03,\n",
       "        3.17382812e-02,  6.29882812e-02, -4.32128906e-02, -4.37011719e-02,\n",
       "        1.10839844e-01,  1.02233887e-03, -1.99218750e-01,  1.09375000e-01,\n",
       "        2.91748047e-02,  1.21582031e-01,  1.42578125e-01,  6.39648438e-02,\n",
       "        1.13677979e-03, -4.68750000e-02,  6.68945312e-02, -6.64062500e-02,\n",
       "        2.35595703e-02,  1.53320312e-01, -5.64575195e-03, -9.42382812e-02,\n",
       "        4.22363281e-02, -3.82812500e-01, -1.90429688e-01,  2.78320312e-02,\n",
       "       -1.25976562e-01,  1.07910156e-01,  1.97265625e-01,  3.30078125e-01,\n",
       "       -2.19726562e-02,  8.25195312e-02, -3.69140625e-01, -3.11279297e-02,\n",
       "        4.22363281e-02,  1.13281250e-01, -8.42285156e-03,  2.91015625e-01,\n",
       "       -1.33789062e-01, -2.70996094e-02, -1.08886719e-01, -1.15234375e-01,\n",
       "       -3.18359375e-01, -4.51660156e-02,  1.37695312e-01,  3.32031250e-01,\n",
       "        7.51953125e-02, -3.12500000e-02, -8.93554688e-02,  2.36328125e-01,\n",
       "       -1.48437500e-01, -9.47265625e-02, -8.34960938e-02,  1.04980469e-01,\n",
       "        1.69921875e-01,  2.26562500e-01, -7.93457031e-04, -5.49316406e-02,\n",
       "       -2.59765625e-01,  4.63867188e-03,  1.13281250e-01,  6.62231445e-03,\n",
       "        1.15966797e-03, -1.68457031e-02, -1.48437500e-01,  2.22656250e-01,\n",
       "        6.07910156e-02, -5.37109375e-03, -2.23632812e-01,  4.93164062e-02,\n",
       "       -3.10058594e-02,  2.86865234e-02,  1.33789062e-01,  5.88378906e-02,\n",
       "        1.05468750e-01, -9.17968750e-02,  2.91748047e-02, -6.73828125e-02,\n",
       "       -8.78906250e-02, -5.03540039e-03, -1.43554688e-01,  1.93359375e-01,\n",
       "        2.59765625e-01, -6.49414062e-02, -2.57812500e-01,  7.56835938e-02,\n",
       "        8.05664062e-03, -9.37500000e-02, -2.08984375e-01, -1.89453125e-01,\n",
       "       -3.22265625e-02,  2.17285156e-02, -1.15234375e-01, -4.90722656e-02,\n",
       "       -7.87353516e-03,  9.71679688e-02, -1.12792969e-01,  5.32226562e-02,\n",
       "        2.55859375e-01, -1.84570312e-01,  2.53906250e-01, -2.69775391e-02,\n",
       "        5.41992188e-02, -6.25000000e-02, -2.21679688e-01, -2.31445312e-01,\n",
       "        7.81250000e-02, -1.26953125e-01,  3.36914062e-02,  5.17578125e-02,\n",
       "       -3.30078125e-01, -7.22656250e-02, -1.03027344e-01,  5.10253906e-02,\n",
       "        1.64794922e-02,  1.72851562e-01, -2.53906250e-01, -3.36914062e-02,\n",
       "        1.61132812e-02,  3.05175781e-02, -9.21630859e-03,  8.25195312e-02,\n",
       "        1.08886719e-01, -2.48046875e-01,  9.66796875e-02,  8.85009766e-03,\n",
       "       -1.24511719e-01,  1.07421875e-02, -1.48437500e-01,  1.35742188e-01,\n",
       "        1.97265625e-01,  1.69921875e-01, -1.36718750e-01,  1.59179688e-01,\n",
       "        1.02539062e-01, -1.75781250e-01,  7.37304688e-02,  7.03125000e-02,\n",
       "        8.11767578e-03, -1.22070312e-01,  2.40234375e-01,  1.44531250e-01,\n",
       "       -1.93359375e-01,  4.39453125e-02, -9.22851562e-02, -4.71191406e-02,\n",
       "       -1.21582031e-01,  6.22558594e-03,  1.73828125e-01,  1.06445312e-01,\n",
       "       -1.77001953e-02, -2.49023438e-02,  6.12792969e-02, -6.50024414e-03,\n",
       "       -1.36718750e-01,  2.77099609e-02, -6.00585938e-02, -5.22460938e-02,\n",
       "       -2.96630859e-02,  6.44531250e-02, -2.24609375e-02,  1.62109375e-01,\n",
       "       -1.45721436e-03, -4.54101562e-02, -1.34765625e-01, -8.54492188e-02,\n",
       "       -1.87500000e-01,  9.96093750e-02, -1.19018555e-02,  2.37304688e-01,\n",
       "       -1.42578125e-01, -8.93554688e-02, -2.94189453e-02, -1.90429688e-02,\n",
       "        2.19726562e-01, -7.08007812e-02, -1.43554688e-01,  7.81250000e-02,\n",
       "       -2.25585938e-01,  1.14257812e-01,  3.90625000e-02,  7.66601562e-02,\n",
       "        1.37695312e-01, -9.96093750e-02, -1.51824951e-03,  1.12304688e-01,\n",
       "       -2.59765625e-01, -1.17675781e-01,  2.55126953e-02, -5.73730469e-02,\n",
       "       -4.29687500e-02, -1.68609619e-03,  1.66015625e-01,  2.03125000e-01,\n",
       "        3.71093750e-02, -1.79443359e-02,  3.30078125e-01,  1.02050781e-01,\n",
       "        1.47460938e-01,  1.82617188e-01,  4.17480469e-02, -8.54492188e-02,\n",
       "       -2.85156250e-01,  9.03320312e-02,  1.50146484e-02,  2.23632812e-01,\n",
       "       -8.93554688e-02, -1.40625000e-01, -2.27050781e-02,  1.90429688e-01,\n",
       "        6.49414062e-02,  1.79687500e-01,  1.56250000e-01,  2.15148926e-03,\n",
       "        7.86132812e-02, -1.92871094e-02,  3.93066406e-02, -2.02148438e-01,\n",
       "       -8.49609375e-02, -1.33789062e-01, -4.58984375e-02, -6.98242188e-02,\n",
       "       -4.27246094e-02, -6.52313232e-04, -2.07031250e-01, -9.96093750e-02,\n",
       "       -8.10546875e-02, -2.57873535e-03, -1.87500000e-01,  1.37695312e-01,\n",
       "        2.25585938e-01, -9.82666016e-03,  6.64062500e-02, -2.24609375e-01,\n",
       "       -1.67968750e-01, -1.79687500e-01, -2.28515625e-01,  7.03125000e-02,\n",
       "        2.60009766e-02, -2.10937500e-01, -6.68945312e-02,  1.05468750e-01,\n",
       "       -1.13281250e-01, -1.25000000e-01, -2.50244141e-02, -2.24609375e-01,\n",
       "       -9.61914062e-02, -6.39648438e-02,  1.43554688e-01,  1.34765625e-01,\n",
       "       -9.42382812e-02, -4.63867188e-03, -3.44238281e-02, -1.45507812e-01,\n",
       "       -3.85742188e-02, -2.46093750e-01, -4.05883789e-03,  4.46319580e-04],\n",
       "      dtype=float32)"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "wv_model['hey']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "id": "n5RJqWqu8nz1"
   },
   "outputs": [],
   "source": [
    "# HERE WE CONCATENATE THE WALKS FEATURES AND THE ABSTRACTS FEATURES\n",
    "features_np = np.concatenate((walks_wv, embedded_abstracts), axis=1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "id": "mCXRY-SPyJn6"
   },
   "outputs": [],
   "source": [
    "def random_subset_with_mc_sampling(lst, ratio):\n",
    "    weights = np.ones(np.shape(lst)[1]) / np.shape(lst)[1]  # Uniform distribution\n",
    "    indices = np.random.choice(np.shape(lst)[1], size=round(ratio*np.shape(lst)[1]), replace=False, p=weights)\n",
    "    return lst[:, indices]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "id": "CHyXpfe_SVEb"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Finished sampling and authors added to pairs in 51 sec\n"
     ]
    }
   ],
   "source": [
    "t = time()\n",
    "#indices_mc = random_subset_with_mc_sampling(indices, ratio = 0.3)\n",
    "indices_mc = indices # without mc sampling\n",
    "indices_mc = add_authors_to_pairs(indices_mc, authors)\n",
    "\n",
    "#### we put this part inside the training to avoid overfitting\n",
    "# rand_indices = np.random.randint(0, len(indices_mc), size=(indices_mc.shape[0], indices_mc.shape[1]))\n",
    "# rand_indices = add_authors_to_pairs(rand_indices, authors)\n",
    "\n",
    "# pairs = np.concatenate((indices_mc, rand_indices), axis=1)\n",
    "\n",
    "val_indices = add_authors_to_pairs(val_indices, authors)\n",
    "print ('Finished sampling and authors added to pairs in {:.0f} sec'.format(time()-t))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "k-k313Z82z4w"
   },
   "source": [
    "# Transform variable into tensors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "id": "ht8fo8cK2fzU"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "node features shape: (138499, 1264)\n",
      "adj converted into a sparce torch tensor in 52 sec\n"
     ]
    }
   ],
   "source": [
    "### as we removed the creation of rand indices, we keep only indices_mc (positive edges)\n",
    "#pairs_torch = torch.LongTensor(pairs).to(device)\n",
    "#indices_mc_torch = torch.LongTensor(indices_mc).to(device)\n",
    "val_indices_torch = torch.LongTensor(val_indices).to(device)\n",
    "y_val_torch = torch.LongTensor(y_val).to(device)\n",
    "\n",
    "# Create class labels\n",
    "y = np.zeros(2*indices_mc.shape[1])\n",
    "y[:indices_mc.shape[1]] = 1 # Concatenated ones for edges indices and later in the model we add zeros for random indices.\n",
    "y = torch.LongTensor(y).to(device)\n",
    "\n",
    "features_torch = torch.FloatTensor(features_np).to(device)\n",
    "print('node features shape:', features_np.shape)\n",
    "\n",
    "adj_torch = sparse_mx_to_torch_sparse_tensor(adj).to(device)\n",
    "print('adj converted into a sparce torch tensor in {:.0f} sec'.format(time()-t))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "gpFQg_jBsGoM"
   },
   "source": [
    "# Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "id": "ROBXxQaZnfQ3"
   },
   "outputs": [],
   "source": [
    "class GNN(nn.Module):\n",
    "    def __init__(self, n_feat, wv_walk_size, n_hidden, n_class, sub_class, dropout):\n",
    "        super(GNN, self).__init__()\n",
    "        # self.fc_in = nn.Linear()\n",
    "        self.fc1 = nn.Linear(n_feat, n_hidden)\n",
    "        self.fc2 = nn.Linear(n_hidden, n_hidden)\n",
    "        self.fc3 = nn.Linear(n_hidden, n_hidden)\n",
    "        self.double_fc3 = nn.Linear((2*n_hidden+wv_walk_size), n_hidden)\n",
    "        self.double_fc3 = nn.Linear((2*n_hidden), n_hidden)\n",
    "        self.fc4 = nn.Linear(n_hidden, sub_class)\n",
    "        self.fc5 = nn.Linear(sub_class, n_class)        \n",
    "        self.dropout = nn.Dropout(dropout)\n",
    "        self.relu = nn.ReLU()\n",
    "        \n",
    "        \n",
    "\n",
    "    def forward(self, x_in, adj, pairs, wv_walk_size):       \n",
    "        \n",
    "        h1 = self.fc1(x_in)\n",
    "        h1 = self.relu(h1)\n",
    "        h1 = self.dropout(h1)\n",
    "\n",
    "        #h1 = self.fc2(h1)\n",
    "        z1 = torch.mm(adj, h1)\n",
    "        del(h1)\n",
    "        z1 = self.relu(z1)\n",
    "        z1 = self.dropout(z1)\n",
    "        \n",
    "\n",
    "        h2 = self.fc2(z1)\n",
    "        del(z1)\n",
    "        z2 = torch.mm(adj, h2)\n",
    "        del(h2, adj)\n",
    "        z2 = self.relu(z2)\n",
    "        z2 = self.dropout(z2)\n",
    "        \n",
    "\n",
    "        x = z2[:, :wv_walk_size][pairs[0]] - z2[:, :wv_walk_size][pairs[1]] # embedded features (z2) of node 0 - embedded features of node 1 // x_in[:, :64].shape\n",
    "        #x = torch.ones(size=(pairs.shape[1], wv_walk_size)).to(device)\n",
    "        x = pairs[2][:, None] * x #we multiply by the number of common authors by pairs of nodes (papers) with pairs[3] || or yes/no if at least one same author (pairs[2])\n",
    "        #x = x.to(device)\n",
    "        x1 = z2[pairs[0]]#.to(device)\n",
    "        x2 = z2[pairs[1]]#.to(device)\n",
    "        del(pairs)\n",
    "        #x = torch.cat((x, x1, x2), dim=1)\n",
    "        x = torch.cat((x1, x2), dim=1)\n",
    "\n",
    "        #print(np.shape(x1), np.shape(x2))\n",
    "        del(x1, x2)\n",
    "        \n",
    "        #print(x.shape)\n",
    "        x = self.relu(self.double_fc3(x))        \n",
    "        x = self.dropout(x)\n",
    "        \n",
    "        x = self.relu(self.fc4(x))\n",
    "        x = self.dropout(x)\n",
    "        \n",
    "        x = self.fc5(x)\n",
    "        x = self.relu(x)\n",
    "        x = self.dropout(x)\n",
    "\n",
    "        return F.log_softmax(x, dim=1)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "id": "bnRNz5z4nh6x"
   },
   "outputs": [],
   "source": [
    "def early_stopping(loss_train, list_loss_train, loss_val, list_loss_val, \n",
    "                   tolerance=0.01, patience=15):\n",
    "    list_loss_val = list(list_loss_val)[-patience:]\n",
    "    list_loss_train = list(list_loss_train)[-patience:]\n",
    "    if (len(list_loss_val) == patience and loss_val > (sum(list_loss_val)/len(list_loss_val)) and loss_train + tolerance < loss_val) or (len(list_loss_train) == patience and loss_train > (sum(list_loss_train)/len(list_loss_train))):\n",
    "        #print('train: {:.5f} val: {:.5f} mean val: {:.5f}'.format(loss_train, loss_val, (sum(list_loss_val)/len(list_loss_val))))\n",
    "        return True\n",
    "    return False\n",
    "    \n",
    "\n",
    "    \n",
    "def train_model(model, learning_rate, features, adj, indices_mc, y, val_indices, \n",
    "                y_val, epochs, batch_size, wv_walk_size, \n",
    "                tolerence = 0.01, patience = 15, run_number=randint(0, 1000)):\n",
    "    # Train model\n",
    "    start_time = time()\n",
    "    print('Initializing the optimizer with learning rate:', learning_rate)\n",
    "    optimizer = optim.Adam(model.parameters(), lr=learning_rate) #optimizer with halving learning rate in training\n",
    "    try: os.mkdir('./outputs')\n",
    "    except: pass\n",
    "    print('Preparing the data for training...')        \n",
    "\n",
    "    today = datetime.today().strftime('%Y-%m-%d-%H:%M')\n",
    "    list_loss_val = []\n",
    "    list_loss_train = []\n",
    "\n",
    "    \n",
    "    halving_lr = 0 # counter of the number of halving lr\n",
    "    print('Start training...')\n",
    "    for epoch in range(epochs):\n",
    "        t = time()\n",
    "\n",
    "        # we create the rand indices corresponding to non edges (their y = 0)\n",
    "        rand_indices = np.random.randint(0, len(indices_mc), size=(indices_mc.shape[0], indices_mc.shape[1]))\n",
    "        rand_indices = add_authors_to_pairs(rand_indices, authors)        \n",
    "        pairs = np.concatenate((indices_mc, rand_indices), axis=1)\n",
    "        pairs = torch.LongTensor(pairs).to(device)\n",
    "\n",
    "        permutation = torch.randperm(pairs.size()[1])\n",
    "\n",
    "        for i in range(0, pairs.size()[1], batch_size):\n",
    "            optimizer.zero_grad()\n",
    "\n",
    "            elts_indices = permutation[i:i+batch_size]\n",
    "            batch_pairs = pairs[:, elts_indices]\n",
    "            batch_y = y[elts_indices]\n",
    "\n",
    "        \n",
    "            model.train()\n",
    "\n",
    "            output = model(features, adj, batch_pairs, wv_walk_size).to(device) # we run the model that gives the output.\n",
    "            loss_train = F.nll_loss(output, batch_y) # we are using nll_loss as loss to optimize, we store it in loss_train. We compare to y which is stable and contains the tag ones and zeros.\n",
    "            acc_train = accuracy_score(torch.argmax(output, dim=1).detach().cpu().numpy(), batch_y.cpu().numpy())# just to show it in the out put message of the training\n",
    "            loss_train.backward() # The back propagation ? --> Computes the gradient of current tensor w.r.t. graph leaves\n",
    "            optimizer.step() # Performs a single optimization step (parameter update).\n",
    "        \n",
    "        model.eval()\n",
    "        output = model(features, adj, val_indices, wv_walk_size).to(device)\n",
    "        #y_val = torch.LongTensor(y_val).to(device)\n",
    "        loss_val = F.nll_loss(output, y_val)\n",
    "        list_loss_val.append(loss_val.item())\n",
    "        list_loss_train.append(loss_train.item())\n",
    "        acc_val = accuracy_score(torch.argmax(output, dim=1).detach().cpu().numpy(), y_val.cpu().numpy())\n",
    "        \n",
    "        if epoch % 5 == 0:\n",
    "            print('Epoch: {:03d}'.format(epoch+1),\n",
    "                  'loss_train: {:.4f}'.format(loss_train.item()),\n",
    "                  'loss_val: {:.4f}'.format(loss_val.item()),\n",
    "                  'acc_train: {:.4f}'.format(acc_train.item()),\n",
    "                  'acc_val: {:.4f}'.format(acc_val.item()),\n",
    "                  'time: {} s'.format(int(round(time()) - round(t))),\n",
    "                 'total_time: {} min'.format(round((time() - start_time)/60)))\n",
    "        if epoch % 20 == 0:\n",
    "            model_path = \"outputs/{}-model-{}epochs-{}.pt\".format(today, epoch, run_number)\n",
    "            torch.save(model.state_dict(), model_path)\n",
    "        \n",
    "        if int(loss_val.item()) > 5:\n",
    "            break\n",
    "            \n",
    "        # early = early_stopping(loss_train.item(), list_loss_train, loss_val.item(), list_loss_val, patience=15)        \n",
    "        # if early:\n",
    "        #     halving_lr += 1\n",
    "        #     if halving_lr > 5:\n",
    "        #         break\n",
    "        #     list_loss_val=[]\n",
    "        #     learning_rate = learning_rate/10\n",
    "        #     optimizer = optim.Adam(model.parameters(), lr=learning_rate)\n",
    "        #     print('Deviding the learning rate by 2. New learning rate: {:.6f}'.format(learning_rate))\n",
    "\n",
    "\n",
    "\n",
    "    print(\"Optimization Finished in {} min!\".format(round((time() - start_time)/60)))\n",
    "    return model\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "StYPzRnT2fzV"
   },
   "source": [
    "# Train the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "id": "xhC2OuMhBMKD"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(64, 1264)"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "wv_vector_size, features_torch.shape[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "id": "UiGcIYWvmXA9"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[     0,      0,      0, ..., 138497, 138498, 138498],\n",
       "       [     2,      1,      0, ..., 138496, 138498, 136589],\n",
       "       [     0,      1,      1, ...,      0,      1,      0],\n",
       "       [     0,      1,      4, ...,      0,      3,      0]])"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "add_authors_to_pairs(indices, authors)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "id": "7i8UpGHuNhQp"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Initializing the optimizer with learning rate: 0.01\n",
      "Preparing the data for training...\n",
      "Start training...\n",
      "Epoch: 001 loss_train: 0.4644 loss_val: 0.6942 acc_train: 0.4967 acc_val: 0.5000 time: 5884 s total_time: 98 min\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[23], line 18\u001b[0m\n\u001b[1;32m     16\u001b[0m \u001b[38;5;66;03m# Creates the model\u001b[39;00m\n\u001b[1;32m     17\u001b[0m model \u001b[38;5;241m=\u001b[39m GNN(n_features, wv_walk_size, n_hidden, n_class, sub_class, dropout_rate)\u001b[38;5;241m.\u001b[39mto(device)\n\u001b[0;32m---> 18\u001b[0m trained_model \u001b[38;5;241m=\u001b[39m \u001b[43mtrain_model\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mlearning_rate\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mfeatures_torch\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43madj_torch\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mindices_mc\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\n\u001b[1;32m     19\u001b[0m \u001b[43m                            \u001b[49m\u001b[43mval_indices_torch\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my_val_torch\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mepochs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mbatch_size\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mwv_walk_size\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\n\u001b[1;32m     20\u001b[0m \u001b[43m                            \u001b[49m\u001b[43mtolerence\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtolerence\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mpatience\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mpatience\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mrun_number\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mrun_number\u001b[49m\u001b[43m)\u001b[49m\n",
      "Cell \u001b[0;32mIn[9], line 54\u001b[0m, in \u001b[0;36mtrain_model\u001b[0;34m(model, learning_rate, features, adj, indices_mc, y, val_indices, y_val, epochs, batch_size, wv_walk_size, tolerence, patience, run_number)\u001b[0m\n\u001b[1;32m     52\u001b[0m     loss_train \u001b[38;5;241m=\u001b[39m F\u001b[38;5;241m.\u001b[39mnll_loss(output, batch_y) \u001b[38;5;66;03m# we are using nll_loss as loss to optimize, we store it in loss_train. We compare to y which is stable and contains the tag ones and zeros.\u001b[39;00m\n\u001b[1;32m     53\u001b[0m     acc_train \u001b[38;5;241m=\u001b[39m accuracy_score(torch\u001b[38;5;241m.\u001b[39margmax(output, dim\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1\u001b[39m)\u001b[38;5;241m.\u001b[39mdetach()\u001b[38;5;241m.\u001b[39mcpu()\u001b[38;5;241m.\u001b[39mnumpy(), batch_y\u001b[38;5;241m.\u001b[39mcpu()\u001b[38;5;241m.\u001b[39mnumpy())\u001b[38;5;66;03m# just to show it in the out put message of the training\u001b[39;00m\n\u001b[0;32m---> 54\u001b[0m     \u001b[43mloss_train\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbackward\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m \u001b[38;5;66;03m# The back propagation ? --> Computes the gradient of current tensor w.r.t. graph leaves\u001b[39;00m\n\u001b[1;32m     55\u001b[0m     optimizer\u001b[38;5;241m.\u001b[39mstep() \u001b[38;5;66;03m# Performs a single optimization step (parameter update).\u001b[39;00m\n\u001b[1;32m     57\u001b[0m model\u001b[38;5;241m.\u001b[39meval()\n",
      "File \u001b[0;32m~/opt/anaconda3/lib/python3.8/site-packages/torch/_tensor.py:487\u001b[0m, in \u001b[0;36mTensor.backward\u001b[0;34m(self, gradient, retain_graph, create_graph, inputs)\u001b[0m\n\u001b[1;32m    477\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m has_torch_function_unary(\u001b[38;5;28mself\u001b[39m):\n\u001b[1;32m    478\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m handle_torch_function(\n\u001b[1;32m    479\u001b[0m         Tensor\u001b[38;5;241m.\u001b[39mbackward,\n\u001b[1;32m    480\u001b[0m         (\u001b[38;5;28mself\u001b[39m,),\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    485\u001b[0m         inputs\u001b[38;5;241m=\u001b[39minputs,\n\u001b[1;32m    486\u001b[0m     )\n\u001b[0;32m--> 487\u001b[0m \u001b[43mtorch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mautograd\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbackward\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    488\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mgradient\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mretain_graph\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcreate_graph\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43minputs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43minputs\u001b[49m\n\u001b[1;32m    489\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/opt/anaconda3/lib/python3.8/site-packages/torch/autograd/__init__.py:197\u001b[0m, in \u001b[0;36mbackward\u001b[0;34m(tensors, grad_tensors, retain_graph, create_graph, grad_variables, inputs)\u001b[0m\n\u001b[1;32m    192\u001b[0m     retain_graph \u001b[38;5;241m=\u001b[39m create_graph\n\u001b[1;32m    194\u001b[0m \u001b[38;5;66;03m# The reason we repeat same the comment below is that\u001b[39;00m\n\u001b[1;32m    195\u001b[0m \u001b[38;5;66;03m# some Python versions print out the first line of a multi-line function\u001b[39;00m\n\u001b[1;32m    196\u001b[0m \u001b[38;5;66;03m# calls in the traceback and some print out the last line\u001b[39;00m\n\u001b[0;32m--> 197\u001b[0m \u001b[43mVariable\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_execution_engine\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrun_backward\u001b[49m\u001b[43m(\u001b[49m\u001b[43m  \u001b[49m\u001b[38;5;66;43;03m# Calls into the C++ engine to run the backward pass\u001b[39;49;00m\n\u001b[1;32m    198\u001b[0m \u001b[43m    \u001b[49m\u001b[43mtensors\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mgrad_tensors_\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mretain_graph\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcreate_graph\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43minputs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    199\u001b[0m \u001b[43m    \u001b[49m\u001b[43mallow_unreachable\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43maccumulate_grad\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m)\u001b[49m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "\n",
    "torch.cuda.empty_cache()\n",
    "\n",
    "wv_walk_size = wv_vector_size\n",
    "n_hidden = 128\n",
    "dropout_rate = 0.3\n",
    "sub_class = 20\n",
    "n_class = 2\n",
    "n_features = features_torch.shape[1]\n",
    "epochs = 100\n",
    "run_number = randint(0, 1000)\n",
    "learning_rate = 0.01\n",
    "patience = 30\n",
    "tolerence = 0.1\n",
    "batch_size = 1000\n",
    "\n",
    "# Creates the model\n",
    "model = GNN(n_features, wv_walk_size, n_hidden, n_class, sub_class, dropout_rate).to(device)\n",
    "trained_model = train_model(model, learning_rate, features_torch, adj_torch, indices_mc, y, \n",
    "                            val_indices_torch, y_val_torch, epochs, batch_size, wv_walk_size, \n",
    "                            tolerence=tolerence, patience=patience, run_number=run_number)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "KDQ_DCCJavQZ"
   },
   "outputs": [],
   "source": [
    "break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "WEpkbzgYDswA"
   },
   "outputs": [],
   "source": [
    "rand_indices = torch.randint(0, features.size(0), (indices.size(0),indices.size(1))).to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "V42H3MbEh6Ba"
   },
   "outputs": [],
   "source": [
    "features.size(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "Von8ehIosDPa"
   },
   "outputs": [],
   "source": [
    "features.get_device()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "jZcN9lfNA6ly"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "z5VIVVzmMCaG"
   },
   "outputs": [],
   "source": [
    "del(adj, G, G_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "158xT56h4_QY"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "ZezlQHa24_Xc"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "Zev8mABQ4_fP"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "zoayPq8E5AGd"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "okgeOyoZ5AJu"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "qe1G4eUBQLNM"
   },
   "outputs": [],
   "source": [
    "class CNN(nn.Module):\n",
    "    def __init__(self, vocab_size, filter_sizes, embedding_dim, dropout, n_class=2):\n",
    "        super(CNN, self).__init__()\n",
    "        #self.conv1d = nn.Conv1d(in_channels=vocab_size, out_channels=embedding_dim, kernel_size=3, stride=1, padding=0)\n",
    "        \n",
    "        # self.convs = nn.ModuleList([\n",
    "        #     nn.Conv1d(in_channels=vocab_size, out_channels=embedding_dim, \n",
    "        #               kernel_size=fs, stride=1, padding=0)\n",
    "        #     for fs in filter_sizes\n",
    "        # ])\n",
    "        \n",
    "        self.conv1d = nn.Conv1d(in_channels=vocab_size, out_channels=embedding_dim*4, \n",
    "                      kernel_size=3, stride=1, padding=3)\n",
    "        self.maxpooling = nn.MaxPool1d(kernel_size=5)\n",
    "\n",
    "\n",
    "        self.fc2 = nn.Linear(embedding_dim*4, embedding_dim) \n",
    "        self.fc1 = nn.Linear(embedding_dim*2, n_class)             \n",
    "        self.dropout = nn.Dropout(dropout)\n",
    "        self.relu = nn.ReLU()\n",
    "        self.sigmoid = nn.Sigmoid()\n",
    "        \n",
    "        \n",
    "\n",
    "    def forward(self, features, pairs):\n",
    "        max_filter = max(filter_sizes)\n",
    "        \n",
    "        features = self.dropout(features)\n",
    "        features = features.unsqueeze(2)\n",
    "\n",
    "        features = self.conv1d(features)\n",
    "        features = self.maxpooling(features)\n",
    "        features = self.sigmoid(features)\n",
    "        features = self.dropout(features)        \n",
    "        features = features.view(features.shape[0], -1)\n",
    "        features = features.squeeze(-1)\n",
    "\n",
    "        features = self.fc2(features)\n",
    "        features = self.relu(features)\n",
    "        features = self.dropout(features)\n",
    "\n",
    "        x1 = features[pairs[0]]\n",
    "        x = features[pairs[1]]        \n",
    "        y = torch.cat((x, x1), 1)\n",
    "        del (features, x1)        \n",
    "        \n",
    "        y = self.fc1(y)\n",
    "        y = self.relu(y)\n",
    "        y = self.dropout(y) ### we distinguish x = embedding and y = output \n",
    "        \n",
    "        return F.log_softmax(y, dim=1), x        \n",
    "         \n",
    "\n",
    "\n",
    "        #print(x.shape)\n",
    "        #print(features.shape)\n",
    "\n",
    "\n",
    "        #features = F.pad(features, (1, max_filter+1), 'constant', 0) #(1, 1): pad last dim in a 'constant' mode with the value 0\n",
    "        #features = features.unsqueeze(2)\n",
    "\n",
    "        #features_conv = self.conv1d(features)\n",
    "\n",
    "        # conv_outputs = []\n",
    "        # for conv in self.convs:\n",
    "            \n",
    "        #     features = conv(features)\n",
    "        #     features = nn.functional.max_pool1d(features, kernel_size=features.shape[2])\n",
    "        #     features = nn.functional.relu(features)\n",
    "        #     features = self.dropout(features)\n",
    "        #     conv_outputs.append(features)\n",
    "\n",
    "        # Concatenate and flatten output when filter sizes is longer than one element\n",
    "        #try: features = torch.cat(features, dim=1)\n",
    "        #except: pass\n",
    "        \n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "        \n",
    "        #print(features.shape)\n",
    "     \n",
    "\n",
    "        # x = self.fc2(x)\n",
    "        # x = self.sigmoid(x)\n",
    "        # y = self.dropout(x)       \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "evrXfCMq9MDn"
   },
   "outputs": [],
   "source": [
    "def early_stopping(loss_train, list_loss_train, loss_val, list_loss_val, wait=15, tolerance=0.05):\n",
    "    list_loss_val = list(list_loss_val)[-wait:]\n",
    "    list_loss_train = list(list_loss_train)[-wait:]\n",
    "    if (len(list_loss_val) == wait and loss_val >= (sum(list_loss_val)/len(list_loss_val)) and (loss_train + tolerance) < loss_val):\n",
    "        print('VAL early stop: train = {:.5f} val = {:.5f} mean val = {:.5f}'.format(loss_train, loss_val, (sum(list_loss_val)/len(list_loss_val))))\n",
    "        return True\n",
    "    elif  len(list_loss_train) == wait and loss_train >= (sum(list_loss_train)/len(list_loss_train)):\n",
    "        print('TRAIN early stop: train = {:.5f} val = {:.5f} mean train = {:.5f}'.format(loss_train, loss_val, (sum(list_loss_train)/len(list_loss_train))))\n",
    "        return True\n",
    "    elif (loss_train + tolerance) < loss_val and len(list_loss_val) >= wait:\n",
    "        print('VAL early stop: train = {:.5f} val = {:.5f} mean val = {:.5f}'.format(loss_train, loss_val, (sum(list_loss_val)/len(list_loss_val))))\n",
    "        return True \n",
    "    return False\n",
    "    \n",
    "\n",
    "    \n",
    "def train_NLP_model(model, learning_rate, features, indices, y, val_indices, y_val, epochs, batch_size, run_number):\n",
    "    # Train model\n",
    "    start_time = time()\n",
    "    print('Initializing the optimizer with learning rate:', learning_rate)\n",
    "    optimizer = optim.Adam(model.parameters(), lr=learning_rate) #optimizer with halving learning rate in training\n",
    "    try: os.mkdir('./outputs')\n",
    "    except: pass\n",
    "    print('Preparing the data for training...')\n",
    "    #indices must be a torch tensor to be able to apply size method\n",
    "    rand_indices = torch.randint(0, features.size(0), (indices.size(0),indices.size(1)), device=indices.device)# We take random indices each time we run an epoch\n",
    "    pairs = torch.cat((indices, rand_indices), dim=1).to(device) # Concatenate the edges indices and random indices. \n",
    "    del(indices, rand_indices)\n",
    "\n",
    "    today = datetime.today().strftime('%Y-%m-%d-%H:%M')\n",
    "    list_loss_val = []\n",
    "    list_loss_train = []\n",
    "    \n",
    "    #features = features.to(device)\n",
    "    #pairs = pairs.to(device)\n",
    "    \n",
    "    halving_lr = 0 # counter of the number of halving lr\n",
    "    print('Start training...')\n",
    "    for epoch in range(epochs):\n",
    "        t = time()\n",
    "        \n",
    "        permutation = torch.randperm(pairs.size()[1])\n",
    "\n",
    "        for i in range(0, pairs.size()[1], batch_size):\n",
    "            optimizer.zero_grad()\n",
    "\n",
    "            elts_indices = permutation[i:i+batch_size]\n",
    "            batch_pairs = pairs[:, elts_indices]\n",
    "            batch_y = y[elts_indices]\n",
    "\n",
    "            model.train()\n",
    "\n",
    "            output, embedding = model(features, batch_pairs) # we run the model that gives the output.\n",
    "            loss_train = F.nll_loss(output, batch_y) # we are using nll_loss as loss to optimize, we store it in loss_train. We compare to y which is stable and contains the tag ones and zeros.\n",
    "            acc_train = accuracy_score(torch.argmax(output, dim=1).detach().cpu().numpy(), batch_y.cpu().numpy())# just to show it in the out put message of the training\n",
    "            loss_train.backward() # The back propagation ? --> Computes the gradient of current tensor w.r.t. graph leaves\n",
    "            optimizer.step() # Performs a single optimization step (parameter update).\n",
    "        \n",
    "        model.eval()\n",
    "        output, embedding = model(features, val_indices)\n",
    "        #y_val = torch.LongTensor(y_val).to(device)\n",
    "        loss_val = F.nll_loss(output, y_val)\n",
    "        list_loss_val.append(loss_val.item())\n",
    "        list_loss_train.append(loss_train.item())\n",
    "        acc_val = accuracy_score(torch.argmax(output, dim=1).detach().cpu().numpy(), y_val.cpu().numpy())\n",
    "        \n",
    "        if epoch % 5 == 0:\n",
    "            print('Epoch: {:03d}'.format(epoch+1),\n",
    "                  'loss_train: {:.4f}'.format(loss_train.item()),\n",
    "                  'loss_val: {:.4f}'.format(loss_val.item()),\n",
    "                  'acc_train: {:.4f}'.format(acc_train.item()),\n",
    "                  'acc_val: {:.4f}'.format(acc_val.item()),\n",
    "                  'time: {} s'.format(int(round(time()) - round(t))),\n",
    "                 'total_time: {} min'.format(round((time() - start_time)/60)))\n",
    "        if epoch % 20 == 0:\n",
    "            model_path = \"outputs/{}-model-{}epochs-{}.pt\".format(today, epoch, run_number)\n",
    "            torch.save(model.state_dict(), model_path)\n",
    "            \n",
    "        early = early_stopping(loss_train.item(), list_loss_train, loss_val.item(), list_loss_val, wait=30)        \n",
    "        if early:\n",
    "            halving_lr += 1\n",
    "            if halving_lr > 5:\n",
    "                break\n",
    "            list_loss_val=[]\n",
    "            list_loss_train=[]\n",
    "            learning_rate = learning_rate/10\n",
    "            optimizer = optim.Adam(model.parameters(), lr=learning_rate)\n",
    "            print('Deviding the learning rate by 10. New learning rate: {:.6f}'.format(learning_rate))\n",
    "\n",
    "\n",
    "\n",
    "    print(\"Optimization Finished in {} min!\".format(round((time() - start_time)/60)))\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "9SD5KLOx86u1"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "UH0ytHBhGvAa"
   },
   "outputs": [],
   "source": [
    "torch.cuda.empty_cache()\n",
    "\n",
    "vocab_size = embedded_abstracts.shape[1]\n",
    "learning_rate = 0.1\n",
    "features = embedded_abstracts\n",
    "indices = indices\n",
    "epochs = 400\n",
    "batch_size = 2000 #2000 : 10min\n",
    "filter_sizes = [3]\n",
    "embedding_dim=64\n",
    "dropout = 0.3\n",
    "run_number = 1 #an arbitrary number to identify the run number (not really used)\n",
    "\n",
    "model_NLP = CNN(vocab_size=vocab_size, embedding_dim=embedding_dim, filter_sizes=filter_sizes, dropout=dropout).to(device)\n",
    "train_NLP_model(model_NLP, learning_rate=learning_rate, features=embedded_abstracts, indices=indices, y=y, val_indices=val_indices, y_val=y_val, epochs=epochs, batch_size=batch_size, run_number=run_number)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "rTTCoAFheRZ2"
   },
   "outputs": [],
   "source": [
    "break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "MeDK2NXYDWmG"
   },
   "outputs": [],
   "source": [
    "# Generate tf-idf matrix\n",
    "corpus = [\"This is a sample sentence.\", \"Another sample sentence.\"]\n",
    "vectorizer = TfidfVectorizer()\n",
    "X = vectorizer.fit_transform(corpus)\n",
    "\n",
    "# Convert matrix to PyTorch tensor\n",
    "X = torch.tensor(X.toarray(), dtype=torch.float)\n",
    "print(X.shape)\n",
    "\n",
    "# Define Conv1D layer\n",
    "conv = nn.Conv1d(in_channels=X.shape[1], out_channels=32, kernel_size=1)\n",
    "\n",
    "# Apply Conv1D layer to tensor\n",
    "X = X.unsqueeze(2)\n",
    "print(X.shape)\n",
    "\n",
    "X_conv = conv(X)  # add extra dimension to tensor for batch size\n",
    "\n",
    "# Print output shape\n",
    "print(X_conv.shape) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "g3NB6dirDWmH"
   },
   "outputs": [],
   "source": [
    "#tfidf_reduced[pairs[0][:5]]\n",
    "pairs[:, :5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "ekTGAyTrneWx"
   },
   "outputs": [],
   "source": [
    "features_np = features_abstracts_wv\n",
    "\n",
    "# Create class labels\n",
    "y = np.zeros(2*indices.shape[1])\n",
    "y[:indices.shape[1]] = 1 # Concatenated ones for edges indices and later in the model we add zeros for random indices.\n",
    "\n",
    "# Transforms the numpy matrices/vectors to torch tensors.\n",
    "features = torch.FloatTensor(features_np).to(device)\n",
    "y = torch.LongTensor(y).to(device)\n",
    "if type(adj) != torch.Tensor:\n",
    "    adj = sparse_mx_to_torch_sparse_tensor(adj).to(device)\n",
    "indices = torch.LongTensor(indices).to(device)\n",
    "val_indices = torch.LongTensor(val_indices).to(device)\n",
    "y_val = torch.LongTensor(y_val).to(device)\n",
    "\n",
    "#del (G, G_train, train_edges, val_edges, nodes, abstracts, embedded_mean_abstracts)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "Dmob3xD4pd5R"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "SfvPqy79pGEW"
   },
   "outputs": [],
   "source": [
    "np.transpose(node_pairs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "cmFO4qI7_245"
   },
   "outputs": [],
   "source": [
    "from datetime import datetime\n",
    "\n",
    "test_path = 'https://www.lix.polytechnique.fr/~nikolentzos/files/aai/challenge/test.txt'\n",
    "node_pairs = list()\n",
    "f = urlopen(test_path)\n",
    "\n",
    "for line in f:\n",
    "    t = str(line).split(',')\n",
    "    t[0] = int(re.sub(\"[^0-9]\", \"\", t[0]))\n",
    "    t[1] = int(re.sub(\"[^0-9]\", \"\", t[1]))\n",
    "    node_pairs.append((node_to_idx[int(t[0])], node_to_idx[int(t[1])]))\n",
    "\n",
    "node_pairs = np.transpose(node_pairs)\n",
    "node_pairs = add_authors_to_pairs(node_pairs, authors)\n",
    "node_pairs = torch.LongTensor(node_pairs).to(device)\n",
    "\n",
    "test_output = model(features, adj, node_pairs)\n",
    "y_pred = torch.exp(test_output)\n",
    "y_pred = y_pred.detach().cpu().numpy()\n",
    "\n",
    "y_pred_true = list()\n",
    "for element in y_pred:\n",
    "    y_pred_true.append(element[1])\n",
    "\n",
    "today = datetime.today().strftime('%Y-%m-%d')\n",
    "random_nb = randint(0, 1000)\n",
    "model_nb = 1\n",
    "\n",
    "pd.DataFrame(y_pred_true, columns={'predicted'}).to_csv(\n",
    "\"{}-submission-{}-{}.csv\".format(today, model_nb, random_nb), header=True, index=True, index_label='id'\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "h2UWL4y-K1jd"
   },
   "outputs": [],
   "source": [
    "# Testing\n",
    "model.eval()\n",
    "node_pairs = np.array(np.transpose(node_pairs))\n",
    "node_pairs = torch.LongTensor(node_pairs).to(device)\n",
    "\n",
    "test_output = model(features, adj, node_pairs)\n",
    "y_pred = torch.exp(test_output)\n",
    "y_pred = y_pred.detach().cpu().numpy()\n",
    "\n",
    "y_pred_true = list()\n",
    "for element in y_pred:\n",
    "    y_pred_true.append(element[1])\n",
    "    \n",
    "\n",
    "    \n",
    "today = datetime.today().strftime('%Y-%m-%d')\n",
    "random_nb = randint(0, 1000)\n",
    "\n",
    "pd.DataFrame(y_pred_true, columns={'predicted'}).to_csv(\n",
    "\"{}-submission-{}-{}.csv\".format(today, model_nb, random_nb), header=True, index=True, index_label='id'\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "dwNIJmkGn6-G"
   },
   "outputs": [],
   "source": [
    "epochs = 1000\n",
    "\n",
    "trained_model = train_model(model, 0.01, features, authors, adj, indices, y, torch.tensor(val_indices).to(device), torch.tensor(y_val).to(device), epochs)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "1OSAu20O0zri"
   },
   "outputs": [],
   "source": [
    "print(type(features), type(adj), type(indices), type(y))\n",
    "print(features.get_device(), adj.get_device(), indices.get_device(), y.get_device())\n",
    "\n",
    "#torch.tensor(np.array(authors)).to(device).get_device()\n",
    "authors\n",
    "print(type(torch.tensor(val_indices)))\n",
    "print(torch.tensor(val_indices).to(device).get_device())\n",
    "\n",
    "type(y_val)\n",
    "\n",
    "####### randindicies to check on which device"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "t_5ih-4EQQqW"
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "print (torch.__version__)\n",
    "!pip install torchvision==0.14.0\n",
    "!pip install torchtext==0.14.0\n",
    "!pip install torchaudio==0.13.0\n",
    "!pip install torch==1.13.0\n",
    "import torch\n",
    "print (torch.__version__)"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "machine_shape": "hm",
   "provenance": []
  },
  "gpuClass": "standard",
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
