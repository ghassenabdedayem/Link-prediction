{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "6e7168a0",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from unidecode import unidecode\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "81705174",
   "metadata": {},
   "outputs": [],
   "source": [
    "def text_to_list(text):\n",
    "    return unidecode(text).split(',')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "6e193c56",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>paper_id</th>\n",
       "      <th>1</th>\n",
       "      <th>authors</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>--</td>\n",
       "      <td>[James H. Niblock, Jian-Xun Peng, Karen R. McM...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>--</td>\n",
       "      <td>[Jian-Xun Peng, Kang Li, De-Shuang Huang]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>--</td>\n",
       "      <td>[J. Heikkila]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>--</td>\n",
       "      <td>[L. Teslic, B. Hartmann, O. Nelles, I. Skrjanc]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>--</td>\n",
       "      <td>[Long Zhang, Kang Li, Er-Wei Bai, George W. Ir...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   paper_id   1                                            authors\n",
       "0         0  --  [James H. Niblock, Jian-Xun Peng, Karen R. McM...\n",
       "1         1  --          [Jian-Xun Peng, Kang Li, De-Shuang Huang]\n",
       "2         2  --                                      [J. Heikkila]\n",
       "3         3  --    [L. Teslic, B. Hartmann, O. Nelles, I. Skrjanc]\n",
       "4         4  --  [Long Zhang, Kang Li, Er-Wei Bai, George W. Ir..."
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "authors = pd.read_csv('../input_data/authors.txt', sep = '|', header=None)\n",
    "authors = authors.rename(columns={0: \"paper_id\", 2: \"authors\"})\n",
    "authors['authors'] = authors['authors'].apply(text_to_list)\n",
    "\n",
    "authors.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "efbb59cb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th>A</th>\n",
       "      <th>Belitski</th>\n",
       "      <th>Budzianowski</th>\n",
       "      <th>S</th>\n",
       "      <th>Sra</th>\n",
       "      <th>A A Lazar</th>\n",
       "      <th>A A Nanavati</th>\n",
       "      <th>A A Nielsen</th>\n",
       "      <th>A Agah</th>\n",
       "      <th>...</th>\n",
       "      <th>yao sun</th>\n",
       "      <th>yatian shen</th>\n",
       "      <th>yichao yan</th>\n",
       "      <th>yongliang wang</th>\n",
       "      <th>yuanzhang su</th>\n",
       "      <th>zhiting hu</th>\n",
       "      <th>zhiwei liu</th>\n",
       "      <th>zhixu li</th>\n",
       "      <th>zhongmin Cai</th>\n",
       "      <th>zulin wang</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 147950 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       A   Belitski   Budzianowski   S   Sra  A A Lazar  A A Nanavati  \\\n",
       "0  0   0          0              0   0     0          0             0   \n",
       "1  0   0          0              0   0     0          0             0   \n",
       "2  0   0          0              0   0     0          0             0   \n",
       "3  0   0          0              0   0     0          0             0   \n",
       "4  0   0          0              0   0     0          0             0   \n",
       "\n",
       "   A A Nielsen  A Agah  ...  yao sun  yatian shen  yichao yan  yongliang wang  \\\n",
       "0            0       0  ...        0            0           0               0   \n",
       "1            0       0  ...        0            0           0               0   \n",
       "2            0       0  ...        0            0           0               0   \n",
       "3            0       0  ...        0            0           0               0   \n",
       "4            0       0  ...        0            0           0               0   \n",
       "\n",
       "   yuanzhang su  zhiting hu  zhiwei liu  zhixu li  zhongmin Cai  zulin wang  \n",
       "0             0           0           0         0             0           0  \n",
       "1             0           0           0         0             0           0  \n",
       "2             0           0           0         0             0           0  \n",
       "3             0           0           0         0             0           0  \n",
       "4             0           0           0         0             0           0  \n",
       "\n",
       "[5 rows x 147950 columns]"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.preprocessing import MultiLabelBinarizer\n",
    "\n",
    "mlb = MultiLabelBinarizer()\n",
    "\n",
    "df = pd.DataFrame(mlb.fit_transform(authors['authors']),columns=mlb.classes_, index=authors.index)\n",
    "\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "c71b215a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(100, 147950)"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.array(df[df.index<100]).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "ed72d030",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "numpy.ndarray"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(df.values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "908beedc",
   "metadata": {},
   "outputs": [
    {
     "ename": "SyntaxError",
     "evalue": "'break' outside loop (668683560.py, line 1)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;36m  Cell \u001b[0;32mIn[9], line 1\u001b[0;36m\u001b[0m\n\u001b[0;31m    break\u001b[0m\n\u001b[0m    ^\u001b[0m\n\u001b[0;31mSyntaxError\u001b[0m\u001b[0;31m:\u001b[0m 'break' outside loop\n"
     ]
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "70626db7",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from keras.layers import Dense, Activation, Flatten\n",
    "model = tf.keras.Sequential()\n",
    "model.add(tf.keras.layers.Embedding(input_dim=df.shape[1], output_dim=64))\n",
    "#model.add(Flatten(64))\n",
    "model.add(Dense(64, activation='sigmoid'))\n",
    "# The model will take as input an integer matrix of size (batch,\n",
    "# input_length), and the largest integer (i.e. word index) in the input\n",
    "# should be no larger than 999 (vocabulary size).\n",
    "# Now model.output_shape is (None, 10, 64), where `None` is the batch\n",
    "# dimension.\n",
    "input_array = np.array(df[df.index<100])\n",
    "model.compile('rmsprop', 'mse')\n",
    "output_array = model.predict(input_array)\n",
    "print(output_array.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5971e8cd",
   "metadata": {},
   "outputs": [],
   "source": [
    "output_array[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b0e3e5ef",
   "metadata": {},
   "outputs": [],
   "source": [
    "help(tf.keras.layers.Embedding)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3462a9bc",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "np.array(df).shape()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f684ac25",
   "metadata": {},
   "outputs": [],
   "source": [
    "from gensim.models import Word2Vec\n",
    "\n",
    "model = Word2Vec(vector_size=64, window=5, min_count=0, sg=1, workers=8)\n",
    "model.build_vocab(df)\n",
    "model.train(df, total_examples=model.corpus_count, epochs=5) \n",
    "model.wv[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d6e79740",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.wv[70]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "80710348",
   "metadata": {},
   "outputs": [],
   "source": [
    "help(Word2Vec)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "227993c5",
   "metadata": {},
   "outputs": [],
   "source": [
    "import math\n",
    "import pandas as pd\n",
    "import tensorflow as tf\n",
    "import kerastuner.tuners as kt\n",
    "import matplotlib.pyplot as plt\n",
    "from tensorflow.keras import Model\n",
    "from tensorflow.keras import Sequential\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from tensorflow.keras.layers import Dense, Dropout\n",
    "from sklearn.model_selection import train_test_split\n",
    "from tensorflow.keras.losses import MeanSquaredLogarithmicError\n",
    "\n",
    "# data in google colab\n",
    "TRAIN_DATA_PATH = '/content/sample_data/california_housing_train.csv'\n",
    "TEST_DATA_PATH = '/content/sample_data/california_housing_test.csv'\n",
    "TARGET_NAME = 'median_house_value'\n",
    "\n",
    "train_data = pd.read_csv(TRAIN_DATA_PATH)\n",
    "test_data = pd.read_csv(TEST_DATA_PATH)\n",
    "\n",
    "x_train, y_train = train_data.drop(TARGET_NAME, axis=1), train_data[TARGET_NAME]\n",
    "x_test, y_test = test_data.drop(TARGET_NAME, axis=1), test_data[TARGET_NAME]\n",
    "\n",
    "Scale the dataset using MinMaxScaler.\n",
    "\n",
    "\n",
    "\n",
    "class AutoEncoders(Model):\n",
    "\n",
    "    def __init__(self, output_units):\n",
    "\n",
    "        super().__init__()\n",
    "        self.encoder = Sequential(\n",
    "                [\n",
    "                    Dense(df.shape[1], activation=\"relu\"),\n",
    "                    Dense(1000, activation=\"relu\"),\n",
    "                    Dense(20, activation=\"relu\")\n",
    "                ]\n",
    "        )\n",
    "\n",
    "        self.decoder = Sequential(\n",
    "                [\n",
    "                    Dense(20, activation=\"relu\"),\n",
    "                    Dense(1000, activation=\"relu\"),\n",
    "                    Dense(df.shape[1], activation=\"sigmoid\")\n",
    "                ]\n",
    "        )\n",
    "\n",
    "def call(self, inputs):\n",
    "\n",
    "    encoded = self.encoder(inputs)\n",
    "    decoded = self.decoder(encoded)\n",
    "    return decoded\n",
    "    \n",
    "auto_encoder = AutoEncoders(len(x_train_scaled.columns))\n",
    "\n",
    "auto_encoder.compile(\n",
    "        loss='mae',\n",
    "        metrics=['mae'],\n",
    "        optimizer='adam'\n",
    ")\n",
    "\n",
    "history = auto_encoder.fit(\n",
    "        x_train_scaled, \n",
    "        x_train_scaled, \n",
    "        epochs=15, \n",
    "        batch_size=32, \n",
    "        validation_data=(x_test_scaled, x_test_scaled)\n",
    ")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
