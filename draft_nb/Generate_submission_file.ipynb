{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "a3d08e45",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import torch.nn.functional as F\n",
    "import numpy as np\n",
    "\n",
    "device = torch.device(\"cuda\") if torch.cuda.is_available() else torch.device(\"cpu\")\n",
    "\n",
    "from utils import random_walk, generate_walks, read_train_val_graph, sparse_mx_to_torch_sparse_tensor\n",
    "from utils import apply_word2vec_on_features, create_and_normalize_adjacency, save_subgraph_in_file, train_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "17a294dc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of nodes: 138499 number of edges: 1091955 in All the set\n",
      "Number of nodes: 138499 number of edges: 982859 in the Training set\n",
      "len(nodes) 138499\n",
      "Creating random val_edges...\n",
      "Returned G_train, train_edges, val_edges, y_val, nodes and node_to_idx objects\n",
      "Loaded from edgelist.txt and with a training validation split ratio = 0.1\n"
     ]
    }
   ],
   "source": [
    "path = '../input_data/edgelist.txt'\n",
    "\n",
    "G, G_train, train_edges, val_edges, val_indices, y_val, nodes, node_to_idx = read_train_val_graph(val_ratio=0.1, path=path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "ee42de0d",
   "metadata": {},
   "outputs": [],
   "source": [
    "class GNN(nn.Module):\n",
    "    def __init__(self, n_feat, n_hidden, n_class, dropout):\n",
    "        super(GNN, self).__init__()\n",
    "        self.fc1 = nn.Linear(n_feat, n_hidden)\n",
    "        self.fc2 = nn.Linear(n_hidden, n_hidden)\n",
    "        self.fc3 = nn.Linear(n_hidden+2, n_hidden)\n",
    "        self.double_fc3 = nn.Linear((2*n_hidden), n_hidden)\n",
    "        self.fc4 = nn.Linear(n_hidden, n_class)\n",
    "        self.dropout = nn.Dropout(dropout)\n",
    "        self.relu = nn.ReLU()\n",
    "        \n",
    "        \n",
    "\n",
    "    def forward(self, x_in, adj, pairs):\n",
    "        \n",
    "        h1 = self.fc1(x_in)\n",
    "        z1 = self.relu(torch.mm(adj, h1))\n",
    "        z1 = self.dropout(z1)\n",
    "\n",
    "        h2 = self.fc2(z1)\n",
    "        z2 = self.relu(torch.mm(adj, h2))\n",
    "\n",
    "        x = z2[pairs[0]] - z2[pairs[1]] # embedded features (z2) of node 0 - embedded features of node 1\n",
    "        \n",
    "        x_auth = 2*pairs[2].reshape([len(pairs[2]), 1])\n",
    "        x_nb_auth = 2*pairs[3].reshape([len(pairs[3]), 1]) \n",
    "        \n",
    "        x = torch.cat((x, x_auth, x_nb_auth), dim=1) #pairs[3] : number of same authors or 1 if same author\n",
    "        \n",
    "        #x1 = z2[pairs[0]]\n",
    "        #x2 = z2[pairs[1]]\n",
    "        # could we add a new dimension to pairs to specify if same author(s)? and then what could we do?\n",
    "              \n",
    "        #x = torch.cat((x1, x2), dim=1)        \n",
    "        #x = self.relu(self.double_fc3(x))        \n",
    "        x = self.relu(self.fc3(x))\n",
    "        x = self.dropout(x)\n",
    "        x = self.fc4(x)\n",
    "\n",
    "        return F.log_softmax(x, dim=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "97a9845c",
   "metadata": {},
   "outputs": [],
   "source": [
    "epochs = 200\n",
    "n_hidden = 128\n",
    "dropout_rate = 0.2\n",
    "n_class = 2\n",
    "n_features = 128\n",
    "\n",
    "# Creates the model and specifies the optimizer\n",
    "model = GNN(n_features, n_hidden, n_class, dropout_rate).to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "3de8b443",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "GNN(\n",
       "  (fc1): Linear(in_features=128, out_features=128, bias=True)\n",
       "  (fc2): Linear(in_features=128, out_features=128, bias=True)\n",
       "  (fc3): Linear(in_features=130, out_features=128, bias=True)\n",
       "  (double_fc3): Linear(in_features=256, out_features=128, bias=True)\n",
       "  (fc4): Linear(in_features=128, out_features=2, bias=True)\n",
       "  (dropout): Dropout(p=0.2, inplace=False)\n",
       "  (relu): ReLU()\n",
       ")"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "PATH = \"../submissions_files/2023-03-23-model-200epochs.pt\"\n",
    "model.load_state_dict(torch.load(PATH))\n",
    "model.eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "f7a0361b",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'features' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[18], line 17\u001b[0m\n\u001b[1;32m     15\u001b[0m node_pairs \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39marray(np\u001b[38;5;241m.\u001b[39mtranspose(node_pairs))\n\u001b[1;32m     16\u001b[0m pairs \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mLongTensor(node_pairs)\u001b[38;5;241m.\u001b[39mto(device)\n\u001b[0;32m---> 17\u001b[0m output \u001b[38;5;241m=\u001b[39m model(\u001b[43mfeatures\u001b[49m, adj, pairs)\n\u001b[1;32m     18\u001b[0m y_pred \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mexp(output)\n\u001b[1;32m     19\u001b[0m y_pred \u001b[38;5;241m=\u001b[39m y_pred\u001b[38;5;241m.\u001b[39mdetach()\u001b[38;5;241m.\u001b[39mcpu()\u001b[38;5;241m.\u001b[39mnumpy()\n",
      "\u001b[0;31mNameError\u001b[0m: name 'features' is not defined"
     ]
    }
   ],
   "source": [
    "from datetime import datetime\n",
    "import pandas as pd\n",
    "\n",
    "\n",
    "\n",
    "# Read test data. Each sample is a pair of nodes\n",
    "node_pairs = list()\n",
    "with open('../test_data/test.txt', 'r') as f:\n",
    "    for line in f:\n",
    "        t = line.split(',')\n",
    "        node_pairs.append((node_to_idx[int(t[0])], node_to_idx[int(t[1])]))\n",
    "\n",
    "# Testing\n",
    "model.eval()\n",
    "node_pairs = np.array(np.transpose(node_pairs))\n",
    "pairs = torch.LongTensor(node_pairs).to(device)\n",
    "output = model(features, adj, pairs)\n",
    "y_pred = torch.exp(output)\n",
    "y_pred = y_pred.detach().cpu().numpy()\n",
    "\n",
    "y_pred_true = list()\n",
    "for element in y_pred:\n",
    "    y_pred_true.append(element[1])\n",
    "    \n",
    "\n",
    "    \n",
    "today = datetime.today().strftime('%Y-%m-%d')\n",
    "random_nb = randint(0, 1000)\n",
    "\n",
    "pd.DataFrame(y_pred_true, columns={'predicted'}).to_csv(\n",
    "\"../submissions_files/{}-submission-{}-{}.csv\".format(today, model_nb, random_nb), header=True, index=True, index_label='id'\n",
    ")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
