{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "a919b81f",
   "metadata": {},
   "outputs": [],
   "source": [
    "from utils import random_walk, generate_walks, read_train_val_graph \n",
    "from utils import apply_word2vec_on_features, create_and_normalize_adjacency"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "d25112fe",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import log_loss, accuracy_score\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from time import time\n",
    "from gensim.models import Word2Vec\n",
    "import networkx as nx\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import torch.nn.functional as F\n",
    "\n",
    "\n",
    "device = torch.device(\"cuda\") if torch.cuda.is_available() else torch.device(\"cpu\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "2b2f1217",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "20000 nodes, 156145 edges Graph saved in ../input_data/small_edgelist.txt\n"
     ]
    }
   ],
   "source": [
    "def save_subgraph_in_file(nbr_nodes, source_path='../input_data/edgelist.txt', destination_path='../input_data/small_edgelist.txt'):\n",
    "    G = nx.read_edgelist(source_path, delimiter=',', create_using=nx.Graph(), nodetype=int)\n",
    "    G = G.subgraph(range(size))\n",
    "    nx.write_edgelist(G, path=destination_path, delimiter=',')\n",
    "    print(G.number_of_nodes(), 'nodes,', G.number_of_edges(), 'edges Graph saved in', destination_path)\n",
    "    return\n",
    "save_subgraph_in_file(nbr_nodes=138499)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "601b8c97",
   "metadata": {},
   "outputs": [],
   "source": [
    "class GNN(nn.Module):\n",
    "    def __init__(self, n_feat, n_hidden, n_class, dropout):\n",
    "        super(GNN, self).__init__()\n",
    "        self.fc1 = nn.Linear(n_feat, n_hidden)\n",
    "        self.fc2 = nn.Linear(n_hidden, n_hidden)\n",
    "        self.fc3 = nn.Linear(n_hidden, n_hidden)\n",
    "        self.fc3 = nn.Linear(n_hidden, n_hidden)\n",
    "        self.fc4 = nn.Linear(n_hidden, n_class)\n",
    "        self.dropout = nn.Dropout(dropout)\n",
    "        self.relu = nn.ReLU()\n",
    "\n",
    "    def forward(self, x_in, adj, pairs):\n",
    "        \n",
    "        h1 = self.fc1(x_in)\n",
    "        z1 = self.relu(torch.mm(adj, h1))\n",
    "        z1 = self.dropout(z1)\n",
    "\n",
    "        h2 = self.fc2(z1)\n",
    "        z2 = self.relu(torch.mm(adj, h2))\n",
    "\n",
    "        x = z2[pairs[0,:],:] - z2[pairs[1,:],:] # embedded features (z2) of node 0 - embedded features of node 1\n",
    "        # could we add a new dimension to pairs to specify if same author(s)? and then what could we do?\n",
    "        x = self.relu(self.fc3(x))\n",
    "        x = self.dropout(x)\n",
    "        x = self.fc4(x)\n",
    "\n",
    "        return F.log_softmax(x, dim=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "4731e087",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Ishan', 'b', 'c']"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "l = list(['a', 'b', 'c'])\n",
    "l = list(map(lambda x: x.replace('a', 'Ishan'), l))\n",
    "l\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "32841f41",
   "metadata": {},
   "outputs": [],
   "source": [
    "def sparse_mx_to_torch_sparse_tensor(sparse_mx):\n",
    "    sparse_mx = sparse_mx.tocoo().astype(np.float32)\n",
    "    indices = torch.from_numpy(np.vstack((sparse_mx.row, sparse_mx.col)).astype(np.int64))\n",
    "    values = torch.from_numpy(sparse_mx.data)\n",
    "    shape = torch.Size(sparse_mx.shape)\n",
    "    return torch.sparse.FloatTensor(indices, values, shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "e894f370",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of nodes of total set: 138499\n",
      "Number of edges of total set: 1091955\n",
      "Number of edges of training set: 983161\n",
      "Returned G_train, train_edges, val_edges, y_val and nodes objects\n",
      "Loaded from edgelist.txt and with a training validation split ratio = 0.1\n",
      "Start generating walks....\n",
      "Random walks generated in in 82s!\n",
      "Start applying Word2Vec...\n",
      "Word2vec model trained on features in 4 min!\n",
      "(138499, 128) features numpy array created in 4 min!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/ghassenabdedayem/Documents/Data/Polytechnique/5- Data Challenge/data_challenge_2022/draft_nb/utils.py:116: FutureWarning: adjacency_matrix will return a scipy.sparse array instead of a matrix in Networkx 3.0.\n",
      "  adj = nx.adjacency_matrix(G) # Obtains the adjacency matrix of the training graph\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Created a normalized adjancency matrix of shape (138499, 138499)\n",
      "Created indices (2, 2104821) with the positions of non zeros in adj matrix\n"
     ]
    }
   ],
   "source": [
    "path = '../input_data/edgelist.txt'\n",
    "\n",
    "G_train, train_edges, val_edges, y_val, nodes = read_train_val_graph(val_ratio=0.1, path=path)\n",
    "walks = generate_walks(G=G_train, num_walks=10, walk_length=15)\n",
    "features_np = apply_word2vec_on_features(features=walks, nodes=nodes)\n",
    "adj, indices = create_and_normalize_adjacency(G_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "469d827f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((217588,), (138499,), (983161, 2), (217588, 2))"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.shape(y_val), np.shape(G_train), np.shape(train_edges), np.shape(val_edges)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "f84f53c0",
   "metadata": {},
   "outputs": [
    {
     "ename": "SyntaxError",
     "evalue": "'break' outside loop (668683560.py, line 1)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;36m  Cell \u001b[0;32mIn[36], line 1\u001b[0;36m\u001b[0m\n\u001b[0;31m    break\u001b[0m\n\u001b[0m    ^\u001b[0m\n\u001b[0;31mSyntaxError\u001b[0m\u001b[0;31m:\u001b[0m 'break' outside loop\n"
     ]
    }
   ],
   "source": [
    "break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6bbf0ee2",
   "metadata": {},
   "outputs": [],
   "source": [
    "np.shape(y_val), np.shape(G_train), np.shape(train_edges), np.shape(val_edges)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "78364549",
   "metadata": {},
   "outputs": [],
   "source": [
    "features_np.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "44a40c91",
   "metadata": {},
   "outputs": [],
   "source": [
    "G_train.number_of_edges()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "5da7e813",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create class labels\n",
    "y = np.zeros(2*indices.shape[1])\n",
    "y[:indices.shape[1]] = 1 # Concatenated ones for edges indices and later in the model we add zeros for random indices.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "dfd0f256",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Transforms the numpy matrices/vectors to torch tensors.\n",
    "features = torch.FloatTensor(features_np).to(device)\n",
    "y = torch.LongTensor(y).to(device)\n",
    "if type(adj) != torch.Tensor:\n",
    "    adj = sparse_mx_to_torch_sparse_tensor(adj).to(device)\n",
    "indices = torch.LongTensor(indices).to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "ae62c3b3",
   "metadata": {},
   "outputs": [],
   "source": [
    "epochs = 1\n",
    "n_hidden = 128\n",
    "dropout_rate = 0.2\n",
    "n_class = 2\n",
    "n_features = features.shape[1]\n",
    "\n",
    "# Creates the model and specifies the optimizer\n",
    "model = GNN(n_features, n_hidden, n_class, dropout_rate).to(device)\n",
    "optimizer = optim.Adam(model.parameters(), lr=0.01)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "6683f78d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([2, 2104821])\n",
      "torch.Size([4209642])\n"
     ]
    }
   ],
   "source": [
    "print(indices.shape)\n",
    "#print(rand_indices.shape)\n",
    "#print(pairs.shape)\n",
    "print(y.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "41d325d7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2104821.0\n"
     ]
    }
   ],
   "source": [
    "print(len(y)/2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "033efbf7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 001 loss_train: 0.6933 acc_train: 0.4999 time: 20.7952 s total_time: 0 min\n",
      "Optimization Finished in 0 min!\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import time\n",
    "\n",
    "# Train model\n",
    "model.train()\n",
    "start_time = time.time()\n",
    "for epoch in range(epochs):\n",
    "    t = time.time()\n",
    "    optimizer.zero_grad()\n",
    "    rand_indices = torch.randint(0, features.size(0), (indices.size(0),indices.size(1)), device=adj.device)# We take random indices each time we run an epoch\n",
    "    pairs = torch.cat((indices, rand_indices), dim=1) # Concatenate the edges indices and random indices.   \n",
    "    output = model(features, adj, pairs) # we run the model that gives the output.\n",
    "    loss_train = F.nll_loss(output, y) # we are using nll_loss as loss to optimize, we store it in loss_train. We compare to y which is stable and contains the tag ones and zeros.\n",
    "    #print(type(loss_train), '\\n', loss_train.shape)\n",
    "    acc_train = accuracy_score(torch.argmax(output, dim=1).detach().cpu().numpy(), y.cpu().numpy())# just to show it in the out put message of the training\n",
    "    loss_train.backward() # The back propagation ? --> Computes the gradient of current tensor w.r.t. graph leaves\n",
    "    optimizer.step() # Performs a single optimization step (parameter update).\n",
    "    \n",
    "    if epoch % 5 == 0:\n",
    "        print('Epoch: {:03d}'.format(epoch+1),\n",
    "              'loss_train: {:.4f}'.format(loss_train.item()),\n",
    "              'acc_train: {:.4f}'.format(acc_train.item()),\n",
    "              'time: {:.4f} s'.format(time.time() - t),\n",
    "             'total_time: {} min'.format(round((time.time() - start_time)/60)))\n",
    "\n",
    "print(\"Optimization Finished in {} min!\".format(round((time.time() - start_time)/60)))\n",
    "print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "bf9396c3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(2, 217588)\n",
      "torch.Size([2, 217588])\n",
      "torch.Size([217588, 2])\n",
      "Log loss: 0.6937010884284973\n"
     ]
    }
   ],
   "source": [
    "# Evaluating the model\n",
    "model.eval()\n",
    "eval_pairs = np.array(np.transpose(val_edges))\n",
    "print(eval_pairs.shape)\n",
    "eval_pairs = torch.LongTensor(eval_pairs).to(device)\n",
    "print(eval_pairs.shape)\n",
    "eval_output = model(features, adj, eval_pairs)\n",
    "print(eval_output.shape)\n",
    "y_pred = torch.exp(eval_output)\n",
    "y_pred = y_pred.detach().cpu().numpy()\n",
    "\n",
    "y_pred_true = list()\n",
    "for element in y_pred:\n",
    "    y_pred_true.append(element[1])\n",
    "    \n",
    "print('Log loss:', log_loss(y_val, y_pred_true))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "11b159ce",
   "metadata": {},
   "outputs": [],
   "source": [
    "#print(output.shape)\n",
    "print(features.shape, adj.shape, eval_pairs.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "df84ba19",
   "metadata": {},
   "outputs": [],
   "source": [
    "eval_pairs.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4446f682",
   "metadata": {},
   "outputs": [],
   "source": [
    "z2[pairs[1,:]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1a903e9f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5871296e",
   "metadata": {},
   "outputs": [],
   "source": [
    "adj = nx.adjacency_matrix(G_train) # Obtains the adjacency matrix of the training graph\n",
    "adj = normalize_adjacency(adj) # Normalizes the adjacency matrix only by adding ones to diag\n",
    "indices = np.array(adj.nonzero()) # Gets the positions of non zeros of adj into indices"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b7d7c683",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "425d6600",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e8607dda",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "991ef0b1",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "97ad5476",
   "metadata": {},
   "outputs": [],
   "source": [
    "# features initializaed with word2vec embedding of the random walks\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "71737f09",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create class labels\n",
    "y = np.zeros(4*G_train.number_of_edges())\n",
    "y[:2*G_train.number_of_edges()] = 1 # Concatenated ones for edges indices and later in the model we add zeros for random indices.\n",
    "train_edges[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2ede8a83",
   "metadata": {},
   "outputs": [],
   "source": [
    "t = time()\n",
    "X_train = np.zeros((4*m, 2*features_np.shape[1]))\n",
    "\n",
    "for i, edge in enumerate(train_edges):\n",
    "    X_train[i] = np.concatenate((features_np[train_edges[i][0]], features_np[train_edges[i][1]]), axis=0)\n",
    "    X_train[m+i] = np.concatenate((features_np[train_edges[i][0]], features_np[train_edges[i][1]]), axis=0)\n",
    "    X_train[2*m+i] = np.concatenate((features_np[randint(0,n-1)], features_np[randint(0,n-1)]), axis=0)\n",
    "    X_train[3*m+i] = np.concatenate((features_np[randint(0,n-1)], features_np[randint(0,n-1)]), axis=0)\n",
    "    \n",
    "X_val = np.zeros((len(val_edges), 2*features_np.shape[1]))\n",
    "for i, edge in enumerate(val_edges):\n",
    "    X_val[i] = np.concatenate((features_np[val_edges[i][0]], features_np[val_edges[i][1]]), axis=0)\n",
    "    \n",
    "print('X_train and X_val created in {} s!'.format(round(time()-t)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cf44a3c2",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8a6fa791",
   "metadata": {},
   "outputs": [],
   "source": [
    "t = time()\n",
    "# Use logistic regression to predict if two nodes are linked by an edge\n",
    "clf = LogisticRegression()\n",
    "clf.fit(X_train, y)\n",
    "y_pred = clf.predict_proba(X_val)\n",
    "y_pred = y_pred[:,1]\n",
    "print('Logistic regression performed in {} s!'.format(round(time()-t)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4d4c60b6",
   "metadata": {},
   "outputs": [],
   "source": [
    "print('Log loss:', log_loss(y_val, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eb2b1ed0",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ac02a4ab",
   "metadata": {},
   "outputs": [],
   "source": [
    "from datetime import datetime\n",
    "\n",
    "# Read test data. Each sample is a pair of nodes\n",
    "test_edges = list()\n",
    "with open('../test_data/test.txt', 'r') as f:\n",
    "    for line in f:\n",
    "        t = line.split(',')\n",
    "        test_edges.append((node_to_idx[int(t[0])], node_to_idx[int(t[1])]))\n",
    "\n",
    "X_test = np.zeros((len(test_edges), 2*features_np.shape[1]))\n",
    "for i, edge in enumerate(test_edges):\n",
    "    X_test[i] = np.concatenate((features_np[test_edges[i][0]], features_np[test_edges[i][1]]), axis=0)\n",
    "\n",
    "t = time()\n",
    "# Use logistic regression to predict if two nodes are linked by an edge\n",
    "y_pred = clf.predict_proba(X_test)\n",
    "y_pred = y_pred[:,1]\n",
    "print('Logistic regression performed in {} s!'.format(round(time()-t)))\n",
    "\n",
    "\n",
    "today = datetime.today().strftime('%Y-%m-%d')\n",
    "random_nb = randint(0, 100000)\n",
    "\n",
    "pd.DataFrame(y_pred, columns={'predicted'}).to_csv(\n",
    "\"../submissions_files/{}-submission-{}.csv\".format(today, random_nb), header=True, index=True, index_label='id'\n",
    ")\n",
    "    \n",
    "    \n",
    "# # Testing\n",
    "# node_pairs = np.array(np.transpose(node_pairs))\n",
    "# pairs = torch.LongTensor(node_pairs).to(device)\n",
    "# output = model(features, adj, pairs)\n",
    "# y_pred = torch.exp(output)\n",
    "# y_pred = y_pred.detach().cpu().numpy()\n",
    "\n",
    "# y_pred_true = list()\n",
    "# for element in y_pred:\n",
    "#     y_pred_true.append(element[1])\n",
    "    \n",
    "\n",
    "    \n",
    "# today = datetime.today().strftime('%Y-%m-%d')\n",
    "# random_nb = randint(0, 100000)\n",
    "\n",
    "# pd.DataFrame(y_pred_true, columns={'predicted'}).to_csv(\n",
    "# \"../submissions_files/{}-submission-{}.csv\".format(today, random_nb), header=True, index=True, index_label='id'\n",
    "# )"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
