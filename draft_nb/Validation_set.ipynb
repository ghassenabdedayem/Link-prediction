{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "fa82d6c0",
   "metadata": {},
   "outputs": [],
   "source": [
    "import networkx as nx\n",
    "import numpy as np\n",
    "from random import randint\n",
    "from random import random\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "from sklearn.metrics import log_loss, accuracy_score\n",
    "import pandas as pd\n",
    "from time import time\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6ca04022",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "7df540b3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of nodes of total set: 138499\n",
      "Number of edges of total set: 1091955\n",
      "Number of nodes of training set: 138499\n",
      "Number of edges of training set: 982380\n"
     ]
    }
   ],
   "source": [
    "G = nx.read_edgelist('../input_data/edgelist.txt', delimiter=',', create_using=nx.Graph(), nodetype=int)\n",
    "nodes = list(G.nodes())\n",
    "n = G.number_of_nodes()\n",
    "m = G.number_of_edges()\n",
    "edges = list(G.edges())\n",
    "\n",
    "print('Number of nodes of total set:', n)\n",
    "print('Number of edges of total set:', m)\n",
    "\n",
    "node_to_idx = dict()\n",
    "for i, node in enumerate(nodes):\n",
    "    node_to_idx[node] = i\n",
    "\n",
    "val_edges = list()\n",
    "G_train = G\n",
    "\n",
    "for edge in edges:\n",
    "    if random() < 0.1:\n",
    "        val_edges.append(edge)\n",
    "\n",
    "# We remove the val edges from the graph G\n",
    "for edge in val_edges:\n",
    "    G_train.remove_edge(edge[0], edge[1])\n",
    "\n",
    "n = G_train.number_of_nodes()\n",
    "m = G_train.number_of_edges()\n",
    "train_edges = list(G_train.edges())\n",
    "    \n",
    "print('Number of nodes of training set:', n)\n",
    "print('Number of edges of training set:', m)\n",
    "\n",
    "y_val = [1]*len(val_edges)\n",
    "\n",
    "n_val_edges = len(val_edges)\n",
    "\n",
    "# Create random pairs of nodes (testing negative edges)\n",
    "for i in range(n_val_edges):\n",
    "    n1 = nodes[randint(0, n-1)]\n",
    "    n2 = nodes[randint(0, n-1)]\n",
    "    (n1, n2) = (min(n1, n2), max(n1, n2))\n",
    "    val_edges.append((n1, n2))\n",
    "    \n",
    "# Remove from val_edges edges that exist in both train and val\n",
    "# for edge in list(set(val_edges) & set(train_edges)):\n",
    "#     val_edges.remove(edge)\n",
    "    \n",
    "# n_val_edges = len(val_edges) # - len(y_val) #because we removed from val_edges edges that exist in both\n",
    "y_val.extend([0]*(n_val_edges))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "9759171d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def random_walk(G, node, walk_length):\n",
    "    walk = [node]\n",
    "  \n",
    "    for i in range(walk_length-1):\n",
    "        neibor_nodes = list(G.neighbors(walk[-1]))\n",
    "        if len(neibor_nodes) > 0:\n",
    "            next_node = choice(neibor_nodes)\n",
    "            walk.append(next_node)\n",
    "    walk = [str(node) for node in walk] # in case the nodes are in string format, we don't need to cast into string, but if the nodes are in numeric or integer, we need this line to cast into string\n",
    "    return walk\n",
    "\n",
    "def generate_walks(G, num_walks, walk_length):\n",
    "  # Runs \"num_walks\" random walks from each node, and returns a list of all random walk\n",
    "    walks = list()  \n",
    "    for i in range(num_walks):\n",
    "        for node in G.nodes():\n",
    "            walk = random_walk(G, node, walk_length)\n",
    "            walks.append(walk)\n",
    "        #print('walks : ', walks)\n",
    "    return walks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "ef66556a",
   "metadata": {},
   "outputs": [],
   "source": [
    "t = time()\n",
    "walks = generate_walks(G=G_train, num_walks=10, walk_length=15)\n",
    "print('Random walks generated in in {} s!'.format(round(time()-t)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "11dbe850",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(102885150, 102885150)"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "t = time()\n",
    "wv_model = Word2Vec(vector_size=128, window=5, min_count=0, sg=1, workers=8)\n",
    "wv_model.build_vocab(walks)\n",
    "wv_model.train(walks, total_examples=wv_model.corpus_count, epochs=5) \n",
    "print('Word2vec embedding of the Random walks generated in in {} s!'.format(round(time()-t)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "b4413fd9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# features initializaed with word2vec embedding of the random walks\n",
    "features_np = []\n",
    "for node in G_train.nodes():\n",
    "    features_np.append(wv_model.wv[str(node)])\n",
    "\n",
    "features_np = np.array(features_np)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "f93be4ac",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0, 1)"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Create class labels\n",
    "y = np.zeros(4*G_train.number_of_edges())\n",
    "y[:2*G_train.number_of_edges()] = 1 # Concatenated ones for edges indices and later in the model we add zeros for random indices.\n",
    "train_edges[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "66772ef5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X_train and X_val created in 22 s\n"
     ]
    }
   ],
   "source": [
    "t = time()\n",
    "X_train = np.zeros((4*m, 2*features_np.shape[1]))\n",
    "\n",
    "for i, edge in enumerate(train_edges):\n",
    "    X_train[i] = np.concatenate((features_np[train_edges[i][0]], features_np[train_edges[i][1]]), axis=0)\n",
    "    X_train[m+i] = np.concatenate((features_np[train_edges[i][0]], features_np[train_edges[i][1]]), axis=0)\n",
    "    X_train[2*m+i] = np.concatenate((features_np[randint(0,n-1)], features_np[randint(0,n-1)]), axis=0)\n",
    "    X_train[3*m+i] = np.concatenate((features_np[randint(0,n-1)], features_np[randint(0,n-1)]), axis=0)\n",
    "    \n",
    "X_val = np.zeros((len(val_edges), 2*features_np.shape[1]))\n",
    "for i, edge in enumerate(val_edges):\n",
    "    X_val[i] = np.concatenate((features_np[val_edges[i][0]], features_np[val_edges[i][1]]), axis=0)\n",
    "    \n",
    "print('X_train and X_val created in {} s!'.format(round(time()-t)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "c4eef9a1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(3929520, 256)"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "16813b72",
   "metadata": {},
   "outputs": [],
   "source": [
    "t = time()\n",
    "# Use logistic regression to predict if two nodes are linked by an edge\n",
    "clf = LogisticRegression()\n",
    "clf.fit(X_train, y)\n",
    "y_pred = clf.predict_proba(X_val)\n",
    "y_pred = y_pred[:,1]\n",
    "print('Logistic regression performed in {} s!'.format(round(time()-t)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "63a22eb5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Log loss: 0.6637081967909859\n"
     ]
    }
   ],
   "source": [
    "print('Log loss:', log_loss(y_val, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a49d0076",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "76e9a557",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Logistic regression performed in 0 s!\n"
     ]
    }
   ],
   "source": [
    "from datetime import datetime\n",
    "\n",
    "# Read test data. Each sample is a pair of nodes\n",
    "test_edges = list()\n",
    "with open('../test_data/test.txt', 'r') as f:\n",
    "    for line in f:\n",
    "        t = line.split(',')\n",
    "        test_edges.append((node_to_idx[int(t[0])], node_to_idx[int(t[1])]))\n",
    "\n",
    "X_test = np.zeros((len(test_edges), 2*features_np.shape[1]))\n",
    "for i, edge in enumerate(test_edges):\n",
    "    X_test[i] = np.concatenate((features_np[test_edges[i][0]], features_np[test_edges[i][1]]), axis=0)\n",
    "\n",
    "t = time()\n",
    "# Use logistic regression to predict if two nodes are linked by an edge\n",
    "y_pred = clf.predict_proba(X_test)\n",
    "y_pred = y_pred[:,1]\n",
    "print('Logistic regression performed in {} s!'.format(round(time()-t)))\n",
    "\n",
    "\n",
    "today = datetime.today().strftime('%Y-%m-%d')\n",
    "random_nb = randint(0, 100000)\n",
    "\n",
    "pd.DataFrame(y_pred, columns={'predicted'}).to_csv(\n",
    "\"../submissions_files/{}-submission-{}.csv\".format(today, random_nb), header=True, index=True, index_label='id'\n",
    ")\n",
    "    \n",
    "    \n",
    "# # Testing\n",
    "# node_pairs = np.array(np.transpose(node_pairs))\n",
    "# pairs = torch.LongTensor(node_pairs).to(device)\n",
    "# output = model(features, adj, pairs)\n",
    "# y_pred = torch.exp(output)\n",
    "# y_pred = y_pred.detach().cpu().numpy()\n",
    "\n",
    "# y_pred_true = list()\n",
    "# for element in y_pred:\n",
    "#     y_pred_true.append(element[1])\n",
    "    \n",
    "\n",
    "    \n",
    "# today = datetime.today().strftime('%Y-%m-%d')\n",
    "# random_nb = randint(0, 100000)\n",
    "\n",
    "# pd.DataFrame(y_pred_true, columns={'predicted'}).to_csv(\n",
    "# \"../submissions_files/{}-submission-{}.csv\".format(today, random_nb), header=True, index=True, index_label='id'\n",
    "# )"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
