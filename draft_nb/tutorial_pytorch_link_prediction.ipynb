{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "2845bce9",
   "metadata": {},
   "outputs": [],
   "source": [
    "import csv\n",
    "import networkx as nx\n",
    "import numpy as np\n",
    "from random import randint\n",
    "from random import random\n",
    "import pandas as pd\n",
    "from unidecode import unidecode\n",
    "import numpy as np\n",
    "from sklearn.preprocessing import MultiLabelBinarizer\n",
    "\n",
    "\n",
    "from scipy.sparse import identity, diags, csr_matrix\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import torch.nn.functional as F\n",
    "\n",
    "from sklearn.metrics import log_loss, accuracy_score\n",
    "\n",
    "\n",
    "device = torch.device(\"cuda\") if torch.cuda.is_available() else torch.device(\"cpu\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "b75016b9",
   "metadata": {},
   "outputs": [],
   "source": [
    "def text_to_list(text):\n",
    "    return unidecode(text).split(',')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "0983d229",
   "metadata": {},
   "outputs": [],
   "source": [
    "def new_normalize_adjacency(A):\n",
    "    n = A.shape[0] \n",
    "    A = A + identity(n)\n",
    "    return A"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "c66b61d2",
   "metadata": {},
   "outputs": [],
   "source": [
    "def sparse_mx_to_torch_sparse_tensor(sparse_mx):\n",
    "    sparse_mx = sparse_mx.tocoo().astype(np.float32)\n",
    "    indices = torch.from_numpy(np.vstack((sparse_mx.row, sparse_mx.col)).astype(np.int64))\n",
    "    values = torch.from_numpy(sparse_mx.data)\n",
    "    shape = torch.Size(sparse_mx.shape)\n",
    "    return torch.sparse.FloatTensor(indices, values, shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "2b5543f3",
   "metadata": {},
   "outputs": [],
   "source": [
    "class MessagePassing(nn.Module):\n",
    "    def __init__(self, input_dim, output_dim):\n",
    "        super(MessagePassing, self).__init__()\n",
    "        self.fc = nn.Linear(input_dim, output_dim)\n",
    "\n",
    "    def forward(self, x, adj):\n",
    "        \n",
    "        x = self.cf(x)\n",
    "        out = torch.mm(adj, x)\n",
    "        \n",
    "        return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "2e5655a1",
   "metadata": {},
   "outputs": [],
   "source": [
    "class GNN(nn.Module):\n",
    "    def __init__(self, n_feat, n_hidden, n_class, dropout):\n",
    "        super(GNN, self).__init__()\n",
    "#         self.fc11 = nn.Linear(n_feat, round(n_feat/10))\n",
    "#         self.fc12 = nn.Linear(round(n_feat/10), round(n_feat/100))\n",
    "#         self.fc13 = nn.Linear(round(n_feat/100), round(n_feat/200))\n",
    "#         self.fc14 = nn.Linear(round(n_feat/200), n_hidden)\n",
    "        self.fc11 = nn.Linear(n_feat, n_hidden)\n",
    "        self.fc12 = nn.Linear(n_hidden, n_hidden)\n",
    "        self.fc13 = nn.Linear(n_hidden, n_hidden)\n",
    "        self.fc14 = nn.Linear(n_hidden, n_hidden)\n",
    "                              \n",
    "        self.fc2 = nn.Linear(n_hidden, n_hidden)\n",
    "        self.fc3 = nn.Linear(n_hidden, n_hidden)\n",
    "        self.fc3 = nn.Linear(n_hidden, n_hidden)\n",
    "        self.fc4 = nn.Linear(n_hidden, n_class)\n",
    "        self.dropout = nn.Dropout(dropout)\n",
    "        self.relu = nn.ReLU()\n",
    "\n",
    "    def forward(self, x_in, adj, pairs):\n",
    "        \n",
    "        # Authors embedding using 4 levels MLP to densify representation from sparse 147950 features to n_hidden embedded features\n",
    "        h11 = self.fc11(x_in)\n",
    "        z11 = self.relu(torch.mm(adj, h11)) # remove the multiplication with adj each time ?\n",
    "#         h12 = self.fc12(z11)\n",
    "#         z12 = self.relu(torch.mm(adj, h12))\n",
    "#         h13 = self.fc13(z12)\n",
    "#         z13 = self.relu(torch.mm(adj, h13))\n",
    "#         h14 = self.fc13(z13)\n",
    "#         z14 = self.relu(torch.mm(adj, h14))\n",
    "        \n",
    "        z1 = self.dropout(z11)\n",
    "        #print('h1.shape=', z1.shape, ' adj.shape=', adj.shape)\n",
    "        h2 = self.fc2(z1)\n",
    "        \n",
    "        z2 = self.relu(torch.mm(adj, h2))\n",
    "        \n",
    "        x = z2[pairs[0,:],:] - z2[pairs[1,:],:]\n",
    "        x = self.relu(self.fc3(x))\n",
    "        x = self.dropout(x)\n",
    "        x = self.fc4(x)\n",
    "\n",
    "        return F.log_softmax(x, dim=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "18418dc8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of nodes of training set: 138499\n",
      "Number of edges of training set: 982771\n"
     ]
    }
   ],
   "source": [
    "G = nx.read_edgelist('../input_data/edgelist.txt', delimiter=',', create_using=nx.Graph(), nodetype=int)\n",
    "nodes = list(G.nodes())\n",
    "n = G.number_of_nodes()\n",
    "m = G.number_of_edges()\n",
    "edges = list(G.edges())\n",
    "\n",
    "val_edges = list()\n",
    "G_train = G\n",
    "\n",
    "for edge in edges:\n",
    "    if random() < 0.1:\n",
    "        val_edges.append(edge)\n",
    "\n",
    "# We remove the val edges from the graph G\n",
    "for edge in val_edges:\n",
    "    G_train.remove_edge(edge[0], edge[1])\n",
    "\n",
    "n = G_train.number_of_nodes()\n",
    "m = G_train.number_of_edges()\n",
    "train_edges = list(G_train.edges())\n",
    "    \n",
    "print('Number of nodes of training set:', n)\n",
    "print('Number of edges of training set:', m)\n",
    "\n",
    "y_val = [1]*len(val_edges)\n",
    "\n",
    "n_val_edges = len(val_edges)\n",
    "\n",
    "# Create random pairs of nodes\n",
    "for i in range(n_val_edges):\n",
    "    n1 = nodes[randint(0, n-1)]\n",
    "    n2 = nodes[randint(0, n-1)]\n",
    "    (n1, n2) = (min(n1, n2), max(n1, n2))\n",
    "    val_edges.append((n1, n2))\n",
    "    \n",
    "# Remove from val_edges edges that exist in both train and val\n",
    "\n",
    "for edge in list(set(val_edges) & set(train_edges)):\n",
    "    val_edges.remove(edge)\n",
    "    \n",
    "n_val_edges = len(val_edges) - len(y_val) #because we removed from val_edges edges that exist in both\n",
    "y_val.extend([0]*n_val_edges)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "2a7f359e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'numpy.ndarray'>\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(138499, 32)"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# features initializaed with a sparce representation of authors of the papers\n",
    "\n",
    "authors = pd.read_csv('../input_data/authors.txt', sep = '|', header=None)\n",
    "authors = authors.rename(columns={0: \"paper_id\", 2: \"authors\"})\n",
    "authors['authors'] = authors['authors'].apply(text_to_list)\n",
    "mlb = MultiLabelBinarizer()\n",
    "df = pd.DataFrame(mlb.fit_transform(authors['authors']),columns=mlb.classes_, index=authors.index)\n",
    "features_np = df.values\n",
    "\n",
    "features_np = np.random.randn(G_train.number_of_nodes(), 32) # Generates node features randomly\n",
    "print(type(features_np))\n",
    "features_np.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "02058af3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# from gensim.models import Word2Vec\n",
    "\n",
    "# model = Word2Vec(vector_size=1000, window=5, min_count=0, sg=1, workers=8)\n",
    "# model.build_vocab(features_np)\n",
    "# model.train(features_np, total_examples=model.corpus_count, epochs=5) \n",
    "# model.wv['32098']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9bacbb98",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "33457238",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/pd/glcnl2497w5b6xn3p94tnwlr0000gn/T/ipykernel_25846/2663459448.py:1: FutureWarning: adjacency_matrix will return a scipy.sparse array instead of a matrix in Networkx 3.0.\n",
      "  adj = nx.adjacency_matrix(G_train)# Obtains the adjacency matrix of the training graph\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'scipy.sparse._csr.csr_matrix'>\n",
      "(138499, 138499)\n",
      "<class 'scipy.sparse._csr.csr_matrix'> \n",
      "\n",
      "<class 'numpy.ndarray'>\n"
     ]
    }
   ],
   "source": [
    "adj = nx.adjacency_matrix(G_train)# Obtains the adjacency matrix of the training graph\n",
    "print(type(adj))\n",
    "print(adj.shape)\n",
    "adj = new_normalize_adjacency(adj) # Normalizes the adjacency matrix only by adding ones to diag\n",
    "print(type(adj), '\\n')\n",
    "\n",
    "indices = np.array(adj.nonzero())\n",
    "\n",
    "# Create class labels\n",
    "y = np.zeros(2*len(indices[0]))\n",
    "y[:len(indices[0])] = 1 # Concatenated ones for edges indices and zeros for random indices.\n",
    "\n",
    "# Transforms the numpy matrices/vectors to torch tensors.\n",
    "print(type(features_np))\n",
    "#features_np = csr_matrix(features_np)\n",
    "#print(type(features_np))\n",
    "#features = sparse_mx_to_torch_sparse_tensor(features_np).to(device)\n",
    "#print(type(features_np))\n",
    "features = torch.FloatTensor(features_np).to(device)\n",
    "y = torch.LongTensor(y).to(device)\n",
    "adj = sparse_mx_to_torch_sparse_tensor(adj).to(device)\n",
    "indices = torch.LongTensor(indices).to(device)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "7d93df05",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Hyperparameters\n",
    "epochs = 20\n",
    "n_hidden = 128\n",
    "dropout_rate = 0.2\n",
    "n_class = 2\n",
    "n_features = features.shape[1]\n",
    "\n",
    "# Creates the model and specifies the optimizer\n",
    "model = GNN(n_features, n_hidden, n_class, dropout_rate).to(device)\n",
    "optimizer = optim.Adam(model.parameters(), lr=0.01)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "98554ddd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([138499, 32])\n",
      "torch.Size([138499, 138499])\n"
     ]
    }
   ],
   "source": [
    "print(features.shape)\n",
    "print(adj.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "7567b078",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "h1.shape= torch.Size([138499, 128])  adj.shape= torch.Size([138499, 138499])\n",
      "Epoch: 001 loss_train: 9610.7598 acc_train: 0.4737 time: 27.4452s total_time: 0min\n",
      "h1.shape= torch.Size([138499, 128])  adj.shape= torch.Size([138499, 138499])\n",
      "h1.shape= torch.Size([138499, 128])  adj.shape= torch.Size([138499, 138499])\n",
      "h1.shape= torch.Size([138499, 128])  adj.shape= torch.Size([138499, 138499])\n",
      "h1.shape= torch.Size([138499, 128])  adj.shape= torch.Size([138499, 138499])\n",
      "h1.shape= torch.Size([138499, 128])  adj.shape= torch.Size([138499, 138499])\n",
      "Epoch: 006 loss_train: 824.4444 acc_train: 0.4812 time: 20.7298s total_time: 2min\n",
      "h1.shape= torch.Size([138499, 128])  adj.shape= torch.Size([138499, 138499])\n",
      "h1.shape= torch.Size([138499, 128])  adj.shape= torch.Size([138499, 138499])\n",
      "h1.shape= torch.Size([138499, 128])  adj.shape= torch.Size([138499, 138499])\n",
      "h1.shape= torch.Size([138499, 128])  adj.shape= torch.Size([138499, 138499])\n",
      "h1.shape= torch.Size([138499, 128])  adj.shape= torch.Size([138499, 138499])\n",
      "Epoch: 011 loss_train: 0.6889 acc_train: 0.6556 time: 20.5678s total_time: 4min\n",
      "h1.shape= torch.Size([138499, 128])  adj.shape= torch.Size([138499, 138499])\n",
      "h1.shape= torch.Size([138499, 128])  adj.shape= torch.Size([138499, 138499])\n",
      "h1.shape= torch.Size([138499, 128])  adj.shape= torch.Size([138499, 138499])\n",
      "h1.shape= torch.Size([138499, 128])  adj.shape= torch.Size([138499, 138499])\n",
      "h1.shape= torch.Size([138499, 128])  adj.shape= torch.Size([138499, 138499])\n",
      "Epoch: 016 loss_train: 0.6505 acc_train: 0.6500 time: 32.7759s total_time: 6min\n",
      "h1.shape= torch.Size([138499, 128])  adj.shape= torch.Size([138499, 138499])\n",
      "h1.shape= torch.Size([138499, 128])  adj.shape= torch.Size([138499, 138499])\n",
      "h1.shape= torch.Size([138499, 128])  adj.shape= torch.Size([138499, 138499])\n",
      "h1.shape= torch.Size([138499, 128])  adj.shape= torch.Size([138499, 138499])\n",
      "Optimization Finished in 7 min!\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import time\n",
    "\n",
    "# Train model\n",
    "model.train()\n",
    "start_time = time.time()\n",
    "for epoch in range(epochs):\n",
    "    t = time.time()\n",
    "    optimizer.zero_grad()\n",
    "    rand_indices = torch.randint(0, features.shape[0], (indices.shape[0],indices.shape[1]), device=adj.device)# We take random indices each time we run an epoch\n",
    "    pairs = torch.cat((indices, rand_indices), dim=1) # Concatenate the edges indices and random indices.   \n",
    "    \n",
    "    output = model(features, adj, pairs) # we run the model that gives the output.\n",
    "    loss_train = F.nll_loss(output, y) # we are using nll_loss as loss to optimize, we store it in loss_train. We compare to y which is stable and contains the tag ones and zeros.\n",
    "    #print(type(loss_train), '\\n', loss_train.shape)\n",
    "    acc_train = accuracy_score(torch.argmax(output, dim=1).detach().cpu().numpy(), y.cpu().numpy())# just to show it in the out put message of the training\n",
    "    loss_train.backward() # The back propagation ? --> Computes the gradient of current tensor w.r.t. graph leaves\n",
    "    optimizer.step() # Performs a single optimization step (parameter update).\n",
    "    \n",
    "    if epoch % 5 == 0:\n",
    "        print('Epoch: {:03d}'.format(epoch+1),\n",
    "              'loss_train: {:.4f}'.format(loss_train.item()),\n",
    "              'acc_train: {:.4f}'.format(acc_train.item()),\n",
    "              'time: {:.4f}s'.format(time.time() - t),\n",
    "             'total_time: {}min'.format(round((time.time() - start_time)/60)))\n",
    "\n",
    "print(\"Optimization Finished in {} min!\".format(round((time.time() - start_time)/60)))\n",
    "print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "cb56093d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "h1.shape= torch.Size([138499, 128])  adj.shape= torch.Size([138499, 138499])\n",
      "Log loss: 0.8243089599514166\n"
     ]
    }
   ],
   "source": [
    "# Validation on val subset then calculate loss between prediction (y_pred) and valid y (y_val)\n",
    "node_pairs = np.array(np.transpose(val_edges))\n",
    "pairs = torch.LongTensor(node_pairs).to(device)\n",
    "pred_output = model(features, adj, pairs)\n",
    "y_pred = torch.exp(pred_output)\n",
    "y_pred = y_pred.detach().cpu().numpy()\n",
    "print('Log loss:', log_loss(y_val, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "ad4e5c2a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "218359 2104041 torch.Size([138499, 138499]) 4208082\n"
     ]
    }
   ],
   "source": [
    "print(len(pairs[0]), len(indices[0]), adj.shape, len(y))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "973d7433",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "218359"
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(pairs[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "220a4bdb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.0e+00, 1.0e+00],\n",
       "       [0.0e+00, 1.0e+00],\n",
       "       [0.0e+00, 1.0e+00],\n",
       "       ...,\n",
       "       [0.0e+00, 1.0e+00],\n",
       "       [3.9e-44, 1.0e+00],\n",
       "       [0.0e+00, 1.0e+00]], dtype=float32)"
      ]
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#y_val\n",
    "y_pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "47dd9074",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "6c115a36",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(138499, 32)"
      ]
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# features initializaed randomly because not yet ready\n",
    "features_np = np.random.randn(G_train.number_of_nodes(), 32) # Generates node features randomly\n",
    "features_np.shape\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "cf743944",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([2, 2104041])\n",
      "-1.9374463378232334\n"
     ]
    }
   ],
   "source": [
    "print(indices.shape)\n",
    "print(min(features_np[0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "e8ba2946",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1965542"
      ]
     },
     "execution_count": 64,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "G_train.number_of_edges()*2 # = 1965036 "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
